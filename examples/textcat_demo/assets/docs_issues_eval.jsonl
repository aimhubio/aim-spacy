{"text":"Node.js: Produce docs files","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Documentation for Virtual Appliance 3.0\n\nUpdate VA technical documentation, and complete release notes, for Virtual Appliance 3.0.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Add Documentation\n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"remark-ping: docs mention zestedesavoir, not how to set it up?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update lunr dependency","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# RFC: Remove pages pertaining to old versions of tesseract from wiki\n\nI suggest removing pages pertaining to old versions of tesseract from wiki.\r\n\r\neg. There are multiple pages with instructions for creating box files for tesseract 3.x. These instructions do not apply to tesseract4 and above. Users who follow these and then try to run lstmtraining get unexpected errors.\r\n\r\nHere is the current list of wiki pages:\r\n\r\n```\r\nHome\r\n4.0 Accuracy and Performance\r\n4.0 Docker Containers\r\n4.0 with LSTM\r\n4.0x Changelog\r\n4.0x Common Errors and Resolutions\r\nAddOns\r\nAPIExample\r\nAPIExample user_patterns\r\nCommand Line Usage\r\nCompiling\r\nCompiling \u2013 GitInstallation\r\nControlParams\r\nData Files\r\nData Files Contributions\r\nData Files in different versions\r\nData Files in tessdata_fast\r\nDocumentation\r\nDownloads\r\nFAQ\r\nFAQ Old\r\nFix footer\r\nFonts\r\nImproveQuality\r\nMake Box Files\r\nMaking Box Files 4.0\r\nNeuralNetsInTesseract4.00\r\nPlanning\r\nReadMe\r\nReleaseNotes\r\nTechnical Documentation\r\nTesseractOpenCL\r\nTestingTesseract\r\nThe Hallucination Effect\r\nTraining Tesseract\r\nTraining Tesseract 3.00\u20133.02\r\nTraining Tesseract 3.03\u20133.05\r\nTraining Tesseract \u2013 Make Box Files\r\nTraining Tesseract \u2013 tesstrain.sh\r\nTrainingTesseract\r\nTrainingTesseract 4.00\r\nTrainingTesseract 4.00 Finetune\r\nTrainingTesseract2\r\nUNLV Testing of Tesseract\r\nUser App Example\r\nUser Projects \u2013 3rdParty\r\nVGSLSpecs\r\nViewerDebugging\r\n```","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Ubuntu 16.04 LST installation instructions","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Usage instructions incomplete","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"GDB debugging fails for TizenRT/Artik053","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"How to use remotely?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Add support for MSI in Azure App Service\n\nPlease add support for the different MSI endpoint and flow used in the authentication of Azure App Service. This flow uses the `MSI_ENDPONT` and `MSI_SECRET` environment variables.\r\n\r\nhttps://docs.microsoft.com/en-us/azure/app-service/overview-managed-identity#using-the-rest-protocol","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"RRD dependency","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Blender Addon for importing OpenMVG SfM reconstruction results\n\nHi Pierre,\r\n\r\nI am working on a Blender Addon (https://github.com/SBCV/Blender-Addon-Photogrammetry-Importer) that allows you to import different photogrammetry data formats into Blender. The latest version supports now OpenMVG JSON files.\r\n\r\nI can imagine that this tool could be useful for other OpenMVG JSON files users as well. It offers for example a nice way to visualize the reconstruction results (including cameras and image planes).\r\n\r\nOne can use Blender's camera animation tool to render the reconstruction. The camera animation in Blender offers many useful options to define the camera motion. You can define for example the camera path in 3D and add looking constraints for the camera.\r\nFurthermore, you can load different models (with different file formats) into Blender at the same time. So you can for example render a point cloud and the corresponding mesh at the same time (e.g. to highlight differences).\r\nI used it for example to compare reconstruction results of virtual data with the corresponding virtual environment.\r\n\r\nFor Blender users:\r\nYou can use OpenMVG instead of Blender's camera tracking tool to reconstruct the scene. Which is way more comfortable, since Blender's camera tracking requires a lot of user interaction to compute reasonable results.\r\n\r\nJust wanted to inform you about that. Maybe you want to add a reference to the documentation.\r\n\r\nFeel free to close this issue.\r\n\r\nCheers\r\nSebastian","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# PDFSurface fails with file object.\n\nConsider the following code:\r\n\r\n    import cairo\r\n    fp = open('out.pdf', 'w')\r\n    s = cairo.PDFSurface(fp, 400, 400)\r\n    s.finish()\r\n\r\nIt fails with this error message:\r\n\r\n    Traceback (most recent call last):\r\n      File \"issue.py\", line 4, in <module>\r\n        s.finish()\r\n    __main__.IOError: error while writing to output stream\r\n\r\nI would expect this code to produce the PDF file `out.pdf`. Replacing the file object by the file path works. Could you figure out, what causes this problem?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"\"bad marshal data\" when loading model that was saved with python 2.7 into python 3.4.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"docker-machine can not create vm","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add FAQ's to the documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Documentation and landing page","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Swap Buttons in GUI\n\n**Describe the feature**\r\nA button in the Companion Admin GUI that would allow two already-programmed functions/buttons to swap places with each other, rather than moving one button and reprogramming the other.\r\n\r\n**Is this platform dependent (windows, mac, ..)?**\r\nNo\r\n\r\n**If documentation is required to implement, do you know where to find it?**\r\nNo, I don't. I do know that there is a similar function in the guts of MA software. When you \"move\" an executor to a fader or button where there is already an executor programmed, the one in the destination moves to where the first executor was originally.\r\n\r\n**Usecases**\r\nIf I have a full Companion page programmed, but decide to change the layout, there are a few options open to me. For the examples, I will say that I want to swap buttons _1.1_ and _1.12_\r\n\r\n**1**) I can move/copy _1.1_ to _2.1_, then move _1.12_ to _1.1_, then move _2.1_ to _1.12_\r\n\r\n**2**) I can export page 1, then import it to page 2. I can then copy _1.1_ to _2.12_, and copy _1.12_ to _2.1_. If I wanted those functions to remain on page 1, I would then export page 2, and import it to page 1 ... and then delete page 2\r\n\r\nBoth of these options are viable, but don't seem very efficient. The efficiency lessens if the next empty page is further away from the page you want to edit. \r\n\r\nHaving a swap function so that I can click on \"Swap\" -> button _1.1_ -> button _1.12_ and have them change places would be time-saving.\r\n\r\nThank you for your consideration of this feature.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Update ConfigMap Docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Samples erroring when loaded locally","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add handlebars support to HTML previews","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Continuous deployment\n\nOur workflow is looking pretty good! We have now set up some automated tests for any new changes. We can go one step further and add continuous deployment to our workflow.\n\n### What is Continuous Deployment?\n\n**Continuous Deployment**, or **CD**, is an extended step that builds from the automation in CI. CD is automation at various stages, deploying new changes to the different environment.\n\nThe goal of CD is to reduce the time it takes to finish a project. Automation provides shorter feedback loops. This could look like faster testing cycles, or faster deployment and user feedback.\n\nThere are several ways to deploy your code changes. For this repository, we'll deploy with GitHub Pages. If you'd like to learn more about GitHub Pages, there are a [few learning lab courses](https://lab.github.com/courses?tag=GitHub%20Pages) you might be interested in.\n\nWhen deploying with GitHub Pages, you can choose to deploy from several locations. We're going to deploy from the `/docs` directory of this repository.  This will deploy only the contents of the `/docs` directory.\n\n## Step 12: Deploy\n\nWhenever there is a new commit on `master`, GitHub pages will deploy.\n\n### :keyboard: Activity: Enable GitHub pages to deploy\n\n1. Navigate to the [**Settings**](https://github.com/m-vallance/continuous-integration-circle/settings) tab.\n1. Under GitHub pages, set the source to `master branch` and click **Save**.\n\n<hr>\n<h3 align=\"center\">I'll respond below for your next steps.</h3>\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Starting documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Create a folder","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"HTML page examples","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Building to Subdirectory\n\nHi team! Great job on this project, it's awesome.\r\n\r\nI'm trying to build to a sub directory, so for example:\r\n```\r\nhttps://example.com/docs-site-1\r\n```\r\n\r\nI'm currently using the `baseURL` key in the `.gitdocs.json` file, and that is compiling the webpages in a `docs-site-1` directory fine. However the main bundle and static assets are outside of this directory in the `.gitdocs_build` directory. Is there any way to change this behavior to have it all compiled in the root `.gitdocs_build` directory with the anchor tags pointing to `/docs-site-1/index.html`?\r\n\r\nThanks for any input!","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Working AndroidTestOrchestrator example","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Start an FAQ section","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Add me please","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"swagger-document compose - FAILED","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Update Documentation for 1.0.1b","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Finish Writing Readme\n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Make data importer\n\nWrite function to Import json files into python.  Might consider using nltools.data.Adjacency class for graphs over time.\r\n\r\nSee here for getting data off of chips using reader.  https://github.com/meriac/openbeacon-ng/blob/master/docs/quickstart.md","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# How do you create your own remote collection?\n\nThis sounds like very basic question, but I tried and could not find an answer from my own searching.\r\n\r\nhttps://docs.bit.dev/docs/cli-remote.html implies you can create your own collection and add it as your remote.\r\nhttps://github.com/teambit/bit-docker seems the one I can use it for that purpose.\r\nhttps://github.com/teambit/bit says \"You can set up a collection on any server, or use Bit\u2019s component hub.\"\r\n\r\nBut I have hard time finding exactly how to set up a collection on any server. All documentation I find leads to using bit.dev. Is there a way for me to start this?\r\n\r\nThank you!","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Re-open Camera","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"lint markdown for style","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Nodemailer not working :(","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Give full schema in docs?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"should update teracy-dev development guide","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Distribute documentation mis-formatted","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"SocketException[Connected refused] errors","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"A way to trigger appear animation using Transition","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Development Environment:  ValueError: Protocol message has no non-repeated submessage field \"metadata\"","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Embed README images","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Design \"resting state\" instructions","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Multiple recipients vs. git signing key","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Which licence is this issued under?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"The aria-labels of checkboxes in the Select component appears as [object Object] if the label is a node.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Document git workflow","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Make switching to CuDNN easy","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"mvn -Pconfigure-datasource fails to build","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Issue when using function convertUTCtoTT","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"node.exe via WSL fails with EINVAL on uv_pipe_open","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Error establishing a database connection","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Swift proto file extension values empty, data showing up in unknown storage","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Model name has no instructions","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Saving empty object to a subschema does not do anything in newest mongoose","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Request - please add an option to read the movie ID at the front of the filename","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Issue with k8s.io/docs/concepts/workloads/pods/pod-lifecycle/\n\n\r\n\r\n<!-- Thanks for filing an issue! Before submitting, please fill in the following information. -->\r\n<!-- See https://kubernetes.io/docs/contribute/start/ for guidance on writing an actionable issue description. -->\r\nI am not sure if this is a bug. Please update documentation on conditionType for readinessGate.\r\n\r\n<!--Required Information-->\r\n**Problem:**\r\nThe readiness gate explanation for conditionType is not clear as to what does conditionType mean, it just says that conditionType: \"www.example.com/feature-1\", is that a hard coded value, and how does this work.\r\n\r\nThe readiness gate requires one or  two lines explanation on conditionType as to how the value can be used or changed.\r\n\r\n**Page to Update:**\r\nhttps://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/\r\n\r\n<!--Optional Information (remove the comment tags around information you would like to include)-->\r\n<!--Kubernetes Version:-->\r\n1.14\r\n<!--Additional Information:-->\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"automate location translation file updates","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# (appveyor-server) Update documentation\n\nAs requested in https://github.com/appveyor/website/pull/645 I have created this issue to update the documentation and title for `appveyor-server`","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Triggers and actions not working ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Trying to add own leds that are connected","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"date format in pluck() for collection","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add -ResourceId parameter for all Get-AzureRm* commands","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Game does not compile on Linux out of the box for several reasons\n\nFirst of all, you hardcode \"g++-5\" in game/sdl/linux/makefile\r\nTo continue compilation I had to remove -5 from several places on top of the make file so that executable is just \"g++\".\r\n\r\nThen build has stopped because of missing #include <stdio.h> in  several files:\r\ngame/httppackinfomanager.cpp with error: 'fopen' was not declared in this scope \r\ngame/httppackmanager.cpp:54:51: error: 'fopen' was not declared in this scope\r\nmpshared/packinfomanager.cpp:43:54: error: 'fopen' was not declared in this scope\r\nmpshared/indexloader.cpp:12:38: error: 'fopen' was not declared in this scope\r\n\r\nNext problem was:\r\n\r\n../../gameform.cpp:4:30: fatal error: game/Multiplayer.h: No such file or directory\r\ncompilation terminated.\r\n../../Multiplayer.cpp:2:30: fatal error: game/Multiplayer.h: No such file or directory\r\ncompilation terminated.\r\nIn fact this file does not exist, however file game/multiplayer.h does. So changing this two files to multiplayer.h did work.\r\n\r\nAfter those five files the game compile successfully.\r\n\r\nAnother problem is with file game/sdl/linux/install.sh\r\nIt uses ``if ! dpkg -l | grep libsdl2-dev > /dev/null ; then``\r\nThis line which would only work in distributions based on deb packages, such as Debian and Ubuntu but not in other distributions. I think it's better to say that SDL2 is required for building and recommend to install this two packages: libsdl2-dev libcurl4-openssl-dev in your readme file\r\n\r\n(though in my distribution -dev packages are not separated from main packages)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# \u0421\u0434\u0435\u043b\u0430\u043b \u0432\u0441\u0451 \u043f\u043e\u0448\u0430\u0433\u043e\u0432\u043e, \u043d\u043e \u0432 /movies -  \u043e\u0448\u0438\u0431\u043a\u0430 404\n\n\u0423\u0436\u0435 2 \u0440\u0430\u0437 \u043f\u0435\u0440\u0435\u0441\u043e\u0437\u0434\u0430\u044e \u043f\u0440\u043e\u0435\u043a\u0442, \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u043b \u0432\u0441\u0435 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u044b ( \u0441 \u043c\u0438\u0433\u0440\u0430\u0446\u0438\u0435\u0439 \u0438 \u0430\u043f\u0434\u0435\u0439\u0442\u043e\u043c), \u043d\u043e  /movies \u0440\u0430\u0437\u0434\u0435\u043b\u0430 \u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442. \r\n\r\n---\r\n#### \u0421\u0432\u0435\u0434\u0435\u043d\u0438\u044f \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435\r\n\r\n\u26a0 *\u041d\u0435 \u0432\u043d\u043e\u0441\u0438\u0442\u0435 \u043f\u0440\u0430\u0432\u043a\u0438 \u0432 \u044d\u0442\u043e\u0442 \u0440\u0430\u0437\u0434\u0435\u043b. \u042d\u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0434\u043b\u044f \u0441\u0432\u044f\u0437\u044b\u0432\u0430\u043d\u0438\u044f \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0441\u0430\u0439\u0442\u0430 docs.microsoft.com \u0441 \u0432\u043e\u043f\u0440\u043e\u0441\u043e\u043c \u043d\u0430 GitHub.*\r\n\r\n* ID: 6719f08e-3bd7-dc1a-71df-f2ef9fbca9d8\r\n* Version Independent ID: 7096fdb3-612e-9e00-bd0b-8ea4886a09ce\r\n* Content: [\u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432 \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 Razor Pages \u0432 ASP.NET Core](https://docs.microsoft.com/ru-ru/aspnet/core/tutorials/razor-pages/model?view=aspnetcore-2.2&tabs=visual-studio#feedback)\r\n* Content Source: [aspnetcore/tutorials/razor-pages/model.md](https://github.com/aspnet/AspNetCore.Docs.ru-ru/blob/live/aspnetcore/tutorials/razor-pages/model.md)\r\n* Product: **aspnet-core**\r\n* Technology: **aspnetcore-tutorials**\r\n* GitHub Login: @Rick-Anderson\r\n* Microsoft Alias: **riande**","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Custom Easing Logic","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"[Docs] How to create custom components?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update Sysctls Docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Multidimensional slicing doesn't work as shown","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Azure deploy Error: Cannot find module 'user-home'","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Fix: info project in README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Error deploying to Dokku","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# How to connect to a ES cluster that is TLS/authentication enable?\n\nI can't seem to find any documentation on how to leverage the jaeger-operator to create an instance using a secured ES cluster that is TLS and authentication enabled. Can someone provide some guidance on how to get this to work? This is what I have right now. Furthermore, the cleaner job will also need to be able to authenticate. The URL for ES is https://jaeger-es-http:9200 using a self-signed cert.\r\n\r\n```\r\napiVersion: jaegertracing.io/v1\r\nkind: Jaeger\r\nmetadata:\r\n  name: jaeger\r\nspec:\r\n  strategy: production\r\n  storage:\r\n    type: elasticsearch\r\n    options:\r\n      es:\r\n        server-urls: http://jaeger-es-http:9200\r\n    esIndexCleaner:\r\n      enabled: true\r\n      numberOfDays: 30\r\n      schedule: \"55 23 * * *\"\r\n      image: jaegertracing/jaeger-es-index-cleaner\r\n  agent:\r\n    strategy: DaemonSet\r\n  sampling:\r\n    options:\r\n      default_strategy:\r\n        type: const\r\n        param: 1\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Compiling Problem to IOS","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Minimum DB User Privileges to run app","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"GetInstanceAttributeListService","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Serps\\SearchEngine\\Google\\Exception\\InvalidDOMException","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# yolov3-tiny compatibility \n\nI am trying to use the yolov3-tiny weights and config files to test performance. I keep encountering a segmentation fault and no other error to be seen. I followed the example code from the pip documentation:\r\n\r\n```\r\nfrom pydarknet import Detector, Image\r\nimport cv2\r\n\r\nnet = Detector(bytes(\"cfg/yolov3-tiny.cfg\", encoding=\"utf-8\"), bytes(\"weights/yolov3-tiny.weights\", encoding=\"utf-8\"), 0, bytes(\"cfg/coco.data\",encoding=\"utf-8\"))\r\n\r\nimg = cv2.imread('humans.jpg')\r\nimg_darknet = Image(img)\r\n\r\nresults = net.detect(img_darknet)\r\n\r\nfor cat, score, bounds in results:\r\n    x, y, w, h = bounds\r\n    cv2.rectangle(img, (int(x - w / 2), int(y - h / 2)), (int(x + w / 2), int(y + h / 2)), (255, 0, 0), thickness=2)\r\n    cv2.putText(img,str(cat.decode(\"utf-8\")),(int(x),int(y)),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0))\r\n\r\ncv2.imshow(\"output\", img)\r\ncv2.waitKey(0)\r\ncv2.destroyAllWindows();\r\n\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Breakup class to better map to Gitlabs documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"GroupProcedure DidFinish observer is not guaranteed to execute before child DidFinish observers","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Where to Run the swarm_setup.sh Script","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"https://github.com/daisykd/hello-world/blob/master/README.md","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"How to run tests","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# UPDATE CRONTAB\n\nI am running a process via crontab once a day , \r\nnow I want to run another process once a day , \r\n\r\nhow do i update my crontab on dokku ?\r\n\r\nroot@AmzBotD:~# dokku run test1 crontab -l\r\nno matching process entry found\r\nno crontab for herokuishuser\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"dapp not reachable when deploying with docker behind nginx","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Implement an interface for all errors, so they can be redefined by callers\n\nCurrently we return some error messages to end users, like\r\n\r\n- \"flag provided but not defined\"\r\n- \"required flag not set\"\r\n\r\nBut do not provide a way for people to re-define those error messages. We should implement some public interfaces for our errors, and provide documentation on how to implement custom error messages.\r\n\r\nRelated issues / PRs\r\n\r\n- https://github.com/urfave/cli/issues/852\r\n- https://github.com/urfave/cli/pull/656","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Updated Definition","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Weekly Digest (4 August, 2019 - 11 August, 2019)\n\nHere's the **Weekly Digest** for [*veggiemonk/awesome-docker*](https://github.com/veggiemonk/awesome-docker):\n\n - - - \n# ISSUES\nLast week 2 issues were created.\nOf these, 2 issues have been closed and 0 issues are still open.\n## CLOSED ISSUES\n:heart: #729 [fix Travis CI Build #2400](https://github.com/veggiemonk/awesome-docker/pull/729), by [agebhar1](https://github.com/agebhar1)\n:heart: #728 [Fix a typo](https://github.com/veggiemonk/awesome-docker/pull/728), by [gokaygurcan](https://github.com/gokaygurcan)\n## NOISY ISSUE\n:speaker: #728 [Fix a typo](https://github.com/veggiemonk/awesome-docker/pull/728), by [gokaygurcan](https://github.com/gokaygurcan)\nIt received 2 comments.\n\n - - - \n# PULL REQUESTS\nLast week, 2 pull requests were created, updated or merged.\n## MERGED PULL REQUEST\nLast week, 2 pull requests were merged.\n:purple_heart: #729 [fix Travis CI Build #2400](https://github.com/veggiemonk/awesome-docker/pull/729), by [agebhar1](https://github.com/agebhar1)\n:purple_heart: #728 [Fix a typo](https://github.com/veggiemonk/awesome-docker/pull/728), by [gokaygurcan](https://github.com/gokaygurcan)\n\n - - - \n# COMMITS\nLast week there were 9 commits.\n:hammer_and_wrench: [Automated update repository metadata [skip-ci]](https://github.com/veggiemonk/awesome-docker/commit/a6fca13c53bec4aecb0f335ad2b7ea1961e46cda) by [veggiemonk](https://github.com/veggiemonk)\n:hammer_and_wrench: [Automated update repository metadata [skip-ci]](https://github.com/veggiemonk/awesome-docker/commit/9b4ed4060f548d16090fe2bce2ca72bd393847cf) by [veggiemonk](https://github.com/veggiemonk)\n:hammer_and_wrench: [Merge pull request #729 from agebhar1/feature/fix-TravisCI#2400  fix Travis CI Build #2400](https://github.com/veggiemonk/awesome-docker/commit/7c97cd24c3c8c301b661e3109ba78bcde97f3473) by [veggiemonk](https://github.com/veggiemonk)\n:hammer_and_wrench: [remove 'docker-fluentd' since it's not available anymore  TravisCI [#2400]:  > Issues :-( > > > Links >   1. [L185] 404 https://github.com/kiyoto/docker-fluentd > > Dupes >   None \u2713  [#2400] https://travis-ci.org/veggiemonk/awesome-docker/builds/569439029](https://github.com/veggiemonk/awesome-docker/commit/3d43a68699d9da3b8d3c1c776cf11d7abfa34909) by [agebhar1](https://github.com/agebhar1)\n:hammer_and_wrench: [fix '4c0a16c Update README.md'](https://github.com/veggiemonk/awesome-docker/commit/aed14d621b97c53df9c27a1c74dda804fb089c27) by [agebhar1](https://github.com/agebhar1)\n:hammer_and_wrench: [Update README.md](https://github.com/veggiemonk/awesome-docker/commit/4c0a16cf5c29fc6cc309dbc7cbe85a30d6b2568f) by [gokaygurcan](https://github.com/gokaygurcan)\n:hammer_and_wrench: [Automated update repository metadata [skip-ci]](https://github.com/veggiemonk/awesome-docker/commit/45fd3df19eb58227bc8275f6bf6846092dc80d0b) by [veggiemonk](https://github.com/veggiemonk)\n:hammer_and_wrench: [Automated update repository metadata [skip-ci]](https://github.com/veggiemonk/awesome-docker/commit/7ce07beb6f94929c5dfdc448699adb6cea32a653) by [veggiemonk](https://github.com/veggiemonk)\n:hammer_and_wrench: [Fix mesosphere renamed d2iq](https://github.com/veggiemonk/awesome-docker/commit/70fe28b14adbebc35705b2f505cd66970384cffe) by [veggiemonk](https://github.com/veggiemonk)\n\n - - - \n# CONTRIBUTORS\nLast week there were 3 contributors.\n:bust_in_silhouette: [veggiemonk](https://github.com/veggiemonk)\n:bust_in_silhouette: [agebhar1](https://github.com/agebhar1)\n:bust_in_silhouette: [gokaygurcan](https://github.com/gokaygurcan)\n\n - - - \n# STARGAZERS\nLast week there were 67 stagazers.\n:star: [tbw-wb](https://github.com/tbw-wb)\n:star: [ayalcin1](https://github.com/ayalcin1)\n:star: [sssxie](https://github.com/sssxie)\n:star: [shimadama](https://github.com/shimadama)\n:star: [charstnut](https://github.com/charstnut)\n:star: [nienjiuntai](https://github.com/nienjiuntai)\n:star: [ashwamegh](https://github.com/ashwamegh)\n:star: [oshou](https://github.com/oshou)\n:star: [wlisrausr](https://github.com/wlisrausr)\n:star: [leaked](https://github.com/leaked)\n:star: [paraparity](https://github.com/paraparity)\n:star: [metalmandalore](https://github.com/metalmandalore)\n:star: [sebnapi](https://github.com/sebnapi)\n:star: [CompilerBian](https://github.com/CompilerBian)\n:star: [Kuri-su](https://github.com/Kuri-su)\n:star: [dionysisk](https://github.com/dionysisk)\n:star: [Raltay](https://github.com/Raltay)\n:star: [balloontmz](https://github.com/balloontmz)\n:star: [jairofloress](https://github.com/jairofloress)\n:star: [pseegaha](https://github.com/pseegaha)\n:star: [mvpvg](https://github.com/mvpvg)\n:star: [danielvelara](https://github.com/danielvelara)\n:star: [Fofade](https://github.com/Fofade)\n:star: [tjuyy](https://github.com/tjuyy)\n:star: [seagalputra](https://github.com/seagalputra)\n:star: [dskusuma](https://github.com/dskusuma)\n:star: [marcotinacci](https://github.com/marcotinacci)\n:star: [dsw0214](https://github.com/dsw0214)\n:star: [rafaelcalleja](https://github.com/rafaelcalleja)\n:star: [tkeitzl](https://github.com/tkeitzl)\n:star: [morkot](https://github.com/morkot)\n:star: [Dougs71](https://github.com/Dougs71)\n:star: [Nyadesune](https://github.com/Nyadesune)\n:star: [Stormiix](https://github.com/Stormiix)\n:star: [VahidAlizadeh](https://github.com/VahidAlizadeh)\n:star: [jamesvibar](https://github.com/jamesvibar)\n:star: [piharpi](https://github.com/piharpi)\n:star: [gabtub](https://github.com/gabtub)\n:star: [hex42](https://github.com/hex42)\n:star: [decryptus](https://github.com/decryptus)\n:star: [femicodes](https://github.com/femicodes)\n:star: [paulmillerp03](https://github.com/paulmillerp03)\n:star: [AndreLucasrs](https://github.com/AndreLucasrs)\n:star: [TyIsI](https://github.com/TyIsI)\n:star: [thenx](https://github.com/thenx)\n:star: [YanghangXu](https://github.com/YanghangXu)\n:star: [DCsunset](https://github.com/DCsunset)\n:star: [pablocrivella](https://github.com/pablocrivella)\n:star: [dangnguyen27](https://github.com/dangnguyen27)\n:star: [mmicome](https://github.com/mmicome)\n:star: [atriple](https://github.com/atriple)\n:star: [jocobtt](https://github.com/jocobtt)\n:star: [romap0](https://github.com/romap0)\n:star: [William0Friend](https://github.com/William0Friend)\n:star: [aimuch](https://github.com/aimuch)\n:star: [breeze924](https://github.com/breeze924)\n:star: [OnurSevket](https://github.com/OnurSevket)\n:star: [cnodin](https://github.com/cnodin)\n:star: [weisurya](https://github.com/weisurya)\n:star: [M3te0r](https://github.com/M3te0r)\n:star: [Celcis](https://github.com/Celcis)\n:star: [wesleimp](https://github.com/wesleimp)\n:star: [lakshmanpasala](https://github.com/lakshmanpasala)\n:star: [fedorovic82](https://github.com/fedorovic82)\n:star: [amjimenez](https://github.com/amjimenez)\n:star: [thiagotnunes](https://github.com/thiagotnunes)\n:star: [v-Muddu](https://github.com/v-Muddu)\nYou all are the stars! :star2:\n\n - - - \n# RELEASES\nLast week there were no releases.\n\n - - - \n\nThat's all for last week, please <kbd>:eyes: **Watch**</kbd> and <kbd>:star: **Star**</kbd> the repository [*veggiemonk/awesome-docker*](https://github.com/veggiemonk/awesome-docker) to receive next weekly updates. :smiley:\n\n*You can also [view all Weekly Digests by clicking here](https://github.com/veggiemonk/awesome-docker/issues?q=is:open+is:issue+label:weekly-digest).* \n\n> Your [**Weekly Digest**](https://github.com/apps/weekly-digest) bot. :calendar:\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Whitespace stripped from 'classic' javascript elements might lead to illegal empty elements","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"typo in Cluster concepts documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Feature - Generate Docs For Services Without Swagger Annotations","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"FILESYSTEM_CHARSET setting - README update (?)","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"[Request] add readme file with dev environment setup instructions","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Labels","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Assets not loading on GitHub Pages with Custom Domain\n\n# Bug report\r\n\r\n## Describe the bug\r\n\r\nI'm hosting my exported static page on gh-pages with a custom domain. \r\n\r\nError shown is as follows:\r\n\r\n```\r\nThe script from \u201chttp://___.co/_next/static/runtime/webpack-f5e50b6b501ccea2a79b.js\u201d was loaded even though its MIME type (\u201ctext/html\u201d) is not a valid JavaScript MIME type.\r\nLoading failed for the <script> with source \u201chttp://___.co/_next/static/runtime/webpack-f5e50b6b501ccea2a79b.js\u201d.\r\n```\r\nImages are loaded fine. It's only hashed files which don't work.\r\n\r\n## To Reproduce\r\n\r\nExport and push to gh-pages.\r\n\r\n## Expected behavior\r\n\r\nSite renders properly and loads all assets as it should.\r\n\r\n## System information\r\n\r\n- gh-pages\r\n- Ubuntu\r\n- .nojekyll and CNAME added.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"oc CMD --help output unreadable and confusing","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"no way to build, missing \"CodecDecoder.h\"","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Step 1 in Viewing Event Details","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Bug in writeCbModel (documentation)","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Rrror when running gdb hello","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Undocumented associated types get handled badly","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Git version without Github","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"can't create xunit project for .NET Core 2.0 Preview 2","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Improve the userscript wrapper to not break window functions","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"How to import a sublime/textmate theme","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Elementor 1.6 - Beta Release (RC2 updated)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# configuration.yaml is not created at startup when using official docker image\n\n<!-- READ THIS FIRST:\r\n- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/\r\n- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases\r\n- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues\r\n- iOS issues should be submitted to the home-assistant-iOS repository: https://github.com/home-assistant/home-assistant-iOS/issues\r\n- Do not report issues for integrations if you are using a custom integration: files in <config-dir>/custom_components\r\n- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests\r\n- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!\r\n-->\r\n**Description of the problem**\r\nAccording to the [docs](https://developers.home-assistant.io/docs/en/configuration_yaml_index.html) the `configuration.yaml` is created at startup. Using the the latest docker release it's not created automatically. Also note that [docs ](https://www.home-assistant.io/docs/configuration/yaml/)don't specify where the file is supposed to be located \r\n\r\n**Home Assistant release with the issue:**\r\nhomeassistant/home-assistant                                             0.97.1\r\n<!--\r\n- Frontend -> Developer tools -> Info\r\n- Or use this command: hass --version\r\n-->\r\n\r\n\r\n**Last working Home Assistant release (if known):**\r\nUnknown\r\n\r\n**Operating environment (Hass.io/Docker/Windows/etc.):**\r\nI'm using the official docker image `homeassistant/home-assistant:0.97.1`.\r\nMy host OS is Ubuntu 16.04 (irrelevant).\r\n\r\n\r\n**Repro steps**\r\n1.  `docker run --name homeass --rm -it -p 8123:8123 -p 8300:8300 -p 51827:51827 homeassistant/home-assistant:0.97.1`\r\n2. `docker exec -it homeass bash`\r\n3. `find . -iname 'configuration.yaml'`\r\n4. `find . -iname 'configuration.yml'`\r\n\r\n**Expected behaviour**\r\nSteps 3-4 should return the path to the configuration file.\r\n\r\n**Actual behaviour**\r\nSteps 3-4 should don't return anything. The `configuration.yaml` isn't created automatically on startup.\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Document deployment profiles in readme","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"CMAKE_INSTALL_DIR is unused","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Uikit 3.0.0-Beta.27 - Lightbox component - add #hash option","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"\"_: Python\" in README.md results in an error","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# trafficlight.py throwing \"AWSIoTPythonSDK.core.protocol.mqtt_core - ERROR - Offline request queue has been disabled\"\n\nHi,\r\n\r\ni am going through GG getting started guide, however, i am stuck at module 5, 3b. (https://docs.aws.amazon.com/greengrass/latest/developerguide/comms-disabled.html)\r\n\r\nseemed like a common problem as someone posted the same in github without any solution \r\nhttps://github.com/aws/aws-iot-device-sdk-python/issues/141\r\n\r\nas module 6 and 7 have dependencies on module 5, i want to complete it successfully. can someone help?\r\n\r\nhere's the error that i am seeing when i execute the py script. tried it on both Mac and Windows. seeing the same output. \r\n\r\n2019-08-11 13:34:01,298 - AWSIoTPythonSDK.core.protocol.mqtt_core - INFO - Performing sync subscribe...\r\n2019-08-11 13:34:01,298 - AWSIoTPythonSDK.core.protocol.mqtt_core - INFO - Offline request detected!\r\n2019-08-11 13:34:01,298 - AWSIoTPythonSDK.core.protocol.mqtt_core - ERROR - Offline request queue has been disabled\r\nTraceback (most recent call last):\r\n  File \"trafficLight.py\", line 232, in <module>\r\n    deviceShadowHandler.shadowRegisterDeltaCallback(customShadowCallback_Delta)\r\n  File \"/Library/Python/2.7/site-packages/AWSIoTPythonSDK/core/shadow/deviceShadow.py\", line 398, in shadowRegisterDeltaCallback\r\n    self._shadowManagerHandler.basicShadowSubscribe(self._shadowName, \"delta\", self.generalCallback)\r\n  File \"/Library/Python/2.7/site-packages/AWSIoTPythonSDK/core/shadow/shadowManager.py\", line 68, in basicShadowSubscribe\r\n    self._mqttCoreHandler.subscribe(currentShadowAction.getTopicDelta(), 0, srcCallback)\r\n  File \"/Library/Python/2.7/site-packages/AWSIoTPythonSDK/core/protocol/mqtt_core.py\", line 299, in subscribe\r\n    self._handle_offline_request(RequestTypes.SUBSCRIBE, (topic, qos, message_callback))\r\n  File \"/Library/Python/2.7/site-packages/AWSIoTPythonSDK/core/protocol/mqtt_core.py\", line 370, in _handle_offline_request\r\n    raise self._offline_request_queue_disabled_exceptions[type]\r\nAWSIoTPythonSDK.exception.AWSIoTExceptions.subscribeQueueDisabledException","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Detecting whether a method is chainable (and general concerns with breaking changes)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Wrong script path in Readme","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"can you help to build tensorflow_amd64 w AVX/AVX2/SSE/FMA ?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Review the Email Validation functionality\n\nAs pointed out here #617 the validation didn't work when tried it using the US servers.\r\n\r\nThe Mailgun Support team has confirmed that the service should work as follows:\r\n\r\n---\r\n\r\n> I can confirm the EU region does not have email validation at this time; only the US.  As for v3 of the email validation API, it is still operative.  I just ran a quick test just to confirm:\r\n\r\n```\r\n$ curl -G --user 'api:pubkey-REDACTED' -G \\\r\n>    https://api.mailgun.net/v3/address/validate \\\r\n>    --data-urlencode address='mgbox01@gmail.com'\r\n```\r\n```\r\n{\r\n    \"address\":\"mgbox01@gmail.com\",\r\n    \"did_you_mean\":null,\r\n    \"is_disposable_address\":false,\r\n    \"is_role_address\":false,\r\n    \"is_valid\":true,\r\n    \"mailbox_verification\":\"true\",\r\n    \"parts\":{\r\n        \"display_name\":null,\r\n        \"domain\":\"gmail.com\",\r\n        \"local_part\":\"mgbox01\"\r\n    },\r\n    \"reason\":null\r\n}\r\n```\r\n\r\n> And we moved the documentation for it to the following URL: https://documentation.mailgun.com/en/latest/api-email-validation-deprecated.html#email-validation\r\n\r\n---\r\n\r\nThus, the SDK needs an update to cover the following cases:\r\n- Potential check and error message if someone tries to validate an email through the EU service\r\n- Potential check and error message if someone tries to validate an email through a private key\r\n- Potential adjustments to use the API v4 instead of the API v3 for the email validation\r\n\r\nEven if we don't update the code, then we should consider to add a disclaimer as part of the README file to announce these details and prevent other misunderstandings.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# TODO: Distribution and GITHUB\n\n1. Package it for download here on github\r\n2. Edit readme with instructions on installing and basic use\r\n3. Include a one-liner that will download and (re)install the package.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Console error being logged with Angular Event Binding implementation","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add Typings for VS Code Intellisense","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Slides\n\nhttps://docs.google.com/presentation/d/10-0eJ_M6YVr-L-VGYLy7-a8ERod_TYgqw8-eBkH3FXE/edit?usp=sharing","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"[Hidden] not working in platform-server","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# [RFC] Reorganizing models, datasets and others\n\nProblem\r\n---\r\n\r\nThere have been a bunch of requests and efforts (PR #744 #748 #753 Issue #719 #742) around our modules, examples and dataset. This RFC would like to discuss some details and write out the roadmap. I know there has been some internal discussions among @mufeili and @VoVAllen about the drug/chemical dataset/applications. I hope you could also summarize it a bit and improve this RFC. This RFC is likely to be broken down into several PRs (for example, #748 is a good start), so having a roadmap is quite important to track the progress.\r\n\r\nThe problem of the current DGL examples is that\r\n(1) Reusable modules are scattered in many training scripts, making them hard to be accessed by the end users.\r\n(2) We need to add **way more** modules and layers due to the increasing demand from the community. This has severely impeded DGL from more adoption.\r\n(3) The organization is not clean. Each example is put in its dedicated folder. We should have a better hierarchy to organize them (possibly by application type).\r\n(4) Example codes are not included in CI, making it hard to maintain.\r\n\r\nProposal\r\n---\r\n\r\nTo fix this, this RFC proposes the following changes:\r\n(1) Move as many layer/module components as possible from examples to `nn` namespace. These modules should be **functional**, has graph object in the argument to allow dynamic graph, and has clear documentation. We also need to implement them for both mxnet and pytorch.\r\n(2) Try organize modules in the following categories.\r\n  * Graph convolution (`conv.py`)\r\n  * node-level classification/regression\r\n  * link prediction\r\n  * graph classification\r\n  * graph pooling (`glob.py`)\r\n  * graph generation\r\n  * `loss.py`\r\n  * `metrics.py`\r\n  * Other functional APIs (e.g. softmax)\r\n  * ...\r\n\r\n  Note that we could include any utilities that may not depend on DGL. They could be evaluation metrics, loss, score or any functions that are common and useful. However, they are still in `dgl.nn` namespace.\r\n(3) Curate more datasets. The question here is whether we are confident that our data format is able to cover all of them. @VoVAllen may have more opinions on this. Otherwise, we will continue the current practice. If using raw dataset, we could directly download it from the official site and construct graphs online. Otherwise, we may need to preprocess the data to generate graphs and store it in our own data format.\r\n(4) Reorg the examples by applications:\r\n  * Community detection\r\n  * Recommender system\r\n  * Graph classification\r\n  * Network embedding\r\n  * ...\r\n\r\nSuggestion from @classicsong: It's better that we could have a unified entry point of each. For example:\r\n```bash\r\npython examples/recsys/train.py --dataset=movielens100k --model=gcmc\r\n```\r\nThis allows the users to easily compare baselines.\r\n\r\nFinally, it is a good time to finally refactor and write more docstrings for these modules. We could also take this chance to enable lint check on `dgl.data` module and move sampling routines to DGL main packages.\r\n\r\nCheck List\r\n---\r\n@mufeili @VoVAllen @yzh119 @zheng-da and anyone who are involved. Please directly edit this post to add items. We could estimate the workload from this.\r\n\r\n**Model Zoo**\r\n\r\nGraph convolution (`dgl.nn.<backend>.conv.py`)\r\n- [ ] RGCN (PR #744 )\r\n- [ ] GraphSAGE (PR #748 )\r\n- [ ] GAT\r\n- [ ] GGNN (PR #748 )\r\n- [ ] ChebyNet (PR #748 )\r\n- [ ] GIN (PR #748 )\r\n- [ ] SGC (PR #748 )\r\n\r\nnode-level classification/regression\r\nTBD\r\n\r\nLink prediction\r\n- [ ] Bilinear decoder\r\n- [ ] Distmult\r\n\r\nGraph generation\r\n- [ ] DGMGDecoder (?)\r\n\r\n`loss.py`\r\nTBD\r\n\r\n`metrics.py`\r\nTBD\r\n\r\nFunctional APIs (`dgl.nn.functional`)\r\nTBD\r\n\r\n**Dataset curation**\r\nCommunity detection\r\n- [ ] TBD\r\n\r\nGraph classification\r\n- [ ] TBD\r\n\r\nRecommender system\r\n- [ ] MovieLens\r\n\r\nNetwork embedding\r\n- [ ] TBD\r\n\r\n**Example reorg**\r\nCommunity detection\r\n- [ ] \r\n\r\nGraph classification\r\n- [ ]\r\n\r\nRecommender system\r\n- [ ]\r\n\r\nNetwork embedding\r\n- [ ] Node2vec\r\n- [ ] Metapath2vec\r\n- [ ] DeepWalk\r\n- [ ] [Poincare](https://arxiv.org/pdf/1705.08039.pdf)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Not able to use helm install\n\nHI,\r\n\r\nIm trying to use the helm chart to install unleash on K8S\r\n(I have running cluster) with the following steps:\r\n\r\n1.  clone the repo\r\n2. cd unleash-helm\r\n3. helm install .\r\n\r\nthe 3 command return error: \r\nError: release flippant-heron failed: Service \"flippant-heron-postgresql\" is invalid: spec.clusterIP: Invalid value: \"10.96.0.2\": provided IP is not in the valid range. The range of valid IPs is 100.64.0.0/13\r\n any idea how to overcome this?  why I need the cluster IP and if I can remove it from the values.yaml","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Document stream_iteration","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"What's the state of Animated Markers?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add contributing guidelines","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update README bootstrap logs image.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"suggestion for readme.md","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Francescos Creatures and Items V5 - Notes & Testing\n\n[Francescos Creatures and Items - V5](https://www.nexusmods.com/oblivion/mods/40190)\r\n\r\n**Source notes**\r\nNo up to date readme.\r\nWizard installer\r\n\r\n**Requirements**\r\n- Oblivion version 1.2.0416\r\n- OBSE\r\n\r\n**Compatibility**\r\n- Incompatible with Oscuro's Oblivion Overhaul. In order for both to work together an FCOM installation is required too.\r\n- If used with TIE, the TIE Frans Patch included in the TIE archive must be used, in addition to using a bashed patch.\r\n- MMM is incompatible with\r\n  - `Francesco's Optional New Creatures Add-On.esm`\r\n  - `Francesco's More Wilderness Life.esp`\r\n  - `Francesco's Optional Leveled Guards.esp`\r\n  - `Francesco's Optional New Adventurers.esp`\r\n  - `Francesco''s Optional Chance of More Enemies.esp`\r\n- FCOM is incompatible with\r\n  - `Francesco's Optional New Creatures Add-On.esm`\r\n  - `Francesco's More Wilderness Life.esp`\r\n  - `Francesco's Optional Dungeon Chest Loot.esp`\r\n  - `Francesco's Optional Dungeon Chest Locks.esp`\r\n  - `Francesco's Optional House Chest Loot.esp`\r\n  - `Francesco's Optional Leveled Arena.esp`\r\n  - `Francesco's Optional Leveled Quests.esp`\r\n  - `Francesco's Optional New Adventurers.esp`\r\n  - `Francesco's Optional Vendor Tweaks.esp`\r\n\r\n**Includes**\r\n- An older version of (MOBS)[Medieval Oblivion Equipment Balance System](https://www.nexusmods.com/oblivion/mods/28537). It should still be used as it includes changes for Frans.\r\n- [Lyrondor Combat Behavior](https://www.nexusmods.com/oblivion/mods/2073/).\r\n\r\n---\r\n\r\nChanges to make based on notes.\r\n\r\n- [ ] Update [Cleaning info](https://github.com/loot/oblivion/issues/51#issuecomment-518071582)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add integration test use case to Examples section in README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Issue parsing 'Returns' in description","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Documentation does not explain how to select a style","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Docs say \"You can also add more storage to the thin pool.\" without specifying how","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Readme Documentation needs to be Updated\n\nUpdate the readme.md","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Rethink what to show on the select screen when the verse is blank","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add Workspace Items optional methods to documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update Networking Docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"the example /bin/pretrained segfaults","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Return reference to self?\n\nIs it currently possible to return a reference to self as a PyResult? Currently I can return a struct with a PyResult, but get an error when trying to return a reference.\r\n\r\n```\r\n#[pyclass]\r\n#[derive(Clone, Copy)]\r\nstruct Test {}\r\n\r\n#[pymethods]\r\nimpl Test {\r\n    fn test_self(self) -> PyResult<Test> {\r\n        Ok(self)\r\n    }\r\n\r\n    fn test_self_reference(&self) -> PyResult<&Test> {\r\n        Ok(self)\r\n    }\r\n\r\n    fn test_self_mut_reference(&mut self) -> PyResult<&mut Test> {\r\n        Ok(self)\r\n    }\r\n}\r\n\r\nerror[E0277]: the trait bound `std::result::Result<&Test, pyo3::err::PyErr>: pyo3::derive_utils::IntoPyResult<_>` is not satisfied\r\n  --> src\\lib.rs:21:1\r\n   |\r\n21 | #[pymethods]\r\n   | ^^^^^^^^^^^^ the trait `pyo3::derive_utils::IntoPyResult<_>` is not implemented for `std::result::Result<&Test, pyo3::err::PyErr>`\r\n\r\nerror[E0277]: the trait bound `std::result::Result<&mut Test, pyo3::err::PyErr>: pyo3::derive_utils::IntoPyResult<_>` is not satisfied\r\n  --> src\\lib.rs:21:1\r\n   |\r\n21 | #[pymethods]\r\n   | ^^^^^^^^^^^^ the trait `pyo3::derive_utils::IntoPyResult<_>` is not implemented for `std::result::Result<&mut Test, pyo3::err::PyErr>`\r\n```\r\n\r\nI was able to find the source code for it here https://github.com/PyO3/pyo3/blob/master/src/derive_utils.rs, but didn't see any documentation related to it. Is it currently possible to return a reference to self? Returning a struct works when it derives Clone and Copy, but is it possible to return a reference for structs that contain fields that don't derive from Clone/Copy? Any information would be greatly appreciated.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Error: unknown command \"push\" for \"pouch\"\n\nI have installed pouch following the README doc.\r\nBut when I do pouch push , it gives me this error \"Error: unknown command \"push\" for \"pouch\"\". The other command, such as pouch pull and pouch ps, works fine.\r\nThe pouch version:\r\nroot@test-pod3-spp22:/# pouch version\r\nGoVersion:       go1.10.4\r\nKernelVersion:   3.10.0-327.ali2012.alios7.x86_64\r\nOs:              linux\r\nVersion:         1.3.0\r\nAPIVersion:      1.24\r\nArch:            amd64\r\nBuildTime:       2019-05-22T11:41:19+08:00\r\nGitCommit:       rpm-1.0.0.21\r\n\r\nCould you help me to solve this, please ?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"ReferenceError: regeneratorRuntime is not defined with Create React App","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Default documentation page is broken\n\nLink is broken - probably redirect issue at front door/cdn level:\r\n\r\n[home](http://www.typescriptlang.org/docs/home.html)\r\n\r\nResult: \r\nThe resource you are looking for has been removed, had its name changed, or is temporarily unavailable.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update Autoscaling Docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"[PRE REVIEW]: Lcopt - An interactive tool for creating fully parameterised Life Cycle Assessment (LCA) foreground models","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Adding a feature\n\n## Release management\n\nAs you prepare for a future release, you'll need to organize more than the tasks and features. It's important to create a clear workflow for your team, and to make sure that the work remains organized.\n\nThere are several strategies for managing releases. Some teams might use long-lived branches, like `production`, `dev`, and `master`. Some teams use simple feature branches, releasing from the master branch.\n\nNo one strategy is better than another. We always recommend being intentional about branches and reducing long-lived branches whenever possible.\n\nIn this exercise, you'll use the `release-v1.0` branch to be your one long-lived branch per release version.\n\n## Protected branches\n\nLike the `master` branch, you can protect release branches. This means you can protect branches from force pushes or accidental deletion. This is already configured in this repository.\n\n## Add a feature\n\nReleases are usually made of many smaller changes.  This is a practice repository, but we will still make at least two feature adjustments.\n\nSince we don't know of any bugs, we'll focus on a few features to update on our game before the version update.\n\n- You should update the README.md to point to the correct game URL\n- I'll help you change the text colors to green\n\n## Step 4: Add a new feature on the release branch\n\nFirst, update the URL in your README.md.\n\nUsing the GitHub flow, make your update, and open a pull request with `release-v1.0` as your base branch.\n\n### :keyboard: Activity: Update the README.md\n\n1. Create a new branch and change the URL in the `README.md` to point to your own GitHub Pages site.\n2. Open a pull request with `release-v1.0` as the `base` branch, and your new branch as `compare`.\n3. Fill in the pull request template to describe your changes.\n4. Add the pull request to the project board, using the **Projects** section on the right side of the pull request.\n\n<hr>\n<h3 align=\"center\">I'll respond in your pull request with the next step.</h3>\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"QUIC Websockets","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"SUMMARY","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Unknown Python Version Error\n\nI tried to install the package `requests` via micropip, as described/shown [in the docs.](https://github.com/iodide-project/pyodide/blob/master/docs/pypi.md)\r\nMWE:\r\nMy code snippet in Pyodide looks like: \r\n```\r\n%% py\r\nimport micropip\r\nmicropip.install('requests')\r\n```\r\n\r\nWhen I run it, I get the following console output and error: \r\n```\r\nimport micropip\r\nmicropip.install('requests')\r\n\r\n\"unknown variable: python_version\"\r\n```\r\n\r\n[requests](https://2.python-requests.org/en/master/) is a popular package that's entirely written in Python, so i don't think it has to do with trying to load a package that is written in multiple non-Python languages.\r\n\r\nIdeas? Suggestions?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Add methods documentations\n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Further Documentation\n\n@majeek Thank you for your hard work,\r\n\r\nCan you post documentation on how to use.\r\n\r\nAlso can you post the `environment.yml` file, or the requirement.txt, by running:\r\n`conda env export > environment.yml`\r\n`pip freeze > requirements.txt`\r\n\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# (Possibly) inaccurate \"returns\" for when creating multiple datapoints\n\nWhen a client POSTs datapoints to the API (using `https://www.beeminder.com/api/v1/users/me/goals/SLUG/datapoints/create_all.json`), the response appears to be an array of the created datapoints which were submitted. This was surprising as the documentation suggests this would have been \"the last created datapoint\" rather than what actually is, what is - IMO - an intuitive response with all of the involved datapoints.\r\n\r\nhttps://github.com/beeminder/apidocs/blob/9f4a69041f60d4ec43b8214904499adb0b6b1b23/source/index.html.md#L984-L986\r\n\r\nWhich shape is expected to be returned?\r\n\r\nP.S. I'm combing through these pages while working on an API client, happy to drop issues as they crop up or open a pull request if that's preferred!","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"searching for 'm', table, BRAF associations...","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Firebase FacebookAuthProvider class not found (in same function GoogleAuthProvider works \ud83d\udc4c)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"build fails with gcc 6.2","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Don't understand how to install plugins\n\nI may be an idiot but I don't understand how to install plugins, the README says \"Install/Uninstall plugin: type `wpm install/uninstall`\" but I don't understand, do I type `Install (Name of Plugin)`? or do I type `wpm install (Name of Plugin)`? How does it work? Sorry for bothering you.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Update Volumes Docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Invalid acr task list-runs sample code\n\n\"az acr task list runs --name mytask --registry myregistry --output table\" should be \"az acr task list-runs --name mytask --registry myregistry --output table\"\n\n\n---\n#### Document Details\n\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\n\n* ID: 7e863c45-bc89-0762-7bc1-525c122cf6ec\n* Version Independent ID: 3937ce4a-4428-bcfc-7ea7-760705947409\n* Content: [Schedule Azure Container Registry tasks](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-tasks-scheduled#feedback)\n* Content Source: [articles/container-registry/container-registry-tasks-scheduled.md](https://github.com/Microsoft/azure-docs/blob/master/articles/container-registry/container-registry-tasks-scheduled.md)\n* Service: **container-registry**\n* GitHub Login: @dlepow\n* Microsoft Alias: **danlep**","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Documentation template","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# --tmpfs defaults are not compatible with docker\n\n/kind bug\r\n\r\nThe `--tmpfs` option (and probably `--mount` too) defaults to 64MB of space, vs docker's default size is unlimited according to [this documentation](https://docs.docker.com/storage/tmpfs/#tmpfs-options) of `tmpfs-size`.\r\n\r\nIn addition, Docker's `--tmpfs` doesn't allow any options, but podman's has several. I'm not too concerned about this one though since the tmpfs syntax for podman is a superset of Docker's.\r\n\r\n**Output of `podman version`:**\r\n\r\n```\r\npodman version 1.4.4\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"hi","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# [firebase_performance] HttpMetric PayloadSize field can throw a NullPointerException\n\nWhen following the example for \"Adding monitoring for network requests\" on the plugin Readme page (https://pub.dev/packages/firebase_performance), a uncaught java.lang.NullPointerException can be thrown when responsePayloadSize or requestPayloadSize are given a null value. \r\n\r\nThis should be handled, as sometimes these values aren't available (especially in the case of streamed responses). ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Create a wiki to improve documentation\n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Add user tracking to dB docs and expose them to users\n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Would be great to add an example of custom implementation for Mongo","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# MSB4062 when running build on Azure DevOps Hosted Ubuntu 16.04\n\n<!-- PLEASE GIVE YOUR ISSUE A SENSIBLE NAME. This makes it easier to identify issues at a glance -->\r\n\r\n/home/vsts/.nuget/packages/specflow.tools.msbuild.generation/3.1.21-beta/build/SpecFlow.Tools.MsBuild.Generation.targets(78,5): error MSB4062: The \"SpecFlow.Tools.MsBuild.Generation.GenerateFeatureFileCodeBehindTask\" task could not be loaded from the assembly /home/vsts/.nuget/packages/specflow.tools.msbuild.generation/3.1.21-beta/build/../tasks/netcoreapp2.0/SpecFlow.Tools.MsBuild.Generation.dll. Assembly with same name is already loaded Confirm that the <UsingTask> declaration is correct, that the assembly and all its dependencies are available, and that the task contains a public class that implements Microsoft.Build.Framework.ITask. \r\n\r\n<!-- PLEASE CHECK THE OPTIONS THAT APPLY TO YOU BY ADDING AN 'x' TO THE CORRESPONDING CHECKBOX ('[ ]') -->\r\n### SpecFlow Version:\r\n- [X ] 3.0\r\n- [ ] 2.4\r\n- [ ] 2.3\r\n- [ ]\t2.2\r\n- [ ]\t2.1\r\n- [ ]\t2.0\r\n- [ ]\t1.9\r\n \r\n### Used Test Runner \r\n- [ ] SpecFlow+Runner\r\n- [ X]\tMSTest \r\n- [ ]\tNUnit\r\n- [ ]\tXunit\r\n\r\n<!-- PLEASE INCLUDE THE VERSION NUMBER OF YOUR TEST RUNNER -->\r\nVersion number:\r\n==============================================================================\r\nTask         : .NET Core\r\nDescription  : Build, test, package, or publish a dotnet application, or run a custom dotnet command\r\nVersion      : 2.156.1\r\nAuthor       : Microsoft Corporation\r\nHelp         : https://docs.microsoft.com/azure/devops/pipelines/tasks/build/dotnet-core-cli\r\n==============================================================================\r\n\r\n### Project Format of the SpecFlow project\r\n- [ ] Classic project format using `packages.config`\r\n- [ ] Classic project format using `<PackageReference>` tags\r\n- [ ] Sdk-style project format\r\n\r\n### .feature.cs files are generated using\r\n- [X ] `SpecFlow.Tools.MsBuild.Generation` NuGet package\r\n- [ ] `SpecFlowSingleFileGenerator` custom tool\r\n\r\n### Visual Studio Version\r\n- [ ] VS 2019\r\n- [ ]\tVS 2017\r\n- [ ]\tVS 2015\r\n- [X] NA\r\n\r\n### `Enable SpecFlowSingleFileGenerator Custom Tool` option in Visual Studio extension settings\r\n- [ ] Enabled\r\n- [ X] Disabled\r\n\r\n### Are the latest Visual Studio updates installed?\r\n- [X ]\tYes\r\n- [ ]\tNo, I use Visual Studio version `<Major>.<Minor>.<Patch>` <!-- e.g. 16.1.0 -->\r\n \r\n### .NET Framework:\r\n- [ ]\t>= .NET 4.5\r\n- [ ]\tbefore .NET 4.5\r\n- [ X] .NET Core 2.0\r\n- [ ] .NET Core 2.1\r\n- [ ] .NET Core 2.2\r\n- [ ] .NET Core 3.0\r\n\r\n### Test Execution Method:\r\n- [ ]\tVisual Studio Test Explorer\r\n- [ ]\tTFS/VSTS/Azure DevOps \u2013 Task \u2013 PLEASE SPECIFY THE NAME OF THE TASK\r\n- [X ]\tCommand line \u2013 PLEASE SPECIFY THE FULL COMMAND LINE\r\n[command]/opt/hostedtoolcache/dncs/2.2.103/x64/dotnet test /home/vsts/work/1/s/Landorphan.Ioc.ServiceLocation.XPlat.sln --logger trx --results-directory /home/vsts/work/_temp\r\n \r\n\r\n### &lt;SpecFlow> Section in app.config or content of specflow.json\r\n<!-- PLEASE COPY THE ENTIRE <SpecFlow> SECTION IN YOUR .config FILE or THE ENTRIE specflow.json AND PASTE IT BETWEEN THE TWO CODE MARKERS (```) BELOW -->\r\n```\r\nN/A\r\n```\r\n\r\n### Repro Project\r\n<!-- PLEASE INCLUDE A LINK TO A PROJECT THAT DEMONSTRATES THE ISSUE YOU ARE REPORTING, IF POSSIBLE \r\nFor information on how to include a useful repro, refer to https://stackoverflow.com/help/mcve\r\n-->\r\nSource: https://github.com/landorphan/service-location/tree/tistocks-Instrumentation-NextSteps\r\nBuild Pipeline Result: https://dev.azure.com/landorphan/Service-Location/_build/results?buildId=759\r\n\r\n### Issue Description\r\n<!-- PLEASE PROVIDE AS MUCH INFORMATION AS POSSIBLE ON THE ISSUE -->\r\n\r\n### Steps to Reproduce\r\n<!-- PLEASE DESCRIBE THE STEPS REQUIRED TO REPRODUCE THIS ISSUE, IF POSSIBLE -->\r\n\r\nrun dotnet test with project specified off of the prescribed branch on Azure DevOps hosted Ubuntu 16.04 build agent. ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"provided solution doesn't match instructions - all in one file","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Check TsnE docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"handle third-party credits and report on server","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Inconsistency with the sample code and the explanation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Run your first Python program\n\nNow you're ready to start coding. Let's get familiar with the files in our repo:\n\n- `README.md`: a markdown introduction to this project\n- `get-quote.py`: the file where we'll write our Python code\n- `quotes.txt`: a text file with a list of quotes\n\nOpen up `get-quote.py` and comment out line 2 by removing the `#` from the beginning of the line.\n\nNow let's try running that Python script. From the command line, type: `python get-quote.py`\n\nYou should see our first quote, the one hard-coded into line 2, printed out in your terminal:\n`Keep it logically awesome.`\n\n## Push your changes\n\nYou've edited your local code, so you have a more recent version than is stored in this repository. You can check that any time by running: `git status`\n\nIt should show one file modified. Every time we want to send our local changes to GitHub, we need to perform three steps:\n\n1. Add the file(s) with changes: `git add get-quote.py`\n2. Commit the changes: `git commit -m \"Hello World\"`\n3. Push the changes: `git push`\n\nOnce you've completed these steps, we'll write some more Python.\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"has_any_role() should take an array of some kind","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Building a new website + docs\n\nAs mentioned on Gitter, let's brainstorm about a better way to build a website and docs for SVG.js. I'll do the hard part, but I want it to be easier to maintain than what we have now. ","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Readme file should be styled as Markdown","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# substantial and significant security issues with current \"bearer token\" scheme\n\nas i mentioned [on the mailing list on july 12](https://lists.w3.org/Archives/Public/public-solid/2019Jul/0003.html), i believe there are substantial and significant security issues with the currently implemented (with documentation [waiting to be merged](https://github.com/solid/webid-oidc-spec/pull/27)) Proof-of-Possession \"bearer token\" authorization scheme.  the most important issues are:\r\n\r\n* the client creates and issues \"bearer tokens\" with no input from the resource server (or its authorization infrastructure). in general, the client has no standing in the OAuth model to create or issue an access token. this is incompatible with the kinds of OAuth infrastructure likely to be deployed in enterprises.\r\n* there\u2019s no reasonable way for the resource server (or its authorization infrastructure) to revoke one of these tokens.\r\n* the validity period (nbf, exp) is solely under control of the webid\u2019s OIDC Issuer and the client/app, another aspect over which those parties don\u2019t have standing. the resource+authorization server is the only party with standing to specify the validity period of its access tokens, which might be shorter or longer than the validity period in any identity proof provided by the client.\r\n* the format of the bearer token is mandated, rather than being up to the resource and authorization servers. this makes it potentially incompatible (or at least non-optimal) with the kinds of OAuth infrastructure likely to be deployed in enterprises.\r\n* there\u2019s no provision for multiple [protection spaces (realms)](https://tools.ietf.org/html/rfc7235#section-2.2) with different security policies at the same origin.\r\n* there\u2019s no way for the resource server to force a current/timely proof of possession of the confirmation key.\r\n* (related) there\u2019s no way for the resource server to directly cryptographically challenge the client (for example, with a salt/nonce).\r\n\r\nalso, these proof tokens are necessarily big and must be passed around on every request. HTTP/2 header compression might mitigate that somewhat over the network between a client and a server (or at least a reverse proxy or application gateway), but at some point in the processing chain a multi-K blob of bytes needs to be processed on every request.\r\n\r\nsome time ago i [proposed](https://github.com/solid/webid-oidc-spec/issues/25) an [alternative authorization method](https://github.com/zenomt/webid-auth-protocol) that addresses the above concerns.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"contains function breaks if item in list starts with a dash","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Hello World | Myblog\n\nhttps://zhgetyou.github.io/2019/08/10/hello-world/#more \n\n Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Lighttpd does not start in container\n\n<!-- Provide a general summary of the issue in the Title above -->\r\n<!-- Note: these are comments that don't show up in the actual issue, no need to delete them as you fill out the template -->\r\n\r\nThis is a... <!-- To choose ONE, put an [x] in the box that applies -->\r\n\r\n- [ ] Request for a new or modified feature\r\n- [x] Issue trying to run the docker image\r\n- [ ] Issue trying to build / test / develop the docker image\r\n\r\n## Description\r\n<!-- Provide a more detailed introduction to the issue or feature -->\r\nWhen starting the container, container gets stuck attempting to start `lighttpd -D -f /etc/lighttpd/lighttpd.conf` over and over again.\r\n\r\n## Expected Behavior\r\n<!-- Tell us what should happen -->\r\nlighttpd should start and web server becomes available\r\n\r\n## Actual Behavior\r\n<!-- Tell us what happens instead -->\r\nLogs from issue (docker logs pihole): https://pastebin.com/Vu069ZdH\r\n\r\n## Possible Fix\r\n<!-- Not obligatory, but suggest a fix or reason for the bug -->\r\n\r\n## Steps to Reproduce and debugging done\r\n<!-- Reproduce this bug. Include code to reproduce, if relevant -->\r\ne.g. your docker run command, pages to visit, CLI commands you ran\r\n1. Clean any existing container with `docker rm pihole`\r\n2. Clean any existing image with `docker rmi pihole/pihole`\r\n3. Run container with `docker run -d --name pihole -p 53:53/tcp -p 53:53/udp -p 81:80 -e TZ=\"America/Chicago\" -v \"$(pwd)/etc-pihole/:/etc/pihole/\" -v \"$(pwd)/etc-dnsmasq.d/:/etc/dnsmasq.d/\" --dns=127.0.0.1 --dns=1.1.1.1 --restart=unless-stopped pihole/pihole:latest`\r\n4. Attempt to start lighttpd manually (same result) with `docker exec -it pihole lighttpd -D -f /etc/lighttpd/lighttpd.con`\r\n\r\n## Debug steps I have tried\r\n<!-- Please attempt these debug steps to see if it helps you resolve or understand your own issue -->\r\n\r\n- [x] I have tried destroying my container instance, pulling the newest image version, and re-creating a new container\r\n- [x] I have tried running the nearly stock `docker run` example in the readme (removing any customizations I added)\r\n- [x] I have tried running without my volume data mounts to eliminate volumes as the cause\r\n- [x] I have searched this repository for existing issues and pull requests that look similar, none found regarding this message\r\n\r\nI have tried entering the container and running apt-get update/apt-get upgrade, tried enabling/disabling lighttpd modules.\r\n\r\n## Context and extra information\r\nHad run this container previously on centos host, but host has been reinstalled with openSUSE tumbleweed. Other containers I run seem unaffected.\r\n\r\n<!-- How has this bug affected you? What were you trying to accomplish? -->\r\n<!-- Got any other relevant links to similar issues? -->\r\n\r\n## Your Environment \r\n<!--- Include as many relevant details about the environment you experienced the bug in -->\r\n* Docker Host Operating System and OS Version: openSUSE Tumbleweed 20190806\r\n* Docker Version: 19.03.1, build 74b1e89e8ac6\r\n* Hardware architecture: amd64\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"how it works, please help","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"rollaxis is weird","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Add documentation to do homebrew ports.\n\nHi, I'm opening this issue to talk about the need for a documentation about porting your godot game as homebrew to consoles, maybe retro consoles.\r\n\r\nI would love to port my game to retro consoles and emulators, but It seems godot can't easily add exporting templates to such consoles because of licencing issues, I was wondering how legal would be to easily let the users do the porting themselves and publish the binaries on the web for easy install on users.\r\n\r\nMaybe the documentation should have a part about this topic.\r\nI'm not talking about current generation consoles, but homebrew ports on the Wii or PS3 or DS.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"File variable not assigned","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Anti-formatting blocks/regions\n\n**Is your feature request related to a problem? Please describe.**\r\nQuite often, I need to add snippets of minified code from third parties for things like analytics, error reporting, etc. It's quite annoying having this minified, obfuscated rubbish clutter up 384 lines when I'm never going to have to do anything with it\r\n\r\n**Describe the solution you'd like**\r\nWhat I'd like to do is have a special piece of text that could be put in a comment to prevent formatting in that region.\r\n\r\n**Describe alternatives you've considered**\r\nI've thought about putting these minified code sections into a separate file, but I think that isn't great. Sometimes, splitting up sections of code from each other is a good idea but often these small pieces of code are designed to be loaded ASAP. In HTML, by being delivered with the rest of the page, it cuts down on requests back to the server which takes extra time and resources in a browser. Repeating these requests for thousands of clients and for tens or hundreds of files (if you're insane) just gets ridiculous.\r\n\r\nI'm aware that VS Code may not support this. I am not totally sure about the way code formatting extensions work and whether they can fully access the content of a file (I'm assuming they do).\r\n\r\n**Example**\r\n\r\n```html\r\n<html>\r\n<head>\r\n    <!--#prettier-no-format-->\r\n    <script>\r\n         function f(){console.log(\"example code i never have to look at and shouldn't be formatted into a 3000000 line mess\");}\r\n    </script>\r\n    <!--#prettier-no-format-end-->\r\n</head>\r\n<body>\r\n    <h1>Hello world!</h1>\r\n</body>\r\n</html>\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Update Chinese README for #1010 (.name and .usage)\n\nI updated the README in #1010 which has been merged to the develop branch.\r\n\r\nI made the format changes in #1013 for the Chinese README but just copied the english text for the new section in the help.\r\n\r\nA Pull Request, or just a translation of that section, is welcome.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Failed building JavaScript bundle","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"React 16 beta","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# @react-native-community/eslint-config#overrides[2]: Environment key \"jest/globals\" is unknown\n\n### Problem\r\n\r\ni create a new project, use `npx react-native init  Demo` from  https://github.com/react-native-community/cli/blob/master/docs/init.md, and open js file, vs code show a tip as below.\r\n\r\n\r\nESLint: Demo/.eslintrc.js \u00bb @react-native-community/eslint-config#overrides[2]: Environment key \"jest/globals\" is unknown . Please see the 'ESLint' output channel for details.\r\n\r\nI want to upgrade eslint-plugin-config, but @react-native-community/eslint-config locked it.\r\n\r\n\r\n### React Native version:\r\n```\r\nreact-info\r\nSystem:\r\n    OS: macOS High Sierra 10.13.6\r\n    CPU: (8) x64 Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz\r\n    Memory: 3.31 GB / 16.00 GB\r\n    Shell: 5.3 - /bin/zsh\r\n  Binaries:\r\n    Node: 12.7.0 - ~/.nvm/versions/node/v12.7.0/bin/node\r\n    Yarn: 1.17.3 - ~/.nvm/versions/node/v12.7.0/bin/yarn\r\n    npm: 6.10.0 - ~/.nvm/versions/node/v12.7.0/bin/npm\r\n    Watchman: 4.9.0 - /usr/local/bin/watchman\r\n  SDKs:\r\n    iOS SDK:\r\n      Platforms: iOS 12.1, macOS 10.14, tvOS 12.1, watchOS 5.1\r\n    Android SDK:\r\n      API Levels: 25, 26, 27, 28\r\n      Build Tools: 25.0.2, 26.0.2, 27.0.3, 28.0.1, 28.0.3\r\n      System Images: android-19 | ARM EABI v7a, android-19 | Intel x86 Atom, android-19 | Google APIs Intel x86 Atom, android-22 | Google APIs Intel x86 Atom, android-23 | Google APIs Intel x86 Atom, android-26 | Google APIs Intel x86 Atom, android-28 | Google APIs Intel x86 Atom\r\n      Android NDK: 19.2.5345600\r\n  IDEs:\r\n    Android Studio: 3.4 AI-183.6156.11.34.5522156\r\n    Xcode: 10.1/10B61 - /usr/bin/xcodebuild\r\n  npmPackages:\r\n    react: 16.8.6 => 16.8.6\r\n    react-native: 0.60.4 => 0.60.4\r\n  npmGlobalPackages:\r\n    react-native-cli: 2.0.1\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Indendation rule bugged","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Make web pack compatible.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"504 Timeout but App Working, Just Slow","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Requires Node v8","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Function to config a mailbox only for receiving\n\n**Is your feature request related to a problem? Please describe.**\r\nNot really but maybe though. ;)\r\n\r\n**Describe the solution you'd like**\r\nI want a function to config a specific mailbox only for internal communication or just receiving only. The mailbox shall not be able to send in the internet or to other internal recipients.\r\n\r\nI googled and looked into the documentation but didn't find any useful informations.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Missing ruby version (2.0.0-p648) for xcode9 osx image","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Docker Hub does not have latest code from master in the head tag","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"7.x.3 Biomaterials migration","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"update readme","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"JIRA Server Test Connection fails ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Missing Guide for development setup on Windows","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Studio 7 beta release download link not present","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"GridLayers with tileSize of type Point are not supported","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# [MAINTENANCE] Pong tutorial mismatch with amethyst_cli\n\n## Description\r\n\r\nThe recommended approach inside of the Getting Started section of the book is to use amethyst_cli to create a project skeleton (https://book.amethyst.rs/stable/getting-started.html).  The later tutorials then build on this skeleton.  However, amethyst_cli now places display_config.ron into resources/display_config.ron instead of config/display_config.ron, so the tutorial code doesn't work without amending.\r\n\r\n## Reason\r\n\r\nIt's pretty trivial to notice and correct yourself, but also a simple change would eliminate the need.  I'm happy to PR the changes if someone more experienced can weigh in and tell me exactly which part of this actually needs changing.\r\n\r\n## Impact\r\n\r\nI don't see why it would, since it's just documentation?\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Incorrect Temperature Readings","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"win-simple with Domino on Windows","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Calling \"css\" with \"undefined\" results in unfriendly error","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Non-encoded $ref on https://swagger.io/docs/specification/using-ref/#escape\n\nOn https://swagger.io/docs/specification/using-ref/#escape, there's a section that says:\r\n\r\n```\r\nFor example, to refer to the path /blogs/{blog_id}/new~posts, you would use:\r\n\r\n$ref: '#/paths/~1blogs~1{blog_id}~1new~0posts'\r\n```\r\n\r\nThe `/` and `~` are encoded to `~1` and `~0` respectively. However, the curly braces around `blog_id` aren't percent-encoded (RFC3986), and this throws an error on `editor.swagger.io`:\r\n\r\n<img width=\"639\" alt=\"Screen Shot 2019-08-11 at 11 17 08\" src=\"https://user-images.githubusercontent.com/681190/62830265-9d490480-bc29-11e9-9a6b-b7d50793b709.png\">\r\n\r\nThe $ref should be `#/paths/~1blogs~1%7Bblog_id%7D~1new~0posts`\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"README should have overview of how algorithm works","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# There is no open SDK ?!\n\nHello.\r\nI have bought Flip because of \"Open SDK\", but there is no one. I just want to build my own xdevice.so for Linux and SteamVR. \r\nIs there any chance to get source code of xdevice?\r\nOr is there any tech documentation about communication with Flip (structures, protocols, etc) for writing my one driver?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"List of APIs to Implement?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# [ngrx] Documentation/unit tests: Swiss Components\n\nWrite unit tests and update all documentation for the components directory of the swiss module.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"question: installing development machine error","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# update README\n\nadd contribution guide to readme","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Translate /docs/concepts/configuration/overview/ in Korean\n\n**This is a Feature Request**\r\n\r\n<!-- Please only use this template for submitting feature/enhancement requests -->\r\n<!-- See https://kubernetes.io/docs/contribute/start/ for guidance on writing an actionable issue description. -->\r\n\r\n**What would you like to be added**\r\n<!-- Describe as precisely as possible how this feature/enhancement should work from the user perspective. What should be changed, etc. -->\r\nTranslate /docs/concepts/configuration/overview/ in Korean\r\n\r\n**Why is this needed**\r\nNo translation with /docs/concepts/configuration/overview/ in Korean\r\n\r\n**Comments**\r\n<!-- Any additional related comments that might help. Drawings/mockups would be extremely helpful (if required). -->\r\nPage to update : https://kubernetes.io/docs/concepts/configuration/overview/\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# README, add a readme\n\nPlease write some lines on how to use it with a demo screenshot. or a cli swag from ascimania ","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Update README\n\n**User Story**\r\n\r\n1. use safer set_password and unlock commands.\r\n\r\n2. Above \"FAQ\", the 3 links are broken.\r\n\r\n3. In FAQ, the answer to the question \"Is there a way to access methods which require login over HTTP\" is outdated. We now support Basic HTTP authentication, see https://github.com/bitshares/bitshares-core/pull/223.\r\n\r\n4. the link to \"type.hpp\" is broken, additionally, the code is less readable for answering the question due to #1506.\r\n\r\n**Impacts**\r\nDescribe which portion(s) of BitShares Core may be impacted by your request. Please tick at least one box.\r\n- [ ] API (the application programming interface)\r\n- [ ] Build (the build process or something prior to compiled code)\r\n- [ ] CLI (the command line wallet)\r\n- [ ] Deployment (the deployment process after building such as Docker, Travis, etc.)\r\n- [ ] DEX (the Decentralized EXchange, market engine, etc.)\r\n- [ ] P2P (the peer-to-peer network for transaction/block propagation)\r\n- [ ] Performance (system or user efficiency, etc.)\r\n- [ ] Protocol (the blockchain logic, consensus, validation, etc.)\r\n- [ ] Security (the security of system or user data, etc.)\r\n- [ ] UX (the User Experience)\r\n- [ ] Other (please add below)\r\n\r\n**Additional Context (optional)**\r\nAdd any other context about your request here.\r\n\r\n## CORE TEAM TASK LIST\r\n- [ ] Evaluate / Prioritize Feature Request\r\n- [ ] Refine User Stories / Requirements\r\n- [ ] Define Test Cases\r\n- [ ] Design / Develop Solution\r\n- [ ] Perform QA/Testing\r\n- [ ] Update Documentation\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Future direction of SoftFloat and its development model","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Kubelet ignoring --register-schedulable=false","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Implement MezaParser ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Not able to use a custom theme / docs unclear on how to do it.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Add support for initial table state (columns, filters, sorting) in grid properties","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"rowStyleClass in DataTable fires indefinitely","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"`.yaydoc.yml` in this repo still uses the old design","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Move webUI functions into a separate file.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Adjust readme about Capture","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# What does ECS stand for?\n\nIt would be nice to have it in the readme if it isn't already. I turned to google for search and it was difficult to learn about because the acronym has (for example) 192 definitions: https://acronyms.thefreedictionary.com/ECS","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Bogus keyword on crates.io","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"ECONNREFUSED","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"sysadm generate gigabytes of logs and causes system stalls","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Not able to run a new react-native project for ios","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"OracleConnection","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# OpenBSD build SIGBUS crash when walking around\n\n<!-- Please follow the template below -->\r\n\r\n# Describe the bug\r\n\r\nProcesses dies with SIGBUS on OpenBSD builds after walking around\r\n\r\n\r\n# Steps To Reproduce\r\n\r\n1. Be using OpenBSD/OpenBSD's malloc implementation\r\n2. Walk in a direction for 30 seconds to a minute\r\n\r\n\r\n# Expected behavior\r\n\r\nTo not crash :>\r\nOpenBSD's malloc implementation sets to top of each page to 0xdf after each free, which you can see in the trace below, this indicates something is being referenced after it was freed\r\n\r\nRelevant Issues:\r\nhttps://github.com/CleverRaven/Cataclysm-DDA/issues/21293\r\nhttps://github.com/CleverRaven/Cataclysm-DDA/pull/21549\r\n\r\n\r\n# Versions and configuration\r\n\r\n- OS: Unix (OpenBSD)\r\n    - OS Version: <unknown> (OpenBSD 6.5-current)\r\n- Game Version: 0.D [64-bit] (I'm on tag jenkins-b9446, not sure why it's reporting this)\r\n- Graphics Version: Tiles\r\n- Mods loaded: [\r\n    Dark Days Ahead [dda],\r\n    Mutant NPCs [mutant_npcs],\r\n    More Locations [more_locations]\r\n]\r\n\r\n<!-- Please complete the following information; you can now go to:\r\n    - \"Main menu (ESC) > Debug Menu > Info > Generate game report\" to generate this report.\r\n    - Please update your OS version with a more precise version. -->\r\n\r\n\r\n# Additional context\r\n\r\n```\r\nGNU gdb (GDB) 7.12.1\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\r\nand \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-unknown-openbsd6.5\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n<http://www.gnu.org/software/gdb/documentation/>.\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from cataclysm-tiles...done.\r\n[New process 402155]\r\nCore was generated by `cataclysm-tiles'.\r\nProgram terminated with signal SIGBUS, Bus error.\r\n#0  _libc_memcmp (s1=0xdfdfdfdfdfdfdfdf, s2=0x7f7ffffee9c1, n=<optimized out>) at /usr/src/lib/libc/string/memcmp.c:46\r\n46                              if (*p1++ != *p2++)\r\n(gdb) bt\r\n#0  _libc_memcmp (s1=0xdfdfdfdfdfdfdfdf, s2=0x7f7ffffee9c1, n=<optimized out>) at /usr/src/lib/libc/string/memcmp.c:46\r\n#1  0x0000092d8039cff0 in std::__1::char_traits<char>::compare (__s1=0xdfdfdfdfdfdfdfdf <error: Cannot access memory at address 0xdfdfdfdfdfdfdfdf>, __s2=<optimized out>, __n=<optimized out>) at /usr/include/c++/v1/__string:250\r\n#2  std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::compare<std::__1::basic_string_view<char, std::__1::char_traits<char> > > (this=<optimized out>, __t=...) at /usr/include/c++/v1/string:3693\r\n#3  std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::compare (this=<optimized out>, __str=...) at /usr/include/c++/v1/string:3709\r\n#4  std::__1::operator< <char, std::__1::char_traits<char>, std::__1::allocator<char> > (__lhs=..., __rhs=...) at /usr/include/c++/v1/string:3934\r\n#5  std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::operator() (__x=..., this=<optimized out>, __y=...) at /usr/include/c++/v1/__functional_base:55\r\n#6  std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>::operator() (__x=..., this=<optimized out>,\r\n    __y=...) at /usr/include/c++/v1/map:517\r\n#7  std::__1::__tree<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >::__lower_bound<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > (this=<optimized out>, __v=..., __root=0x92fc468ff80, __result=0x92d813123c0 <FILENAMES+8>) at /usr/include/c++/v1/__tree:2670\r\n#8  std::__1::__tree<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >::find<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > (this=<optimized out>, __v=...) at /usr/include/c++/v1/__tree:2599\r\n#9  0x0000092d804c39ac in std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >::find (this=0x92d813123b8 <FILENAMES>, __k=...) at /usr/include/c++/v1/map:1375\r\n#10 get_crash_log_file_name () at src/crash.cpp:232\r\n#11 log_crash (type=0x92d80024de5 \"Signal\", msg=0x92d8002011f \"SIGSEGV: Segmentation fault\") at src/crash.cpp:247\r\n#12 0x0000092d804c384a in signal_handler (sig=<optimized out>) at src/crash.cpp:291\r\n#13 0x0000092fade21005 in ?? ()\r\n#14 0x0000093067c08100 in ?? ()\r\n#15 0x0000000000000000 in ?? ()\r\n(gdb)\r\n```\r\n\r\n<!-- Crash: if your problem refers to a crash, please add the following files to the \"Additional Context\" paragraph:\r\n    - From the /config folder (you can zip them both together):\r\n        - crash.log file.\r\n        - debug.log file.\r\n    - Your save file (zipped)\r\n\r\n- note #1: you can drag and drop files in this issue post!\r\n- note #2: it is very important for us that you provide a save file in case of a crash. It really helps the developers\r\n    to reproduce the bug and fix it. If possible, try to provide a save file that occurs in the right conditions, just\r\n    before the crash happens. -->\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# upgrade dependencies to enable hardened runtime for easier install?\n\nGot the project to build locally \ud83c\udf89 \r\n\r\nI have an enhancement idea \ud83d\udca1 \r\n\r\nWe could upgrade the dependencies to enable hardened runtime.  If we do this, I think that it makes it easier for some users on the latest versions of MacOS to install Dozer.\r\n\r\nThis is what I see when I try to validate the build with Apple:\r\n![Screen Shot 2019-08-10 at 4 48 46 PM](https://user-images.githubusercontent.com/2119400/62827909-18111180-bb8f-11e9-8e2f-3bea887401af.png)\r\n\r\nI think that these are the dependencies that would need to be updated or configured to support this:\r\n\r\n- [ ] submit\r\n- [ ] uploadDYSM\r\n- [ ] Autoupdate.app (Sparkle)\r\n- [ ] fileop\r\n\r\n\r\n### research \r\n\r\nhttps://developer.apple.com/documentation/security/notarizing_your_app_before_distribution\r\n\r\nor alternately do some code-signing work-around like the one described here: https://github.com/insidegui/WWDC/issues/540#issuecomment-498483471\r\n\r\nmore discussion here: sparkle-project/Sparkle#1389","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# MaxAuthTries - Citation(s) for baseline choice.\n\nI'm new to Ansible and have got a lot of value from your ansible-ssh-hardening project, thanks!\r\n\r\nI did hit one snag with the MaxAuthTries setting of 2, compared to the default of 6. I actually managed to lock myself out of a host due to my ssh agent offering different keys before the correct one, causing a \"Too many authentication failures for XXX\" disconnection. After discovering the issue I wanted to understand from the baseline why this setting is chosen.\r\n\r\nI read the description for this control baseline and am struggling to see if changing this setting offers any tangible benefits for the increased risk of inconvenience (based on the fact the baseline already requires password login disabled).\r\n\r\nI wanted to offer a general observation here. The internet is full of varying quality guides for hardening SSH with very little reference to reputable STIG or other similar frameworks for secure configuration. I think the vision for this project is fantastic, it should streamline things for many people but I think it's important to track why baseline settings are chosen, citations for any particular attack vectors and noting some of the tradeoffs for the decision. Otherwise it feels like just an extension of \"cargo cult\" style blog posts where everyone is offering their chosen secure settings with little critical evaluation on why this setting was chosen.\r\n\r\nAre you able to provide some background on this setting?\r\n\r\nI'm happy to open a PR for the ansible-ssh-hardening to update the documentation/faq to flag this, unfortunately as Ansible uses SSH as the control channel it's particularly sensitive to these types of issues! ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"How can I get the raw body of a MimeMessage","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Possible casing issue for links to docs category pages","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Please add me for access to this repo - San Jose , CA","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Dates on Firefox Android seem not to work","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Logical file names","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Guest Users should be able to register for an account","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"add a readme file","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Choropleth Map","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# CVE-2018-19838 (Medium) detected in opennms-opennms-source-23.0.0-1\n\n## CVE-2018-19838 - Medium Severity Vulnerability\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Vulnerable Library - <b>opennmsopennms-source-23.0.0-1</b></p></summary>\n<p>\n\n<p>A Java based fault and performance management system</p>\n<p>Library home page: <a href=https://sourceforge.net/projects/opennms/>https://sourceforge.net/projects/opennms/</a></p>\n<p>Found in HEAD commit: <a href=\"https://github.com/mixcore/website/commit/eeefb98d520629c182c4d88691216d2bd738678a\">eeefb98d520629c182c4d88691216d2bd738678a</a></p>\n</p>\n</details>\n</p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Library Source Files (62)</summary>\n<p></p>\n<p> * The source files were matched to this source library based on a best effort match. Source libraries are selected from a list of probable public libraries.</p>\n<p>\n\n  - /website/docs/node_modules/node-sass/src/libsass/src/expand.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/expand.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/factory.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/boolean.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/util.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/value.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/emitter.hpp\n  - /website/docs/node_modules/node-sass/src/callback_bridge.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/file.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/operation.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/operators.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/constants.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/error_handling.hpp\n  - /website/docs/node_modules/node-sass/src/custom_importer_bridge.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/parser.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/constants.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/list.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/cssize.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/functions.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/util.cpp\n  - /website/docs/node_modules/node-sass/src/custom_function_bridge.cpp\n  - /website/docs/node_modules/node-sass/src/custom_importer_bridge.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/bind.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/eval.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/backtrace.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/extend.cpp\n  - /website/docs/node_modules/node-sass/src/sass_context_wrapper.h\n  - /website/docs/node_modules/node-sass/src/sass_types/sass_value_wrapper.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/error_handling.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/debugger.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/emitter.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/number.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/color.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_values.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/output.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/check_nesting.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/null.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast_def_macros.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/functions.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/cssize.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/prelexer.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_c.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_value.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast_fwd_decl.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/inspect.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/color.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/values.cpp\n  - /website/docs/node_modules/node-sass/src/sass_context_wrapper.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/list.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/check_nesting.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_value.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/context.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/string.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_context.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/prelexer.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/context.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/boolean.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/eval.cpp\n</p>\n</details>\n<p></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/medium_vul.png' width=19 height=20> Vulnerability Details</summary>\n<p>  \n  \nIn LibSass prior to 3.5.5, functions inside ast.cpp for IMPLEMENT_AST_OPERATORS expansion allow attackers to cause a denial-of-service resulting from stack consumption via a crafted sass file, as demonstrated by recursive calls involving clone(), cloneChildren(), and copy().\n\n<p>Publish Date: 2018-12-04\n<p>URL: <a href=https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-19838>CVE-2018-19838</a></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/cvss3.png' width=19 height=20> CVSS 3 Score Details (<b>6.5</b>)</summary>\n<p>\n\nBase Score Metrics:\n- Exploitability Metrics:\n  - Attack Vector: Network\n  - Attack Complexity: Low\n  - Privileges Required: None\n  - User Interaction: Required\n  - Scope: Unchanged\n- Impact Metrics:\n  - Confidentiality Impact: None\n  - Integrity Impact: None\n  - Availability Impact: High\n</p>\nFor more information on CVSS3 Scores, click <a href=\"https://www.first.org/cvss/calculator/3.0\">here</a>.\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/suggested_fix.png' width=19 height=20> Suggested Fix</summary>\n<p>\n\n<p>Type: Upgrade version</p>\n<p>Origin: <a href=\"https://github.com/sass/libsass/blob/3.6.0/src/ast.cpp\">https://github.com/sass/libsass/blob/3.6.0/src/ast.cpp</a></p>\n<p>Release Date: 2019-07-01</p>\n<p>Fix Resolution: 3.6.0</p>\n\n</p>\n</details>\n<p></p>\n\n***\nStep up your Open Source Security Game with WhiteSource [here](https://www.whitesourcesoftware.com/full_solution_bolt_github)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Font Awesome icons are screwed up","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Wrong readme instructions ","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"RStudio Feature Request: Cheatsheet please!","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Authentication issues with API\n\n#### Please confirm you have done the following before posting your bug report:\r\n\r\n- [ x] I have enabled debug mode \r\n- [ x] I have read [checked the Common Issues page](https://snipe-it.readme.io/docs/common-issues)\r\n\r\n**Describe the bug**\r\nCalls to the API return unauthorised error. I have generated a personal token as per the documentation and tried several different keys. I also tried creating from the command line. None seem to work.\r\n\r\n`{\r\n    \"error\": \"Unauthorized.\"\r\n}`\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\nNote - bearer token has been changed for security. \r\n\r\ncurl -X GET \\\r\n  https://snipeit.axiomit.com.au/api/v1/companies \\\r\n  -H 'Accept: application/json' \\\r\n  -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6ImNkNWU4MzQzNWNiZTEwMzQxZGQwZGQ3NmNiZjVmODY4YjQ3ZWYzNWU0Yjk1NmQ0M2MxYzZlZmU1NmU5ZGFiMGNiMWQ3NGExNDY2ZTg0NTZiIn0.eyJhdWQiOiIzIiwianRpIjoiY2Q1ZTgzNDM1Y2JlMTAzNDFkZDBkZDc2Y2JmNWY4NjhiNDdlZjM1ZTRiOTU2ZDQzYzFjNmVmZTU2ZTlkYWIwY2IxZDc0YTE0NjZlODQ1NmIiLCJpYXQiOjE1NjU1MDM3NDUsIm5iZiI6MTU2NTUwMzc0NSwiZXhwIjoxNTk3MTI2MTQ1LCJzdWIiOiIxIiwic2NvcGVzIjpbXX0.SlTsSAMenCirBv0pEXxCz1wISIGBzXT9MWnkR5jHk2XY3KQhwyIRyfyLHI64VuSWvdfWyKMm8sZuiDgL_b3JV5A9IZOKBq6eUjhNkEky0TQ8_dvYh3ACfZl38N1_WKROli65kCfuP2KTAQIna2exSKb6up8ATfnH0ErvPRiHiakjMeJMnP4fZnRXHHWjHIBPSEZJCr2BQRYcrVdgj06NX334x0UW7LDhWMxIZOC6E2TvjBhVgtfYqTC-DcvFSB0Gv-B-ZtvAFvJdu_4V8SHFi4FT9ccVjDhsxo6Dwrz4xH0YDltt_jti2BsKK-O2g2B5vm3F-PD9Udvo7OGRhhJRD3epaZP0ZTDXu6lGkmUW9omho6IOGdxVKt9nIfgLopvigDh2xrbG694Al3YfVQd94zMoFwvu91PjsgGKGvT62ngJjbQ9WjASFdFLzGE83nAeOwh5BKQaG4pWDrCFEUf581Dxn4kzTa2oKTVAFCc5yHNws6Di1TtcDSovYR5lwKKncHT9O9bvjdMxN0qAzTfiGWkTh3LNp-S17NLi_WxrMu1GmlmDN432vFtgjzt5BohNnm1drR85AkB2_1I5gQGbOdriv4nnfmhA6v1IsAAt2UvqdidF8bMUrlVRfAhENcZ-gNPJ177XkQ3_hOwp0EmQemr6c_RuuwRYpYoQtTG0c4' \\\r\n  -H 'Content-Type: application/json' \\\r\n\r\n\r\n**Expected behavior**\r\n\r\nI expect the API call to authorise and return relevant data.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Server (please complete the following information):**\r\n - Snipe-IT Version: v4.7.6 - build 4143 (master)\r\n - OS: CloudLinux\r\n - Web Server: Apache (WHM/cPanel)\r\n - PHP Version: 7.2\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: Windows 10\r\n - Browser N/A\r\n - Version N/A\r\n\r\n**Smartphone (please complete the following information):**\r\n - Device: [e.g. iPhone6]\r\n - OS: [e.g. iOS8.1]\r\n - Browser [e.g. stock browser, safari]\r\n - Version [e.g. 22]\r\n\r\n**Error Messages**\r\n- Include any additional information you can find in `storage/logs` and your webserver's logs.\r\nNo errors reported.\r\n\r\n**Additional context**\r\n- Is this a fresh install or an upgrade? Fresh\r\n- What OS and web server you're running Snipe-IT on: cPanel/CloudLinux\r\n- What method you used to install Snipe-IT (install.sh, manual installation, docker, etc): Git\r\n- Include what you've done so far in the installation, and if you got any error messages along the way: Everything else works prefectly\r\n- Indicate whether or not you've manually edited any data directly in the database: No\r\n\r\nAdd any other context about the problem here.\r\n\r\nEverything works well, just can't seem to get authorisation against hte API.\r\n\r\nPlease do not post an issue without answering the related questions above. If you have opened a different issue and already answered these questions, answer them again, once for every ticket. It will be next to impossible for us to help you.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# CherryPy and pytest fixtures in tests' class\n\n**I'm submitting a ...**\r\n- [X] bug report\r\n- [ ] feature request\r\n- [ ] question about the decisions made in the repository\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nI think is a sort of \"bug\", but I'm not sure to understand what's the intended behaviour.\r\n\r\n**What is the current behavior?**\r\nWhen I run a test method with pytest inside a test class to group different tests together, the test fails if a fixture is required by the test method (intended as a pytest fixture).\r\nIt seems that this is due to the helper.CPWebCase class, that for some reason tries to use unittest (even if the documentation tells to install pytest).\r\n\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a screenshots and logs of the problem. If you can, show us your code.**\r\n\r\nA minimal example to reproduce the problem:\r\n\r\n```\r\nimport pytest\r\nfrom cherrypy.test import helper\r\n\r\n@pytest.fixture\r\ndef foo():\r\n    return \"Ok!\"\r\n\r\nclass TestSample(helper.CPWebCase):\r\n\r\n    def test_sample(self, foo):\r\n        return foo is not None\r\n```\r\n\r\nIf you run the test with pytest you will get:\r\n`TypeError: test_sample() missing 1 required positional argument: 'foo'`\r\n\r\n**What is the expected behavior?**\r\nI would expect that if pytest is the suggested testing framework it will work as expected also with the helpers of CherryPy, so fixtures should be correctly injected in the test methods.\r\nOr, at least, the documentation should state somewhere that pytest is used for other purposes, but not all the features are supported in these cases. \r\n\r\n\r\n**Please tell us about your environment:**\r\n\r\n- Cheroot version: 6.5.5\r\n- CherryPy version: 18.1.2\r\n- Python version: 3.7.3\r\n- OS: Windows\r\n- Browser: not relevant.\r\n- pytest: 5.0.1","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Docsite is out of date, specifically section on looping over dicts","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Using ES6 imports, everything global under AWS namespace","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add support for cpus (Version 3 Resources Key)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Website URL is down","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# [Document] orm.Pagination Pagination not declared\n\nHi, when using https://github.com/go-pg/pg/wiki/Writing-Queries#pagination example, I found out orm.Pagination is gone. By checking the README.md, I figure out I think I should use https://godoc.org/github.com/go-pg/pg/urlvalues#NewPager instead. \r\n\r\n(1) The doc should be updated. \r\n(2) Can I have an example how to use this new Pagination way to do `?page=2&limit=50`? The old way looks pretty simple. I feel I have to create a Filter struct now. \r\n\r\nThanks a lot. ","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Documentation should indicate if function is sync or async","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Documentation page doesn't seem to work\n\nDocumentation page doesn't seem to work.\r\n`https://www.typescriptlang.org/docs/home.html` throws `The resource you are looking for has been removed, had its name changed, or is temporarily unavailable.`.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Missing File according to doc (tests/python/gpu/test_conv.py)","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Unexpected behavior using create-react-app ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Can't connect to torrent client qBitTorrent v3.3.14","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Readme.md","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Can't access scripts in v0.6.0-dev2","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Half empty debian","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# TODO List\n\n- [ ] Resource Reduced Model\r\n- [ ] Distribute Strategy\r\n- [ ] README for Korean\r\n- [ ] preprocessing with method1\r\n- [ ] add sample audio url","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Copilot support","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Create Compatibility with Object.fromEntries() with ES5\n\n<!-- \ud83d\udea8 STOP \ud83d\udea8 \ud835\udde6\ud835\udde7\ud835\udde2\ud835\udde3 \ud83d\udea8 \ud835\udc7a\ud835\udc7b\ud835\udc76\ud835\udc77 \ud83d\udea8\r\n\r\nHalf of all issues filed here are duplicates, answered in the FAQ, or not appropriate for the bug tracker. Please read the FAQ first, especially the \"Common Feature Requests\" section.\r\n\r\n-->\r\n\r\n## Search Terms\r\n\r\n<!-- List of keywords you searched for before creating this issue. Write them down here so that others can find this suggestion more easily -->\r\n\r\nObject.fromEntries()\r\n\r\n## Suggestion\r\n\r\n<!-- A summary of what you'd like to see added or changed -->\r\nI'd like to see `Object.fromEntries()` available to use as a function when compiling to the browser compatible ES5.\r\n\r\n## Use Cases\r\n\r\n<!--\r\nWhat do you want to use this for?\r\nWhat shortcomings exist with current approaches?\r\n-->\r\n\r\nUsing `Object.fromEntries()` when targeting ES5 alongside the friendly `Object.entries()`\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/fromEntries\r\n\r\n## Examples\r\n\r\n<!-- Show how this would be used and what the behavior would be -->\r\n\r\nHere is the polyfill from TC39 https://github.com/tc39/proposal-object-from-entries/blob/master/polyfill.js\r\n```js\r\n  \r\nfunction ObjectFromEntries(iter) {\r\n  const obj = {};\r\n\r\n  for (const pair of iter) {\r\n    if (Object(pair) !== pair) {\r\n      throw new TypeError('iterable for fromEntries should yield objects');\r\n    }\r\n\r\n    // Consistency with Map: contract is that entry has \"0\" and \"1\" keys, not\r\n    // that it is an array or iterable.\r\n\r\n    const { '0': key, '1': val } = pair;\r\n\r\n    Object.defineProperty(obj, key, {\r\n      configurable: true,\r\n      enumerable: true,\r\n      writable: true,\r\n      value: val,\r\n    });\r\n  }\r\n\r\n  return obj;\r\n}\r\n\r\n```\r\n\r\n## Checklist\r\n\r\nMy suggestion meets these guidelines:\r\n\r\n* [x] This wouldn't be a breaking change in existing TypeScript/JavaScript code\r\n* [x] This wouldn't change the runtime behavior of existing JavaScript code\r\n* [x] This could be implemented without emitting different JS based on the types of the expressions\r\n* [x] This isn't a runtime feature (e.g. library functionality, non-ECMAScript syntax with JavaScript output, etc.)\r\n* [x] This feature would agree with the rest of [TypeScript's Design Goals](https://github.com/Microsoft/TypeScript/wiki/TypeScript-Design-Goals).\r\n\r\n## My Questions\r\n+ Is this feature left out intentionally?\r\n+ A guide/where to look when contributing to adding a feature like this?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Consider a minor refactor of the Secrets API to be more pluggable\n\nWe could introduce a Secret base class that Prefect inherits from for it's secrets, and provide documentation about how to subclass for implementing other sensitive storage options.\r\n\r\nAs discussed [here](https://github.com/PrefectHQ/prefect/pull/1343/files#r312719069)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Documentation: Installation / Running","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"running yamp with docker","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Quick Install - Fails mounting BPF crio due to multiple mount points\n\n**General Information**\r\n\r\n- Cilium version (run `cilium version`)\r\n  - v1.6.90\r\n- Kernel version (run `uname -a`)\r\n  - 5.2.7-816.native\r\n- Orchestration system version in use (e.g. `kubectl version`, Mesos, ...)\r\n  - v1.15.2\r\n- Link to relevant artifacts (policies, deployments scripts, ...)\r\n  - https://raw.githubusercontent.com/cilium/cilium/master/install/kubernetes/quick-install.yaml\r\n- Upload a system dump (run `curl -sLO\r\nreleases.cilium.io/tools/cluster-diagnosis.zip &&\r\npython cluster-diagnosis.zip sysdump` and then attach the generated zip file)\r\n\r\n**How to reproduce the issue**\r\n\r\n1. Paso 1\r\n  - kubeadm init on master running on Clear Linux using crio\r\n2. Paso 2\r\n  - kubectl apply -f https://.../quick-install.yaml\r\n3. Paso 3\r\n  - Get the following error on the cilium pods:\r\n```\r\nlevel=info msg=\"Cilium 1.6.90 a96d7f4fe 2019-08-06T11:32:30-07:00 go version go1.12.7 linux/amd64\" subsys=daemon                                                                                                                    \r\nlevel=info msg=\"cilium-envoy  version: 2e42144f26667ddee9f5d2506019f16c57386b29/1.11.0-dev/Modified/RELEASE/BoringSSL\" subsys=daemon                                                                                                \r\nlevel=info msg=\"clang (7.0.0) and kernel (5.2.7) versions: OK!\" subsys=daemon                                                                                                                                                       \r\nlevel=info msg=\"linking environment: OK!\" subsys=daemon                                                                                                                                                                             \r\nlevel=info msg=\"bpf_requirements check: OK!\" subsys=daemon                                                                                                                                                                          \r\nlevel=info msg=\"Detected mounted BPF filesystem at /sys/fs/bpf\" subsys=bpf                                                                                                                                                          \r\nlevel=fatal msg=\"Unable to mount BPF filesystem\" error=\"multiple mount points detected at /sys/fs/bpf\" subsys=bpf\r\n```\r\nFYI - Deploying the old way works every time:\r\nkubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.6-backports-19-07-25/examples/kubernetes/1.15/cilium-crio.yaml\r\n\r\nFrom a quick look it seems that the crio specific deployment doesn't mount /sys/fs/bpf which looks to be the main issue.\r\n\r\nCheers","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Document rate limiting","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Instructions for installing MySQL sakila-schema fail","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Alertmanager's storage spec should reflect prometheus storage spec for Operator version v0.11.0","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Cannot find SocketIOClient on deployment to Heroku\n\nUpon deploying to Heroku, my build failed with the following message:  \r\n\r\n```\r\nremote:        lib/store/index.ts(31,18): error TS2503: Cannot find namespace 'SocketIOClient'.\r\nremote:        lib/store/index.ts(40,14): error TS2503: Cannot find namespace 'SocketIOClient'.\r\nremote:        error Command failed with exit code 2.\r\nremote:        info Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command.\r\nremote:        error Command failed with exit code 2.\r\nremote:        info Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command.\r\n```\r\nand Heroku rejected the build. I was able to solve this problem by manually moving my `node_modules/@types` folder to a local folder (in my case, `app/lib`) and redirecting `typeRoots` inside tsconfig towards the folder I moved it to, instead of node_modules. \r\n\r\nThis error should be reproducible by just taking a fresh copy of this repo, and following instructions to upload it to Heroku. I'm not exactly sure what the underlying problem is, as the app builds fine on my machine. Error occurs only upon deployment to Heroku.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"cmd/go: cannot build go binary on Windows","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Decide which tools to use for planning","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"WIKI Help Image","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# protoLoader.loadSync not finding proto file\n\nHi there, it appears that when executing the code from the readme the protoLoader module is not able to locate the `./protobufs/anki_vector/messaging/external_interface.proto` file.\r\n\r\nHere is the error message I receive:\r\n`Error: ENOENT: no such file or directory, open 'protobufs/anki_vector/messaging/external_interface.proto'`\r\n\r\nI forked the repo to see if I am able to come up with a solution.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"`composer create-project` fails with \"No such file or directory\"","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Make the extension Antora aware\n\nThe extension should automatically detect an Antora documentation component and resolve external resources (images, partials, examples...).\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Optimize nginx configuration for production based on Laravel documentation\n\nhttps://laravel.com/docs/5.8/deployment","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Project Setup Feedback\n\nYour README doesn't describe what your project is.  This is the first thing anyone (read: a potential employer) sees when they browse this project. For a first step, copy your project outline into the `README.md`.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Failure to build caffe","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Badge for readme files","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Add empty commit instructions to troubleshooting","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"issue creating multiple docker nodes with vmwarefusion driver","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"snap fails after \u00b4\u00b4main.go:220: WARNING: cannot create syslog logger","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# AcceptLoginRequest results in EOF\n\nWhen accepting a login request via hydra, the rest api/ go sdk responds with an Bad Request -> EOF.\r\n\r\nSteps to reproduce the behavior:\r\n\r\n<!--\r\n1. Run the docker compose\r\n2. Create an OAuth Client via command line (do it only once)\r\n3. Create an OAuth2 Token via command line (do it only once)\r\n4. Click the \"Authorize application\" Link\r\n5. Copy the login_challenge\r\n6. Paste into HTTP Request\r\n-->\r\n\r\n*Server response + logs*\r\n\r\nLogs:\r\n\r\n```\r\nhydra_1          | time=\"2019-08-11T09:18:17Z\" level=error msg=\"An error occurred while handling a request\" code=400 debug= details=\"map[]\" error=EOF reason= request-id= status= trace=\"Stack trace: \\ngithub.com/ory/hydra/consent.(*Handler).AcceptLoginRequest\\n\\t/go/src/github.com/ory/hydra/consent/handler.go:320\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v1.2.0/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1995\\ngithub.com/ory/hydra/x.RejectInsecureRequests.func1\\n\\t/go/src/github.com/ory/hydra/x/tls_termination.go:55\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/x/metricsx.(*Service).ServeHTTP\\n\\t/go/pkg/mod/github.com/ory/x@v0.0.64/metricsx/middleware.go:260\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2774\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1878\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1337\" writer=JSON\r\n```\r\n\r\nResponse\r\n```json\r\n{\r\n    \"error\": \"error\",\r\n    \"error_description\": \"The error is unrecognizable.\",\r\n    \"status_code\": 500,\r\n    \"error_debug\": \"EOF\",\r\n    \"request_id\": \"\"\r\n}\r\n```\r\n\r\n*Server configuration*\r\n\r\n```yml\r\nversion: \"3.7\"\r\nservices:\r\n  dbdev:\r\n    image: \"postgres:11\"\r\n    ports:\r\n      - \"5432:5432\"\r\n    environment:\r\n      - \"POSTGRES_PASSWORD=postgres\"\r\n      - \"POSTGRES_USER=postgres\"\r\n      - \"POSTGRES_DB=postgres\"\r\n  hydra:\r\n    image: \"oryd/hydra:v1.0.0\"\r\n    environment:\r\n      - \"URLS_SELF_ISSUER=http://localhost:4444\"\r\n      - \"URLS_CONSENT=http://localhost:4200/consent\"\r\n      - \"URLS_LOGIN=http://localhost:4200/login\"\r\n      - \"URLS_LOGOUT=http://localhost:4200/logout\"\r\n      - \"DSN=postgres://hola:hola@hydradb:5432/holadb?sslmode=disable\"\r\n      - \"SECRETS_SYSTEM=youReallyNeedToChangeThis\"\r\n      - \"OIDC_SUBJECT_TYPES_SUPPORTED=public,pairwise\"\r\n      - \"OIDC_SUBJECT_TYPE_PAIRWISE_SALT=youReallyNeedToChangeThis\"\r\n    ports:\r\n      - \"4444:4444\"\r\n      - \"4445:4445\"\r\n      - \"4446:4446\"\r\n      - \"5555:5555\"\r\n    command: serve all --dangerous-force-http\r\n    depends_on:\r\n      - hydra-migrate\r\n  hydradb:\r\n    image: \"postgres:11\"\r\n    environment:\r\n      - \"POSTGRES_PASSWORD=hola\"\r\n      - \"POSTGRES_USER=hola\"\r\n      - \"POSTGRES_DB=holadb\"\r\n    ports:\r\n      - \"5433:5432\"\r\n  hydra-migrate:\r\n    image: oryd/hydra:latest\r\n    environment:\r\n      - \"DSN=postgres://hola:hola@hydradb:5432/holadb?sslmode=disable\"\r\n    command:\r\n      migrate sql -e --yes\r\n    restart: on-failure\r\n```\r\n\r\n**Expected behavior**\r\n\r\nHydra sends the redirectTo Uri as response.\r\n\r\n**Environment**\r\n\r\n* Version: oryd/hydra:v1.0.0\r\n* Environment: MacOS, Docker Desktop 2.1.0.1, ...\r\n\r\n**Additional context**\r\n\r\nA example User Service / Identity Provider should be implemented. The Client sends its email and password, the service should mark the request as accepted via hydra.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Feature request: IPV6 Loadbalancing support","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Encryption at rest key rotation is not working","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"remark-iframes: incorrect docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Built with grunt","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Windows cannot verify the digital signature of the driver required for this device. A piece of software or hardware has recently changed, and a file with a wrong signature or corruption may be installed, or the installed file may be malware of unknown origin. (Code 52)\n\n_The template below is mostly useful for bug reports and support questions. Feel free to remove anything which doesn't apply to you and add more information where it makes sense._\r\n\r\n_Also, before reporting a new issue, please make sure that:_\r\n\r\n- _You read carefully the [documentation and frequently asked questions](https://github.com/NVIDIA/nvidia-docker/wiki)._\r\n- _You [searched](https://github.com/NVIDIA/nvidia-docker/issues?utf8=%E2%9C%93&q=is%3Aissue) for a similar issue and this is not a duplicate of an existing one._\r\n- _This issue is not related to [NGC](https://github.com/NVIDIA/nvidia-docker/wiki/NGC), otherwise, please use the [devtalk forums](https://devtalk.nvidia.com/default/board/200/nvidia-gpu-cloud-ngc-users/) instead._\r\n- _You went through the [troubleshooting](https://github.com/NVIDIA/nvidia-docker/wiki/Troubleshooting) steps._\r\n\r\n---\r\n\r\n### 1. Issue or feature description\r\n\r\n### 2. Steps to reproduce the issue\r\n\r\n### 3. Information to [attach](https://help.github.com/articles/file-attachments-on-issues-and-pull-requests/) (optional if deemed irrelevant)\r\n\r\n - [ ] Some nvidia-container information: `nvidia-container-cli -k -d /dev/tty info`\r\n - [ ] Kernel version from `uname -a`\r\n - [ ] Any relevant kernel output lines from `dmesg`\r\n - [ ] Driver information from `nvidia-smi -a`\r\n - [ ] Docker version from `docker version`\r\n - [ ] NVIDIA packages version from `dpkg -l '*nvidia*'` _or_ `rpm -qa '*nvidia*'`\r\n - [ ] NVIDIA container library version from `nvidia-container-cli -V`\r\n - [ ] NVIDIA container library logs (see [troubleshooting](https://github.com/NVIDIA/nvidia-docker/wiki/Troubleshooting))\r\n - [ ] Docker command, image and tag used\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Infinite loop when calling `brew style --fix`","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"saving the file","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add info to upgrade manual","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# add to document about android sdk licenses agreement\n\nHhi. To prevent additional searching add to your dicumentation commands to agree android license agreement\r\n\r\nhttps://stackoverflow.com/questions/39760172/you-have-not-accepted-the-license-agreements-of-the-following-sdk-components\r\n\r\n```\r\non Windows:\r\n\r\ncd \"%ANDROID_HOME%\"/tools/bin\r\nRun the sdkmanager as follows:\r\n\r\nsdkmanager --licenses\r\nAnd accept the licenses you did not accept yet (but need to).\r\n\r\nFor more details see the Android Studio documentation, although the current documentation is missing any description on the --licenses option.\r\n```","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update Docs on Security Context and Policy","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Please install GAMS in Codecov testing framework","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"service documentation links to all nodes need updated.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Using useReducer will have `errors` as  an empty object.\n\n**Describe the bug**\r\n`errors` is empty if it's coming from `useReducer`\r\n\r\n**To Reproduce**\r\nhttps://codesandbox.io/s/my-app-wuloq\r\n\r\n**Expected behavior**\r\n`errors` before `useReducer` seems to have correct properties.  I am expecting to have the same values in errors coming from `state`.\r\n\r\n```tsx\r\n// https://codesandbox.io/s/my-app-wuloq\r\n// App.tsx\r\n\r\n  // This has error properties when the form is invalid\r\n  console.log(\"coming directly from useForm - errors:\", errors)\r\n  // This seems it's always empty\r\n  console.log(\"coming from state - errors:\", state.errors)\r\n\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Router upgrade does not work when initial state is Angular","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Preparing Hass.io .... infinite time\n\nI've just tried to install hass.io on Hetzner Cloud (also tried to install on local vm)\r\n\r\nafter script finished with no error and [Info] Run Hass.io message, i can access web at http://ip.adrress:8123 but all i get is Preparing Hass.io (this can take up to 20 minutes) message.\r\nBoth VMs are fast and even after 4-5 hours there's nothing much happening.\r\n\r\nOS: ubuntu-18.04.3-live-server-amd64, fresh install.  Docker-ce is installed as describes here: https://docs.docker.com/install/linux/docker-ce/debian/\r\n\r\n\r\nhave no clue what to do next.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"PortalScripting typings are missing constructor for ScriptCall","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"[Feature Request] more protocols for links","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"\"499 Client Error: Client Disconnected for url: https://upload.pypi.org/legacy/\"","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Enquiry about RepositoryFiles section from the node-gitlab package\n\nHi!\r\nI use node-gitlab package (Gitlab API Node.js client) in order to get a file from a gitlab repository . I followed what exists in the official documentation concerning this one (https://www.npmjs.com/package/node-gitlab) and I tried this function (see the capture below) but I received this error during the execution. \r\nAny idea about how to resolve this?\r\nThanks in advance!\r\n\r\nHere is the code that I tried: [\r\n![Capture](https://user-images.githubusercontent.com/36052172/62827552-99d16100-bbc8-11e9-9e1a-0bde8e427b7e.PNG)\r\n](url)\r\n\r\nThe result that I supposed to get: \r\n![Capture1](https://user-images.githubusercontent.com/36052172/62827558-d4d39480-bbc8-11e9-9c13-35fcf0d963a4.PNG)\r\n\r\nThe output: \r\n![Capture2](https://user-images.githubusercontent.com/36052172/62827566-15331280-bbc9-11e9-8666-a7a2d5c0f8a9.PNG)\r\n\r\nThe function : \r\n![Capture3](https://user-images.githubusercontent.com/36052172/62827584-9db1b300-bbc9-11e9-8639-12de2e4a7211.PNG)\r\n\r\n\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# 404 when click to Edit on the Multidimensional Modeling (Adventure Works Tutorial)\n\n**\ud83d\uded1 IMPORTANT**: You can get your feedback addressed faster if you **use the comment section for the article in which you encountered a problem**.\r\n\r\n**Link to article:**\r\nhttps://docs.microsoft.com/en-us/analysis-services/multidimensional-tutorial/multidimensional-modeling-adventure-works-tutorial?view=sql-server-2017\r\n\r\n**Problem:**\r\nAfter signing in and click on the Edit button. It return 404 page not found. \r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# CVE-2018-11697 (High) detected in CSS::Sass-v3.6.0\n\n## CVE-2018-11697 - High Severity Vulnerability\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Vulnerable Library - <b>CSS::Sassv3.6.0</b></p></summary>\n<p>\n\n<p>Library home page: <a href=https://metacpan.org/pod/CSS::Sass>https://metacpan.org/pod/CSS::Sass</a></p>\n<p>Found in HEAD commit: <a href=\"https://github.com/mixcore/website/commit/eeefb98d520629c182c4d88691216d2bd738678a\">eeefb98d520629c182c4d88691216d2bd738678a</a></p>\n</p>\n</details>\n</p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Library Source Files (63)</summary>\n<p></p>\n<p> * The source files were matched to this source library based on a best effort match. Source libraries are selected from a list of probable public libraries.</p>\n<p>\n\n  - /website/docs/node_modules/node-sass/src/libsass/src/color_maps.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_util.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8/unchecked.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/output.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/b64/cencode.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/source_map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_values.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/lexer.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8.h\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_node.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8_string.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/plugins.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/node.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/base.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/json.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/environment.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/position.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/extend.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/subset_map.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/remove_placeholders.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_context.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast_fwd_decl.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/contrib/plugin.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8/core.h\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/functions.h\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_superselector.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_functions.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8_string.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/node.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/cencode.c\n  - /website/docs/node_modules/node-sass/src/libsass/src/subset_map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/base64vlq.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/listize.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/c99func.c\n  - /website/docs/node_modules/node-sass/src/libsass/src/position.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/remove_placeholders.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/values.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_functions.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_subset_map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass2scss.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/memory/SharedPtr.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/paths.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/context.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/color_maps.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_unification.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_util.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/script/test-leaks.pl\n  - /website/docs/node_modules/node-sass/src/libsass/src/source_map.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/lexer.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/memory/SharedPtr.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/json.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/units.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_c.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/units.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/b64/encode.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/file.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/environment.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8/checked.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/plugins.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/listize.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/debug.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass2scss.h\n</p>\n</details>\n<p></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/high_vul.png' width=19 height=20> Vulnerability Details</summary>\n<p>  \n  \nAn issue was discovered in LibSass through 3.5.4. An out-of-bounds read of a memory region was found in the function Sass::Prelexer::exactly() which could be leveraged by an attacker to disclose information or manipulated to read from unmapped memory causing a denial of service.\n\n<p>Publish Date: 2018-06-04\n<p>URL: <a href=https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-11697>CVE-2018-11697</a></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/cvss3.png' width=19 height=20> CVSS 3 Score Details (<b>8.1</b>)</summary>\n<p>\n\nBase Score Metrics:\n- Exploitability Metrics:\n  - Attack Vector: Network\n  - Attack Complexity: Low\n  - Privileges Required: None\n  - User Interaction: Required\n  - Scope: Unchanged\n- Impact Metrics:\n  - Confidentiality Impact: High\n  - Integrity Impact: None\n  - Availability Impact: High\n</p>\nFor more information on CVSS3 Scores, click <a href=\"https://www.first.org/cvss/calculator/3.0\">here</a>.\n</p>\n</details>\n<p></p>\n\n***\nStep up your Open Source Security Game with WhiteSource [here](https://www.whitesourcesoftware.com/full_solution_bolt_github)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Need an issue template","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Compilation problem with dependency Vigra","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# CVE-2018-19827 (High) detected in CSS::Sass-v3.6.0\n\n## CVE-2018-19827 - High Severity Vulnerability\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Vulnerable Library - <b>CSS::Sassv3.6.0</b></p></summary>\n<p>\n\n<p>Library home page: <a href=https://metacpan.org/pod/CSS::Sass>https://metacpan.org/pod/CSS::Sass</a></p>\n<p>Found in HEAD commit: <a href=\"https://github.com/mixcore/website/commit/eeefb98d520629c182c4d88691216d2bd738678a\">eeefb98d520629c182c4d88691216d2bd738678a</a></p>\n</p>\n</details>\n</p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Library Source Files (63)</summary>\n<p></p>\n<p> * The source files were matched to this source library based on a best effort match. Source libraries are selected from a list of probable public libraries.</p>\n<p>\n\n  - /website/docs/node_modules/node-sass/src/libsass/src/color_maps.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_util.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8/unchecked.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/output.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/b64/cencode.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/source_map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_values.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/lexer.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8.h\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_node.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8_string.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/plugins.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/node.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/base.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/json.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/environment.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/position.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/extend.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/subset_map.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/remove_placeholders.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_context.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast_fwd_decl.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/contrib/plugin.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8/core.h\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/functions.h\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_superselector.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_functions.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8_string.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/node.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/cencode.c\n  - /website/docs/node_modules/node-sass/src/libsass/src/subset_map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/base64vlq.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/listize.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/c99func.c\n  - /website/docs/node_modules/node-sass/src/libsass/src/position.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/remove_placeholders.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/values.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_functions.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_subset_map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass2scss.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/memory/SharedPtr.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/paths.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass/context.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/color_maps.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/test/test_unification.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_util.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/script/test-leaks.pl\n  - /website/docs/node_modules/node-sass/src/libsass/src/source_map.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/lexer.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/memory/SharedPtr.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/json.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/units.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_c.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/units.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/b64/encode.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/file.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/environment.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/utf8/checked.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/plugins.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/listize.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/debug.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/include/sass2scss.h\n</p>\n</details>\n<p></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/high_vul.png' width=19 height=20> Vulnerability Details</summary>\n<p>  \n  \nIn LibSass 3.5.5, a use-after-free vulnerability exists in the SharedPtr class in SharedPtr.cpp (or SharedPtr.hpp) that may cause a denial of service (application crash) or possibly have unspecified other impact.\n\n<p>Publish Date: 2018-12-03\n<p>URL: <a href=https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-19827>CVE-2018-19827</a></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/cvss3.png' width=19 height=20> CVSS 3 Score Details (<b>8.8</b>)</summary>\n<p>\n\nBase Score Metrics:\n- Exploitability Metrics:\n  - Attack Vector: Network\n  - Attack Complexity: Low\n  - Privileges Required: None\n  - User Interaction: Required\n  - Scope: Unchanged\n- Impact Metrics:\n  - Confidentiality Impact: High\n  - Integrity Impact: High\n  - Availability Impact: High\n</p>\nFor more information on CVSS3 Scores, click <a href=\"https://www.first.org/cvss/calculator/3.0\">here</a>.\n</p>\n</details>\n<p></p>\n\n***\nStep up your Open Source Security Game with WhiteSource [here](https://www.whitesourcesoftware.com/full_solution_bolt_github)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Please add \"remove_tags\" support to CreateOrUpdateSubscriber","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Migrating examples from CodeSandbox to the examples folder\n\n<!--\r\n\r\n\ud83d\udc4b Hey, thanks for taking an interest in \ud83c\udfc1 React Final Form!\r\n\r\n-->\r\n\r\nThere's a note at the top of the [Examples page](https://final-form.org/docs/react-final-form/examples) that calls for help in moving examples from CodeSandbox to the [examples folder](https://github.com/final-form/react-final-form/tree/master/examples).\r\nI would like to help out with this but I'm not quite sure what is required for migration. I can see that the files in each example's folder match those in the respective CodeSandbox, but the README of each folder contains broken links to the respective sandboxes; \"Could not find package.json\" is the error message.\r\n\r\nIt appears that you want the files to be copied from the CodeSandbox to a corresponding subfolder in the examples folder, but I want to be sure before doing anything. I also don't know which CodeSandbox link should be provided in the README for each subfolder, given that those in the current folders are broken as I mentioned earlier. Could you please provide some clarification or a little guide explaining what you want to see in each PR? Thanks.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# CVE-2018-16487 (High) detected in lodash-1.0.2.tgz\n\n## CVE-2018-16487 - High Severity Vulnerability\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Vulnerable Library - <b>lodash-1.0.2.tgz</b></p></summary>\n\n<p>A utility library delivering consistency, customization, performance, and extras.</p>\n<p>Library home page: <a href=\"https://registry.npmjs.org/lodash/-/lodash-1.0.2.tgz\">https://registry.npmjs.org/lodash/-/lodash-1.0.2.tgz</a></p>\n<p>Path to dependency file: /website/docs/package.json</p>\n<p>Path to vulnerable library: /tmp/git/website/docs/node_modules/lodash/package.json</p>\n<p>\n\nDependency Hierarchy:\n  - gulp-3.9.1.tgz (Root Library)\n    - vinyl-fs-0.3.14.tgz\n      - glob-watcher-0.0.6.tgz\n        - gaze-0.5.2.tgz\n          - globule-0.1.0.tgz\n            - :x: **lodash-1.0.2.tgz** (Vulnerable Library)\n<p>Found in HEAD commit: <a href=\"https://github.com/mixcore/website/commit/eeefb98d520629c182c4d88691216d2bd738678a\">eeefb98d520629c182c4d88691216d2bd738678a</a></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/high_vul.png' width=19 height=20> Vulnerability Details</summary>\n<p>  \n  \nA prototype pollution vulnerability was found in lodash <4.17.11 where the functions merge, mergeWith, and defaultsDeep can be tricked into adding or modifying properties of Object.prototype.\n\n<p>Publish Date: 2019-02-01\n<p>URL: <a href=https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-16487>CVE-2018-16487</a></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/cvss3.png' width=19 height=20> CVSS 3 Score Details (<b>9.8</b>)</summary>\n<p>\n\nBase Score Metrics:\n- Exploitability Metrics:\n  - Attack Vector: Network\n  - Attack Complexity: Low\n  - Privileges Required: None\n  - User Interaction: None\n  - Scope: Unchanged\n- Impact Metrics:\n  - Confidentiality Impact: High\n  - Integrity Impact: High\n  - Availability Impact: High\n</p>\nFor more information on CVSS3 Scores, click <a href=\"https://www.first.org/cvss/calculator/3.0\">here</a>.\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/suggested_fix.png' width=19 height=20> Suggested Fix</summary>\n<p>\n\n<p>Type: Upgrade version</p>\n<p>Origin: <a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16487\">https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16487</a></p>\n<p>Release Date: 2019-02-01</p>\n<p>Fix Resolution: 4.17.11</p>\n\n</p>\n</details>\n<p></p>\n\n***\nStep up your Open Source Security Game with WhiteSource [here](https://www.whitesourcesoftware.com/full_solution_bolt_github)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Cannot find libzmq in linux","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Maven Dependency","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Make it easier to use grafanalib in a project","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Documentation of HttpServer.bind and HttpServer.bindSecure is misleading","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Double precision emulation using 2 floats (double-float)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Unable to run rook with dataDirHostPath","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Can't understand what is this page saying....","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"[Feature Request] LaTeX with Chinese support","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add an FAQ page to the website","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"The connector can silently fail to connect to the requested database or schema","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Congratulations!\n\n## Nice work\n\n![celebrate](https://octodex.github.com/images/benevocats.jpg)\n\nCongratulations @anesta95, you've completed this course!\n\nWhen considering the security of your repository, consider the installed applications, like me. Every app installed on your repository has access to some of your data. Even if it is harmless (like me), it is a good idea to periodically check and prune the list of installed apps and integrations on your repositories. Look for things like active use, or  permissions giving more access than necessary.\n\n### Manage app permissions\n\nAs much as it pains me to leave you, I want you to uninstall me from this repository. I won't be able to congratulate you on achieving this task, but know I'm excited about your progress.\n\nFollow the guidelines in [GitHub's documentation](https://help.github.com/articles/reviewing-your-authorized-integrations/#reviewing-your-authorized-github-apps) to review authorized OAuth and GitHub Apps. If you'd like to practice, you can uninstall Learning Lab from this repository.\n\n### What went well\n\nBefore I say good-bye, here's a recap of all the tasks you've accomplished in your repository:\n\n- Enable vulnerable dependency detection for private repositories\n- Detect and fix outdated dependencies with security vulnerabilities\n- Keep sensitive data out of your repository by leveraging the use of a `.gitignore` file\n\n### What's next?\n\nWant to learn more options to secure your repository? Check out the [documentation for security alerts](https://help.github.com/articles/about-security-alerts-for-vulnerable-dependencies/), as well as some [GitHub apps for security](https://github.com/marketplace/category/security) that might help you keep your code safe.\n\n### Keep Learning\n\nWant to keep learning? Feel free to [check out our other courses](https://lab.github.com/courses).\n\n<hr>\n<h3 align=\"center\">I won't respond to this issue, go ahead and close it when finished.</h3>\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# CVE-2019-6286 (Medium) detected in opennms-opennms-source-23.0.0-1\n\n## CVE-2019-6286 - Medium Severity Vulnerability\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Vulnerable Library - <b>opennmsopennms-source-23.0.0-1</b></p></summary>\n<p>\n\n<p>A Java based fault and performance management system</p>\n<p>Library home page: <a href=https://sourceforge.net/projects/opennms/>https://sourceforge.net/projects/opennms/</a></p>\n<p>Found in HEAD commit: <a href=\"https://github.com/mixcore/website/commit/eeefb98d520629c182c4d88691216d2bd738678a\">eeefb98d520629c182c4d88691216d2bd738678a</a></p>\n</p>\n</details>\n</p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/vulnerability_details.png' width=19 height=20> Library Source Files (62)</summary>\n<p></p>\n<p> * The source files were matched to this source library based on a best effort match. Source libraries are selected from a list of probable public libraries.</p>\n<p>\n\n  - /website/docs/node_modules/node-sass/src/libsass/src/expand.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/expand.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/factory.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/boolean.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/util.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/value.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/emitter.hpp\n  - /website/docs/node_modules/node-sass/src/callback_bridge.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/file.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/operation.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/operators.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/constants.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/error_handling.hpp\n  - /website/docs/node_modules/node-sass/src/custom_importer_bridge.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/parser.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/constants.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/list.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/cssize.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/functions.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/util.cpp\n  - /website/docs/node_modules/node-sass/src/custom_function_bridge.cpp\n  - /website/docs/node_modules/node-sass/src/custom_importer_bridge.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/bind.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/eval.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/backtrace.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/extend.cpp\n  - /website/docs/node_modules/node-sass/src/sass_context_wrapper.h\n  - /website/docs/node_modules/node-sass/src/sass_types/sass_value_wrapper.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/error_handling.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/debugger.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/emitter.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/number.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/color.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_values.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/output.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/check_nesting.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/null.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast_def_macros.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/functions.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/cssize.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/prelexer.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_c.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_value.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/ast_fwd_decl.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/inspect.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/color.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/values.cpp\n  - /website/docs/node_modules/node-sass/src/sass_context_wrapper.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/list.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/check_nesting.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/map.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/to_value.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/context.cpp\n  - /website/docs/node_modules/node-sass/src/sass_types/string.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/sass_context.cpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/prelexer.hpp\n  - /website/docs/node_modules/node-sass/src/libsass/src/context.hpp\n  - /website/docs/node_modules/node-sass/src/sass_types/boolean.h\n  - /website/docs/node_modules/node-sass/src/libsass/src/eval.cpp\n</p>\n</details>\n<p></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/medium_vul.png' width=19 height=20> Vulnerability Details</summary>\n<p>  \n  \nIn LibSass 3.5.5, a heap-based buffer over-read exists in Sass::Prelexer::skip_over_scopes in prelexer.hpp when called from Sass::Parser::parse_import(), a similar issue to CVE-2018-11693.\n\n<p>Publish Date: 2019-01-14\n<p>URL: <a href=https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-6286>CVE-2019-6286</a></p>\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/cvss3.png' width=19 height=20> CVSS 3 Score Details (<b>6.5</b>)</summary>\n<p>\n\nBase Score Metrics:\n- Exploitability Metrics:\n  - Attack Vector: Network\n  - Attack Complexity: Low\n  - Privileges Required: None\n  - User Interaction: Required\n  - Scope: Unchanged\n- Impact Metrics:\n  - Confidentiality Impact: None\n  - Integrity Impact: None\n  - Availability Impact: High\n</p>\nFor more information on CVSS3 Scores, click <a href=\"https://www.first.org/cvss/calculator/3.0\">here</a>.\n</p>\n</details>\n<p></p>\n<details><summary><img src='https://whitesource-resources.whitesourcesoftware.com/suggested_fix.png' width=19 height=20> Suggested Fix</summary>\n<p>\n\n<p>Type: Upgrade version</p>\n<p>Origin: <a href=\"https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-6286\">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-6286</a></p>\n<p>Release Date: 2019-08-06</p>\n<p>Fix Resolution: 3.6.0</p>\n\n</p>\n</details>\n<p></p>\n\n***\nStep up your Open Source Security Game with WhiteSource [here](https://www.whitesourcesoftware.com/full_solution_bolt_github)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"[todo-mvvm-databinding] Task class is not actually immutable (despite docs claim)","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Failing to compile with hw and xen ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# No readme file\n\ncan you add readme.md file with the detail description about the project? that would help ","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Error in auth0-spa-js\n\nAn error is happening when logged in:\r\n`ERROR TypeError: Cannot read property 'close' of undefined`\r\n\r\nThis issue is discussed here:\r\nhttps://community.auth0.com/t/typeerror-cannot-read-property-close-of-undefined-when-using-new-auth0-spa-library-in-angular-interceptor/28010\r\n\r\nThere was an update to the Auth0 documentation when setting up the auth service: \r\nhttps://auth0.com/docs/quickstart/spa/angular2","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# edit2_ERimage for README.md\n\n![](https://i.gyazo.com/a11f7c52c200a66a62321f5cab168f78.png)\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"FieldDoesNotExist on Customising generated forms","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Visual Guide in GUI for Different StreamDeck Models\n\n**Describe the feature**\r\nA simple rectangle around the buttons used by each of the smaller StreamDeck models when programming in Companion v2.0 or higher, as a reminder of button limitations when programming for StreamDeck Mini or the original StreamDeck\r\n\r\n**Is this platform dependent (windows, mac, ..)?**\r\nNo\r\n\r\n**If documentation is required to implement, do you know where to find it?**\r\nI am unaware of any documentation for this.\r\n\r\n**Usecases**\r\nI believe that this would be helpful for those new to programming in Companion, as they would be able to see the constraints of the device that they are programming for.\r\n\r\nIt would also help those with multiple StreamDeck versions, to serve as a reminder of the constraints of each version. Especially since in 2.0 and higher, we the ability to use the far left column as something other than page switching buttons, having that visual guide would be a great help.\r\n\r\nThe image is just a mock-up of what this could look like, with the constraints of the StreamDeck Mini shown on the regular size StreamDeck. I know that if the guide were in place with Companion 1.4 and below, the actual buttons in use for a StreamDeck mini would be only the top left 4, but this is just meant to serve as an example of the type of visual guide to which I'm referring.\r\n![Screen Shot 2019-08-11 at 11 34 23](https://user-images.githubusercontent.com/40829374/62828635-aab4bd80-bc2e-11e9-8109-a0a2c5b30009.png)\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Translate homepage texts and categories","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Is this tool supported?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Failed Pre-Flight Check","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"How to add prefix to id?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Support images in the List block","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Conan docs incorrect.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"tf.estimate quickstart","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Amp-Analytics - feature ability to trigger multiple GA Event tags on page load","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Replace tutorials in the user guide with links to the guides","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# More documentation updates\n\n- [ ] Special css classes\r\n- [ ] Filenames should be unique","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"[feat]: IssuesEvent","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# iOS deploy not working\n\nThis is the error I get after following all steps out of the documentation. Using Unity3D v.2019.3.0a11 and the latest version of flutter-unity-view-widget and the latest version of Flutter:\r\n\r\n2019-08-11 00:35:01.400320+0200 Runner[1571:278941] Built from 'trunk' branch, Version '2019.3.0a11 (6fa9444d8a5d)', Build type 'Release', Scripting Backend 'il2cpp'\r\nno boot config - using default values\r\n \r\n\r\nCould you provide a fix or help.\r\n\r\nThank you.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"undefined method `head?' for nil:NilClass when Golang has update","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Add new logo to readme\n\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"HTML documentation on UntrustedRootOK looks strange","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Outdated README.md","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"broken link in ABOUT","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"[feature] Tizen support","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"README text / jQuery removal?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# SDCard not showing up\n\nIm trying to install windows 10 Pro Build 18956, but in GUI my sdcard not showing up, and in cmd line `\"C:\\Users\\Administrador\\Downloads\\WOA.Deployer\\WoaDeployer.exe\" deploy --disk 2 --wim install.wim` give me some erros \r\n\r\n**Screenshots**\r\nMy SDCARD showing normaly  on diskmgmt.msc\r\n![image](https://user-images.githubusercontent.com/3611208/62829468-95ab4080-bbd4-11e9-843f-0acff64d775d.png)\r\nand on explorer\r\n![image](https://user-images.githubusercontent.com/3611208/62829437-cb9bf500-bbd3-11e9-86c8-bb306f4fb0df.png)\r\nUsing GUI utility\r\n![image](https://user-images.githubusercontent.com/3611208/62829408-3e58a080-bbd3-11e9-8757-4212c7aa4d9c.png)\r\nUsing cmd line utility\r\n![image](https://user-images.githubusercontent.com/3611208/62829392-cdb18400-bbd2-11e9-95fc-3f53caaab13e.png)\r\n\r\n\r\n**Log file**\r\nGUI logs:\r\n[Log-20190811.txt](https://github.com/WOA-Project/WOA-Deployer-Rpi/files/3489494/Log-20190811.txt)\r\nCMD Logs:\r\n```\r\nC:\\Users\\Administrador\\Downloads\\WOA.Deployer>\r\n[00:55:42 INF] Downloading UEFI\r\n[00:55:42 WRN] UEFI was already downloaded. Skipping download.\r\n[00:55:42 INF] Fetching zip from http://ww1.microchip.com/downloads/en//softwarelibrary/obj-lan95xx-windows/lan9500-wdf-v18.12.18.0.zip\r\n[00:55:42 INF] Fetching zip from http://ww1.microchip.com/downloads/en//softwarelibrary/obj-lan78xx-windows/lan7800-wdf-v18.12.14.0.zip\r\n[00:55:42 INF] Fetching zip from https://pi64.win/wp-content/uploads/2019/02/usb-drivers.zip\r\n[00:55:42 INF] Fetching from GitHub subfolder: https://github.com/driver1998/bsp/bsp-master/prebuilt to Downloaded\\Drivers\\BSP Drivers\r\n[00:55:42 WRN] https://github.com/driver1998/bspbsp-master/prebuilt was already downloaded. Skipping download.\r\n[00:55:42 INF] License from Downloaded\\Drivers\\USB\\license.md\r\nBy continuing you are accepting the following license below.\r\nIf you decline it, press Control+C anytime during the deployment process.\r\n# TrueTask\u00ae USB\r\n## ARM64 host drivers for Windows 10 on the Raspberry Pi\r\n### Software License Agreement and Warranty Statement\r\n\r\nMCCI IS WILLING TO LICENSE THE SOFTWARE TO YOU ONLY UPON THE CONDITION THAT YOU ACCEPT ALL OF THE TERMS CONTAINED IN THIS LICENSE AGREEMENT.  PLEASE READ THE TERMS CAREFULLY AND CLICK ON \"ACCEPT\" BEFORE INSTALLING THE SOFTWARE, AS CLICKING ON \"ACCEPT\" AND INSTALLING THE SOFTWARE WILL INDICATE YOUR AGREEMENT WITH THEM.  IF YOU DO NOT AGREE WITH THESE TERMS, THEN MCCI IS UNWILLING TO LICENSE THE SOFTWARE TO YOU, IN WHICH EVENT YOU SHOULD NOT PROCEED WITH INSTALLING THE SOFTWARE.\r\n\r\nTO THE EXTENT THESE TERMS CONFLICT WITH ANY PREVIOUSLY SIGNED AND WRITTEN AGREED TO TERMS BETWEEN YOU AND MCCI, THE PRIOR TERMS SHALL CONTROL.\r\n\r\nThe software which accompanies this license (the \"Software\") and any accompanying documentation (the \"Documentation\") is the property of MCCI Corporation (\"MCCI\") or its licensors and is protected by copyright law. This agreement is between MCCI and the individual who downloads and wishes to use the Software and Documentation (\"You\"). While MCCI continues to own the software, You will have certain rights to use the Software upon your acceptance of this license.  MCCI grants You a non-transferable and non-exclusive license to use this Software under the terms of this agreement.  MCCI remains the proprietor of this software and licenses its use to You.  You do not obtain title to the Software or Documentation or any copyrights or proprietary rights in the software.  You assume responsibility for the selection of the Software to achieve your intended results, and for the installation, use and results obtained from the Software.  Additional rights and obligations regarding the Software and its contents, and/or the Documentation may be defined by a separate written agreement with MCCI, and if so, such separate written agreement shall be controlling.\r\n\r\nIn the absence of conflict of such separate written agreement or except as may be modified by such a license addendum which accompanies this license, your rights and obligations with respect to use of this Software and Documentation are as follows:\r\n\r\nThis license does NOT extend to any corporation or organization of which You are a member or with which You are affiliated. It is only for personal use. Commercial licenses for corporations and organizations are available from MCCI.\r\n\r\nYOU MAY:  License Grant: You are granted non-exclusive rights to install and use the Software for personal use and evaluation purposes only. You may install on any Raspberry Pi computer that you personally own, provided that You acquire and dedicate a licensed copy of the Software for each computer on which the Software is used or to which it is transmitted over the internal network. You may also make backup copies of the Software.\r\n\r\nRESTRICTIONS  YOU MAY NOT: (i) permit others to use the Software, except as expressly provided above for authorized network use; (ii) modify or translate the Software; (iii) reverse engineer, decompile, or disassemble the Software, except to the extent this restriction is expressly prohibited by applicable law; (iv) create derivative works based on the Software; (v) merge the Software with another product; (vi) export or use the Software data compilations, structures, or algorithms with another product; (vii) copy the Software, except as expressly provided above; (viii) remove or obscure any proprietary rights notices or labels on the Software; (ix) post the software on a website for public download, or (x) resell or distribute the Software, either stand-alone or bundled with or installed with hardware or software supplied by You or others, or (xi) distribute the Software or Documentation in any form (electronic or otherwise).\r\n\r\nTERM AND TERMINATION.  The license provided in this Agreement will continue in perpetuity unless You fail to comply with the terms and conditions of this Agreement.  You agree that, upon such termination, you will either destroy (or permanently erase) all copies of the Software and Documentation, or return the original Software and Documentation to MCCI, together with any other material you have received from MCCI in connection with the Software.\r\n\r\nTRANSFERS.  You may not transfer the Software or any rights under this Agreement without the prior written consent of MCCI. Any attempted transfer or assignment in violation of this provision shall be null and void.\r\n\r\nFEEDBACK.  You agree that in the event You voluntarily disclose any ideas or suggestions to MCCI (in any manner, whether in writing or orally or otherwise) regarding the Software, Documentation, or Design Techniques, including possible enhancements or improvements (\"Feedback\"), MCCI may freely use and disseminate such Feedback.  You agree not to claim that MCCI owes You any compensation for its use or dissemination of such Feedback.\r\n\r\nOWNERSHIP.  MCCI and its suppliers own the Software and all intellectual property rights embodied therein, including copyrights and valuable trade secrets embodied in the Software&#39;s design and coding methodology.  The Software is protected by United States copyright laws and international treaty provisions.  This Agreement provides You only a limited use license, and no ownership of any intellectual property. All content accessed through the Software is the property of the applicable content owner and may be protected by applicable copyright law. This license gives You no rights to such content.\r\n\r\nWRITTEN RECORD.  The text of this Agreement is included with the Software files as \"ttusb-pi64-installer-license.rtf.\"  You agree to print this text file immediately after installation of the Software and to maintain the printed copy as a written record of this transaction.\r\n\r\nDISCLAIMER OF WARRANTY; LIMITATION OF LIABILITY **.**  MCCI PROVIDES THE SOFTWARE AND THE DOCUMENTATION \"AS IS\" WITHOUT WARRANTY OF ANY KIND EITHER EXPRESS IMPLIED OR STATUTORY, INCLUDING WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.  THERE IS NO WARRANTY OR GUARANTEE THAT THE OPERATION OF THE SOFTWARE WILL BE UNINTERRUPTED, ERROR-FREE, OR VIRUS-FREE, OR THAT THE SOFTWARE WILL MEET ANY PARTICULAR CRITERIA OF PERFORMANCE OR QUALITY EXCEPT AS EXPRESSLY PROVIDED IN THE LIMITED WARRANTY.  All risk of quality and performance of the software and documentation is with You.   This disclaimer of warranty constitutes an essential part of this Agreement.\r\n\r\nTo the extent that this Warranty Statement is inconsistent with the jurisdiction where You use the Software, the Warranty Statement shall be deemed to be modified consistent with such local law but to the maximum extent enforceable in such jurisdiction.  Under such local law, certain limitations may not apply, and You may have additional rights which vary from jurisdiction to jurisdiction.  For example, some states in the United States and some jurisdictions outside the United States may: (i) preclude the disclaimers and limitations of this Warranty Statement from limiting the rights of a consumer; (ii) otherwise restrict the ability of a manufacturer to make such disclaimers or to impose such limitations; or (iii) grant the consumer additional legal rights, specify the duration of implied warranties which the manufacturer cannot disclaim, or prohibit limitations on how long an implied warranty lasts.\r\n\r\nIN NO EVENT AND UNDER NO LEGAL THEORY, INCLUDING WITHOUT LIMITATION, TORT, CONTRACT, OR STRICT PRODUCTS LIABILITY, SHALL MCCI OR ANY OF ITS SUPPLIERS BE LIABLE TO YOU OR ANY OTHER PERSON FOR ANY PERSONAL INJURY, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, INCLUDING WITHOUT LIMITATION, DAMAGES FOR LOSS OF GOODWILL, WORK STOPPAGE, COMPUTER MALFUNCTION, OR ANY OTHER KIND OF COMMERCIAL DAMAGE, EVEN IF MCCI HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.  IN NO EVENT SHALL MCCI BE LIABLE FOR DAMAGES IN EXCESS OF THE AMOUNT PAID BY YOU TO MCCI OR THIS SOFTWARE LICENSE.  SOME JURISDICTIONS DO NOT ALLOW THE LIMITATION OF LIABILITY FOR PERSONAL INJURY, OR OF INCIDENTAL OR CONSEQUENTIAL DAMAGES, SO THIS LIMITATION MAY NOT APPLY TO YOU. In no event shall MCCI&#39;s total liability to You for all damages (other than as may be required by applicable law in cases involving personal injury) exceed the amount of fifty dollars ($50.00). The foregoing limitations will apply even if the above stated remedy fails of its essential purpose.\r\n\r\nEXPORT CONTROLS.  You may not use or otherwise export the Software except as authorized by United States law and the laws of the jurisdiction in which the Software was obtained. In particular, but without limitation, the Software or underlying information or technology may not be exported or re-exported (i) into (or to a national or resident of) Cuba, Libya, North Korea, Iran, Syria or any other country to which the United States has embargoed goods; or (ii) to anyone on the U.S. Treasury Department&#39;s list of Specially Designated Nationals, the U.S. Commerce Department&#39;s Table of Denial Orders, or the U.S. Department of Commerce Denied Person&#39;s List or Entity List.  By downloading, ordering or using the Software, You agree to the foregoing and represent that You are not located in, under the control of, or a national or resident of any such country or on any such list. You also agree that you will not use the Software for any purposes prohibited by United States law, including, without limitation, the development, design, manufacture or production of missiles, or nuclear, chemical or biological weapons.\r\n\r\nMISCELLANEOUS.  This Agreement constitutes the entire understanding of the parties with respect to the subject matter of this Agreement and merges all prior communications, representations, and agreements.  This Agreement may be modified only by a written agreement signed by the parties.  If any provision of this Agreement is held to be unenforceable for any reason, such provision shall be reformed only to the extent necessary to make it enforceable.  This Agreement shall be construed under the laws of the State of New York, USA, excluding rules regarding conflicts of law.  The application of the United Nations Convention of Contracts for the International Sale of Goods is expressly excluded.\r\n\r\nUNITED STATES GOVERNMENT USE.  MCCI represents that the Software and its documentation were developed at private expense and no part of same is in the public domain.  The Software is Commercial Computer Software provided with RESTRICTED RIGHTS under the Federal Acquisition Regulations and agency supplements to them.  Use, duplication, or disclosure by the U.S. Government is subject to the restrictions as set forth in the Rights in Technical Data and Computer Software clause at DFAR 252.227-7013 et. seq. or the Commercial Computer Software Restricted Rights at DFAR 52.227-19, as applicable.  Contractor is MCCI Corporation, 3520 Krums Corners Road, Ithaca, NY  14850, USA.\r\n\r\nTrueTask and MCCI are registered trademarks of MCCI Corporation.\r\n\r\n\r\n\r\n[00:55:42 INF] Deploying Windows\r\n[00:55:45 FTL] Operation failed\r\nSystem.InvalidOperationException: A sequ\u00eancia n\u00e3o cont\u00e9m elementos de correspond\u00eancia\r\n   em System.Linq.Enumerable.First[TSource](IEnumerable`1 source, Func`2 predicate)\r\n   em Deployer.Raspberry.RaspberryPi.<GetDeviceDisk>d__4.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Tasks.DeployWindows.<Execute>d__4.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Execution.ScriptRunner.<Run>d__5.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Execution.ScriptRunner.<Run>d__4.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Raspberry.WoaDeployer.<Deploy>d__3.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Raspberry.Console.Program.<Execute>d__1.MoveNext() na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Console\\Program.cs:linha 49\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Raspberry.Console.Program.<Main>d__0.MoveNext() na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Console\\Program.cs:linha 28\r\n\r\nExce\u00e7\u00e3o Sem Tratamento: System.AggregateException: Um ou mais erros. ---> System.InvalidOperationException: A sequ\u00eancia n\u00e3o cont\u00e9m elementos de correspond\u00eancia\r\n   em System.Linq.Enumerable.First[TSource](IEnumerable`1 source, Func`2 predicate)\r\n   em Deployer.Raspberry.RaspberryPi.<GetDeviceDisk>d__4.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Tasks.DeployWindows.<Execute>d__4.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Execution.ScriptRunner.<Run>d__5.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Execution.ScriptRunner.<Run>d__4.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Raspberry.WoaDeployer.<Deploy>d__3.MoveNext()\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Raspberry.Console.Program.<Execute>d__1.MoveNext() na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Console\\Program.cs:linha 49\r\n--- Fim do rastreamento de pilha do local anterior onde a exce\u00e7\u00e3o foi gerada ---\r\n   em System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\r\n   em System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   em Deployer.Raspberry.Console.Program.<Main>d__0.MoveNext() na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Console\\Program.cs:linha 36\r\n   --- Fim do rastreamento de pilha de exce\u00e7\u00f5es internas ---\r\n   em System.Threading.Tasks.Task.ThrowIfExceptional(Boolean includeTaskCanceledExceptions)\r\n   em System.Threading.Tasks.Task.Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken)\r\n   em Deployer.Raspberry.Gui.App.<>c__DisplayClass2_0.<LaunchConsole>b__0() na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Gui\\App.xaml.cs:linha 40\r\n   em Deployer.Gui.Common.ConsoleEmbedder.ExecuteInsideConsole(Action consoleAction) na D:\\a\\1\\s\\Source\\DeployerPlatform\\Deployer.Gui.Common\\ConsoleEmbedder.cs:linha 33\r\n   em Deployer.Raspberry.Gui.App.LaunchConsole(String[] args) na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Gui\\App.xaml.cs:linha 40\r\n   em Deployer.Raspberry.Gui.App.OnStartup(StartupEventArgs e) na D:\\a\\1\\s\\Source\\Deployer.Raspberry.Gui\\App.xaml.cs:linha 21\r\n   em System.Windows.Application.<.ctor>b__1_0(Object unused)\r\n   em System.Windows.Threading.ExceptionWrapper.InternalRealCall(Delegate callback, Object args, Int32 numArgs)\r\n   em System.Windows.Threading.ExceptionWrapper.TryCatchWhen(Object source, Delegate callback, Object args, Int32 numArgs, Delegate catchHandler)\r\n   em System.Windows.Threading.DispatcherOperation.InvokeImpl()\r\n   em System.Windows.Threading.DispatcherOperation.InvokeInSecurityContext(Object state)\r\n   em MS.Internal.CulturePreservingExecutionContext.CallbackWrapper(Object obj)\r\n   em System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)\r\n   em System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)\r\n   em System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n   em MS.Internal.CulturePreservingExecutionContext.Run(CulturePreservingExecutionContext executionContext, ContextCallback callback, Object state)\r\n   em System.Windows.Threading.DispatcherOperation.Invoke()\r\n   em System.Windows.Threading.Dispatcher.ProcessQueue()\r\n   em System.Windows.Threading.Dispatcher.WndProcHook(IntPtr hwnd, Int32 msg, IntPtr wParam, IntPtr lParam, Boolean& handled)\r\n   em MS.Win32.HwndWrapper.WndProc(IntPtr hwnd, Int32 msg, IntPtr wParam, IntPtr lParam, Boolean& handled)\r\n   em MS.Win32.HwndSubclass.DispatcherCallbackOperation(Object o)\r\n   em System.Windows.Threading.ExceptionWrapper.InternalRealCall(Delegate callback, Object args, Int32 numArgs)\r\n   em System.Windows.Threading.ExceptionWrapper.TryCatchWhen(Object source, Delegate callback, Object args, Int32 numArgs, Delegate catchHandler)\r\n   em System.Windows.Threading.Dispatcher.LegacyInvokeImpl(DispatcherPriority priority, TimeSpan timeout, Delegate method, Object args, Int32 numArgs)\r\n   em MS.Win32.HwndSubclass.SubclassWndProc(IntPtr hwnd, Int32 msg, IntPtr wParam, IntPtr lParam)\r\n   em MS.Win32.UnsafeNativeMethods.DispatchMessage(MSG& msg)\r\n   em System.Windows.Threading.Dispatcher.PushFrameImpl(DispatcherFrame frame)\r\n   em System.Windows.Threading.Dispatcher.PushFrame(DispatcherFrame frame)\r\n   em System.Windows.Application.RunDispatcher(Object ignore)\r\n   em System.Windows.Application.RunInternal(Window window)\r\n   em System.Windows.Application.Run(Window window)\r\n   em Deployer.Raspberry.Gui.App.Main()\r\n```\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Explain how to activate license somewhere","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Tests check that allowed use of `void` is an error","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"http.webdav doesn't work on armv7 ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add HTML legend support","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# [build] Improve N0110 build/flash mechanism\n\n#### Describe the bug\r\nThere is no obvious and easy way to build and flash the firmware with just basic tooling (i.e. dfu-util and a USB cable, not a ST-Link).\r\n\r\n#### To Reproduce\r\nThis is what I had to type to flash a custom firmware for the N0110 through NumWorks's DFU:\r\n```\r\nmake EPSILON_DEVICE_BENCH=0 EPSILON_USB_DFU_XIP=0 EPSILON_ONBOARDING_APP=1 EPSILON_BOOT_PROMPT=update build/device/n0110/epsilon_two_binaries -j\r\nsudo dfu-util -D build/device/n0110/epsilon.internal.bin -s 0x08000000\r\nsudo dfu-util -D build/device/n0110/epsilon.external.bin -s 0x90000000\r\n```\r\n\r\n#### Expected behavior\r\n- [ ] Flashing a new firmware for the N0100 through dfu-util should be a short one-liner.\r\n- [ ] Official documentation should be updated (https://www.numworks.com/resources/engineering/software/sdk/).\r\n\r\n#### While I'm here\r\nI haven't looked too deeply into that yet, but I'm not sure there is a way to reflash from scratch (STM's DFU) both internal and external Flash with unmodified sources and dfu-util. The stock dfu-util utility refuses to flash at a location that is not described in the DFU string descriptor, so it won't let me download/upload the recovery to RAM on both STM's DFU and NumWorks's DFU.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Migrate from imp to importlib","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"End-user bug report","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"xmllint error when building docs","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# signingSecret overrides custom receiver\n\n### Description\r\n\r\nHi! I'm new to using Bolt and Slack in general.\r\nBeen scratching my head over why my custom receiver was not working, and when I looked at the source code in `src/App.tsx` I noticed this:\r\n\r\n```\r\nif (signingSecret !== undefined) {\r\n      this.receiver = new ExpressReceiver({ signingSecret, endpoints });\t      this.receiver = new ExpressReceiver({ signingSecret, logger, endpoints });\r\n    } else if (receiver === undefined) {\t    } \r\n```\r\n\r\nSo I commented out the SigningSecret that I was previously passing and it worked!\r\n\r\nI think the application should either not overwrite the passed receiver, or log a warning in this scenario.\r\n\r\n### What type of issue is this? (place an `x` in one of the `[ ]`)\r\n- [X] bug\r\n- [ ] enhancement (feature request)\r\n- [ ] question\r\n- [X] documentation related\r\n- [ ] testing related\r\n- [ ] discussion\r\n\r\n### Requirements (place an `x` in each of the `[ ]`)\r\n* [X] I've read and understood the [Contributing guidelines](https://github.com/slackapi/bolt/blob/master/.github/contributing.md) and have done my best effort to follow them.\r\n* [X] I've read and agree to the [Code of Conduct](https://slackhq.github.io/code-of-conduct).\r\n* [X] I've searched for any related issues and avoided creating a duplicate issue.\r\n\r\n---\r\n\r\n### Bug Report\r\n\r\nFilling out the following details about bugs will help us solve your issue sooner.\r\n\r\n#### Reproducible in:\r\n\r\npackage version: 1.2.0\r\n\r\nnode version: 12.6.0\r\n\r\nOS version(s): Windows 10 Pro\r\n\r\n#### Steps to reproduce:\r\n\r\n1. Create a custom receiver class\r\n2. Instantiate an App with a custom receiver and signing key\r\n3. Emit an event with the receiver\r\n\r\n#### Expected result:\r\n\r\nBolt doesn't overwrite my receiver with the ExpressReceiver\r\n\r\n#### Actual result:\r\n\r\nBolt overwrites my receiver with the ExpressReceiver\r\n\r\n#### Attachments:\r\n\r\nhttps://github.com/slackapi/bolt/blob/522e70b381cf3d18a88b7ca271dcfb4f0ce1be9b/src/App.ts#L161","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Id generation ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"readme images","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Outdated README?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update home page with developer tool info","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Add license badge to readme","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"could you share how to install is plugin?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Language starter specs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Documentation or example of creating an object with a Generic Relationship?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"License?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Setting up Heroku Server documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# SqlSetup: Localized string TestFailedAfterSet should reference link to check bootstrap logs\n\nText should be added to tell to look for reported errors from the setup.exe in the logs. Reference the article https://docs.microsoft.com/en-us/sql/database-engine/install-windows/view-and-read-sql-server-setup-log-files for help.\r\n\r\nhttps://github.com/PowerShell/SqlServerDsc/blob/2337c7cbaa9c47d5bf82802ec77167922ec892b6/DSCResources/MSFT_SqlSetup/en-US/MSFT_SqlSetup.strings.psd1#L58\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# absda\n\n# Azure documentation issue guidance\r\n\r\nThanks for opening an issue in the Azure technical documentation repository. \r\n\r\nWe use GitHub issues as the primary channel for customer and community feedback about the Azure documentation.\r\n\r\n## Creating an issue\r\n\r\nWe prefer that you create documentation feedback issues using the Feedback link on the published article - the feedback control on the doc page creates an issue that contains all the article details so you can focus on the feedback part.\r\n\r\nYou can also create a feedback issue here in the repo. If you do this, please make sure your issue lists:\r\n\r\n- [ ] The relevant Azure service or technology. \r\n- [ ] A link to the published documentation article that you have feedback about.\r\n- [ ] Clear, specific feedback that the author can act on.\r\n\r\n## Pull requests and article contributions\r\n\r\nIf you know the change that is needed in an article, we encourage you to submit the changes directly using a pull request. If the change is large, or if you want to contribute an entire article, follow these guidelines:\r\n\r\n- [ ] Don't surprise us with a big pull request or a pull request with a new article! Submit an issue that describes the details of the proposed large change or new article. \r\n- [ ] Include the service or technology area.\r\n\r\nWe'll route the issue to the appropriate content team for review and discussion.\r\n\r\n## Tech support and product feedback\r\nIf you would like to contact Microsoft about other things, such as product feedback or tech support, please review these guidelines:\r\n\r\n- If you need technical support using Azure, the paid and free support options are described here: https://azure.microsoft.com/support/options/.\r\n\r\n- Each article in the Azure technical documentation contains a product feedback button - it's best to submit product feedback directly from a relevant article. Otherwise, you can submit product feedback for most Azure products in the following product feedback forum: https://feedback.azure.com/forums/34192--general-feedback.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Does esdoc-typescript-plugin allow me to hand write JSDoc/TSDoc without types getting in the way?\n\nI have \"mixin classes\" (class-factory mixins), but I just want to document them as regular classes, and use things like `@mixes` (or similar) to describe what they inherit from. I don't care about having to duplicate types in my comments, if it means I can have control and can shape the documentation output by hand.\r\n\r\nThe reason is, the end use case of my (mixin) classes is for them to be custom elements. The mixin functionality is only for combining classes together during implementation mostly (though a discerning intellisense user will be able to pick up on and use the mixin patterns).\r\n\r\nBasically, I have classes that can be used like this:\r\n\r\n```ts\r\nimport {Transformable} from './Transformable'\r\n\r\n// instantiate one:\r\nconst f = new Transformable\r\n\r\n// extend it like a regular class\r\nclass Foo extends Transformable {}\r\n\r\n// or mix it with other classes:\r\nclass Bar {}\r\nclass Baz extends Transformable.mixin(Bar) {}\r\n```\r\n\r\nWhere I want to document the Transformable class something like the following:\r\n\r\n```ts\r\nimport {TreeNode} from './TreeNode'\r\nimport {Sizeable} from './Sizeable'\r\nimport {Constructor, Mixin, MixinResult} from 'lowclass'\r\n\r\n/**\r\n * @class Transformable\r\n * @mixin\r\n * @mixes TreeNode\r\n * @mixes Sizeable\r\n */\r\nfunction TransformableMixin<T extends Constructor>(Base: T) {\r\n\r\n    // The Transformable mixin class is composed from TreeNode and Sizeable mixin classes\r\n    const Parent = TreeNode.mixin(Sizeable.mixin(Constructor(Base)))\r\n\r\n    class Transformable extends Parent {\r\n        /**\r\n         * Set the position of the Transformable.\r\n         *\r\n         * @property position\r\n         * @memberof Transformable\r\n         * @type {SomeType}\r\n         */\r\n        set position(newValue: any) {\r\n            this._setPropertyXYZ<Transformable, TransformProp>('position', newValue)\r\n        }\r\n        get position(): any {\r\n            return this._props.position\r\n        }\r\n\r\n        // ... etc ...\r\n    }\r\n\r\n    return Transformable as MixinResult<typeof Transformable, T>\r\n}\r\n\r\n// this actually creates the class reference.\r\nexport const Transformable = Mixin(TransformableMixin)\r\nexport interface Transformable extends InstanceType<typeof Transformable> {}\r\n```\r\n\r\nSee what I'm trying to do there?\r\n\r\nBasically, I'd like to use `@mixes` (or something) for multiple inheritance. I'd like to be able to represent this in the docs somehow (f.e. like one class with multiple arrows pointing to the other classes, or something).\r\n\r\nIn the end, a user will only use the class instances directly, and won't necessarily even need to know about the mixin functionality:\r\n\r\n```js\r\n// `mesh` inherits from Transformable, and possibly from something else.\r\nconst mesh = document.querySelector('box-mesh')\r\n\r\n// but in the end, the user reading docs just needs to know about the classes, and their inherited properties.\r\n// Under the hood the instances are composed from mixin classes, but that's not important here, and things like\r\n// TypeDoc try to document every aspect possible, including mixin machinery.\r\n\r\n// The user just needs to do this, for example:\r\nmesh.position = {y: 20}\r\n```\r\n\r\nSo I'm aiming to make the docs really simple. I really don't want to throw an HTML beginner at some TypeDoc docs (I hope you know what I mean).\r\n\r\nSeems like what I need is for some parser to parse JSDoc comments out of my TypeScript files, then I should handle the rest myself? I've had no luck with that so far.\r\n\r\nAny ideas?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"There is a bug when you click the number in the center of the dialog.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Dashes in headings","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Having 404 page in different languages\n\nI see in gatsby-node.js there is this condition that avoids generating multilingual pages for the 404 page. \r\n\r\n```\r\n// Only create one 404 page at /404.html\r\n    if (page.path.includes('404')) {\r\n      return\r\n    }\r\n```\r\n\r\nBut running `gatsby build` generates the following error. \r\n```\r\nBuilding static HTML failed for path \"/404/\"\r\n\r\nSee our docs page for more info on this error: https://gatsby.dev/debug-html\r\n\r\n\r\n  21 |               <span id=\"opening\">\r\n  22 |                 <i className=\" icon-clock-1\"></i>\r\n> 23 |                 {i18n.schedule}\r\n     |                       ^\r\n  24 |               </span>\r\n  25 |             </div>\r\n  26 |\r\n\r\n\r\n  WebpackError: TypeError: Cannot read property 'schedule' of undefined\r\n```\r\n\r\nI guess this is happening because no `locale` is defined so that the `i18n` translations are not available. \r\n\r\nIs there any possibility to make the 404 pages translatable in every language? \r\n\r\nDoes anyone have a nice approach to solving this? ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"NITRO Compilation under Windos 7 and Visual Studio 2010","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Exclude expired assets from search results\n\n**Question?**\r\n* What piece of functionality do you have a question about?\r\n* What are you trying to achieve?\r\n\r\nDocumentation can be found here: https://adobe-marketing-cloud.github.io/asset-share-commons/. It might answer your question!\r\n\r\n\r\nHi ,\r\n\r\nI have same kind of requirement where i expired assets should not show up on landing page(home page) but when i will search them through property filter then expired assets should display with other assets.\r\nTo achieve this i have excluded expired assets from search restrictions but now the issue i am facing is that i am not even able to search them through search filter.\r\nHow should i achieve this scenario?\r\nWill hidden filter help me out in this cas\r\n\r\nThanks,\r\nLovepreet","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Documentation missing for Selenium Html Runner","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Minecraft Version Field doesn't have any options.\n\n<!--\r\nAfter reading this section, fill out the fields below.\r\n\r\nPlease note that this is the issue tracker for TechnicSolder, and NOT the place to\r\npost problems opening/installing/managing any modpacks/mods/java/anything else.\r\n\r\nIf you are having issues installing or opening a modpack, ask for assistance in the #help\r\nchannel of the Technic discord server.\r\n\r\nIf the launcher is crashing, make an issue here: https://github.com/TechnicPack/TechnicLauncher\r\n\r\nIf you are having issues managing a pack, or having any issues with the\r\nplatform or website, ask for help here: http://www.technicpack.net/help\r\n\r\n\r\nGUIDELINES TO FOLLOW WHEN REPORTING:\r\n\r\nPlease be aware that Solder is intended for experienced server admins only, and so it is\r\nexpected that you've at least tried to research an issue before reporting it.\r\n\r\nNote that Windows is not officially supported. (Though some community members may help)\r\n\r\nPlease try to be respectful when reporting an issue. We understand that bugs are\r\nfrustrating, but getting mad will only make it harder to fix.\r\n\r\nPlease fill out all other information to the best of your knowledge.\r\n-->\r\n\r\n  Solder Repo Hash:\r\n\r\n  Operating System and version: Fedora 30 (server)\r\n\r\n  PHP version: 7.3.7\r\n\r\n<!-- Can be found by running ```php -v``` -->\r\n  Composer version: 1.9.0\r\n\r\n<!-- Can be found using composer -v -->\r\n  Server type: \r\n\r\n  Type of database: SQLite\r\n\r\n<!-- Are you using MySQL, or Sqlite? -->\r\n  Type of hosting: Personal Shared\r\n\r\n<!-- Shared? VPS? Dedi? Cloud? -->\r\n  Link to the affected install's public url: solder.binaryaura.net/\r\n\r\n<!-- The URL to your Solder's public folder --> repo.binaryaura.net/solder\r\n---------------------------------------------------------\r\n\r\n<!-- Please describe the issue you are having in as much detail as possible here -->\r\nI'm not sure if I'm doing something in the wrong order, or I've put something in the wrong place, but the field 'Minecraft Version' the field below has no options to choose. I was give more information but, I'm getting no errors and I have no documentation to point me in the right direction. Any direction at all would be appreciated.\r\nThank-you.\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Problem connecting to Acquia DevDesktop local site","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"python3 Question","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Allow rendering of choral page even if there is no data","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Several tests fail on Windows with 0.4.0\n\nTest log:\r\n```\r\n============================= test session starts =============================\r\nplatform win32 -- Python 3.7.4, pytest-5.0.1, py-1.8.0, pluggy-0.12.0\r\nrootdir: C:\\w\\2\\s\\packaging\\windows\\vision\r\ncollected 187 items\r\n\r\ntest\\test_backbone_utils.py ..                                           [  1%]\r\ntest\\test_cpp_models.py FFFFF..FFFF........FFFFFFFFFF..                  [ 17%]\r\ntest\\test_datasets.py ..F......                                          [ 22%]\r\ntest\\test_datasets_transforms.py ..                                      [ 23%]\r\ntest\\test_datasets_utils.py .....FFF.                                    [ 28%]\r\ntest\\test_datasets_video_utils.py ..FFss                                 [ 31%]\r\ntest\\test_io.py .FFFFF                                                   [ 34%]\r\ntest\\test_models.py ................................................     [ 60%]\r\ntest\\test_ops.py ..s..s.s.s.s.s.s.s.s                                    [ 71%]\r\ntest\\test_transforms.py ..........sss................................... [ 96%]\r\n..                                                                       [ 97%]\r\ntest\\test_utils.py ..FF                                                  [100%]\r\n\r\n================================== FAILURES ===================================\r\n_____________________________ Tester.test_alexnet _____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_alexnet>\r\n\r\n    def test_alexnet(self):\r\n>       process_model(models.alexnet(self.pretrained), self.image, _C_tests.forward_alexnet, 'Alexnet')\r\n\r\ntest\\test_cpp_models.py:43: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = AlexNet(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\r\n    (1)...ures=4096, bias=True)\r\n    (5): ReLU(inplace=True)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_alexnet of PyCapsule object at 0x000000323C5E9450>\r\nname = 'Alexnet'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_densenet121 ___________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_densenet121>\r\n\r\n    def test_densenet121(self):\r\n>       process_model(models.densenet121(self.pretrained), self.image, _C_tests.forward_densenet121, 'Densenet121')\r\n\r\ntest\\test_cpp_models.py:105: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = DenseNet(\r\n  (features): Sequential(\r\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias....1, affine=True, track_running_stats=True)\r\n  )\r\n  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_densenet121 of PyCapsule object at 0x000000323C6005A0>\r\nname = 'Densenet121'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_densenet161 ___________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_densenet161>\r\n\r\n    def test_densenet161(self):\r\n>       process_model(models.densenet161(self.pretrained), self.image, _C_tests.forward_densenet161, 'Densenet161')\r\n\r\ntest\\test_cpp_models.py:114: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = DenseNet(\r\n  (features): Sequential(\r\n    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias....1, affine=True, track_running_stats=True)\r\n  )\r\n  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_densenet161 of PyCapsule object at 0x000000323C600BD0>\r\nname = 'Densenet161'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_densenet169 ___________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_densenet169>\r\n\r\n    def test_densenet169(self):\r\n>       process_model(models.densenet169(self.pretrained), self.image, _C_tests.forward_densenet169, 'Densenet169')\r\n\r\ntest\\test_cpp_models.py:108: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = DenseNet(\r\n  (features): Sequential(\r\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias....1, affine=True, track_running_stats=True)\r\n  )\r\n  (classifier): Linear(in_features=1664, out_features=1000, bias=True)\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_densenet169 of PyCapsule object at 0x000000323C6008D0>\r\nname = 'Densenet169'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_densenet201 ___________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_densenet201>\r\n\r\n    def test_densenet201(self):\r\n>       process_model(models.densenet201(self.pretrained), self.image, _C_tests.forward_densenet201, 'Densenet201')\r\n\r\ntest\\test_cpp_models.py:111: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = DenseNet(\r\n  (features): Sequential(\r\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias....1, affine=True, track_running_stats=True)\r\n  )\r\n  (classifier): Linear(in_features=1920, out_features=1000, bias=True)\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_densenet201 of PyCapsule object at 0x000000323C600B70>\r\nname = 'Densenet201'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_mnasnet0_5 ____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_mnasnet0_5>\r\n\r\n    def test_mnasnet0_5(self):\r\n>       process_model(models.mnasnet0_5(self.pretrained), self.image, _C_tests.forward_mnasnet0_5, 'MNASNet0_5')\r\n\r\ntest\\test_cpp_models.py:123: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = MNASNet(\r\n  (layers): Sequential(\r\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)...Sequential(\r\n    (0): Dropout(p=0.2, inplace=True)\r\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_mnasnet0_5 of PyCapsule object at 0x000000323C6009F0>\r\nname = 'MNASNet0_5'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_mnasnet0_75 ___________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_mnasnet0_75>\r\n\r\n    def test_mnasnet0_75(self):\r\n>       process_model(models.mnasnet0_75(self.pretrained), self.image, _C_tests.forward_mnasnet0_75, 'MNASNet0_75')\r\n\r\ntest\\test_cpp_models.py:126: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = MNASNet(\r\n  (layers): Sequential(\r\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)...Sequential(\r\n    (0): Dropout(p=0.2, inplace=True)\r\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_mnasnet0_75 of PyCapsule object at 0x000000323C600A80>\r\nname = 'MNASNet0_75'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_mnasnet1_0 ____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_mnasnet1_0>\r\n\r\n    def test_mnasnet1_0(self):\r\n>       process_model(models.mnasnet1_0(self.pretrained), self.image, _C_tests.forward_mnasnet1_0, 'MNASNet1_0')\r\n\r\ntest\\test_cpp_models.py:129: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = MNASNet(\r\n  (layers): Sequential(\r\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)...Sequential(\r\n    (0): Dropout(p=0.2, inplace=True)\r\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_mnasnet1_0 of PyCapsule object at 0x000000323C8A9570>\r\nname = 'MNASNet1_0'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_mnasnet1_3 ____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_mnasnet1_3>\r\n\r\n    def test_mnasnet1_3(self):\r\n>       process_model(models.mnasnet1_3(self.pretrained), self.image, _C_tests.forward_mnasnet1_3, 'MNASNet1_3')\r\n\r\ntest\\test_cpp_models.py:132: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = MNASNet(\r\n  (layers): Sequential(\r\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)...Sequential(\r\n    (0): Dropout(p=0.2, inplace=True)\r\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_mnasnet1_3 of PyCapsule object at 0x000000323C8A9060>\r\nname = 'MNASNet1_3'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n__________________________ Tester.test_squeezenet1_0 __________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_squeezenet1_0>\r\n\r\n    def test_squeezenet1_0(self):\r\n        process_model(models.squeezenet1_0(self.pretrained), self.image,\r\n>                     _C_tests.forward_squeezenet1_0, 'Squeezenet1.0')\r\n\r\ntest\\test_cpp_models.py:98: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = SqueezeNet(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\r\n    (1): ReLU(inplace=...00, kernel_size=(1, 1), stride=(1, 1))\r\n    (2): ReLU(inplace=True)\r\n    (3): AdaptiveAvgPool2d(output_size=(1, 1))\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_squeezenet1_0 of PyCapsule object at 0x000000323C600F60>\r\nname = 'Squeezenet1.0'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n__________________________ Tester.test_squeezenet1_1 __________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_squeezenet1_1>\r\n\r\n    def test_squeezenet1_1(self):\r\n        process_model(models.squeezenet1_1(self.pretrained), self.image,\r\n>                     _C_tests.forward_squeezenet1_1, 'Squeezenet1.1')\r\n\r\ntest\\test_cpp_models.py:102: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = SqueezeNet(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\r\n    (1): ReLU(inplace=...00, kernel_size=(1, 1), stride=(1, 1))\r\n    (2): ReLU(inplace=True)\r\n    (3): AdaptiveAvgPool2d(output_size=(1, 1))\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_squeezenet1_1 of PyCapsule object at 0x000000323C600D50>\r\nname = 'Squeezenet1.1'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n______________________________ Tester.test_vgg11 ______________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg11>\r\n\r\n    def test_vgg11(self):\r\n>       process_model(models.vgg11(self.pretrained), self.image, _C_tests.forward_vgg11, 'VGG11')\r\n\r\ntest\\test_cpp_models.py:46: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): ReLU...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg11 of PyCapsule object at 0x000000323C5E97B0>\r\nname = 'VGG11'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n____________________________ Tester.test_vgg11_bn _____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg11_bn>\r\n\r\n    def test_vgg11_bn(self):\r\n>       process_model(models.vgg11_bn(self.pretrained), self.image, _C_tests.forward_vgg11bn, 'VGG11BN')\r\n\r\ntest\\test_cpp_models.py:58: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): Batc...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg11bn of PyCapsule object at 0x000000323C5B5F30>\r\nname = 'VGG11BN'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torch\\include\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n______________________________ Tester.test_vgg13 ______________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg13>\r\n\r\n    def test_vgg13(self):\r\n>       process_model(models.vgg13(self.pretrained), self.image, _C_tests.forward_vgg13, 'VGG13')\r\n\r\ntest\\test_cpp_models.py:49: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): ReLU...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg13 of PyCapsule object at 0x000000323C5E97E0>\r\nname = 'VGG13'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n____________________________ Tester.test_vgg13_bn _____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg13_bn>\r\n\r\n    def test_vgg13_bn(self):\r\n>       process_model(models.vgg13_bn(self.pretrained), self.image, _C_tests.forward_vgg13bn, 'VGG13BN')\r\n\r\ntest\\test_cpp_models.py:61: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): Batc...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg13bn of PyCapsule object at 0x000000323C5B5E40>\r\nname = 'VGG13BN'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n______________________________ Tester.test_vgg16 ______________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg16>\r\n\r\n    def test_vgg16(self):\r\n>       process_model(models.vgg16(self.pretrained), self.image, _C_tests.forward_vgg16, 'VGG16')\r\n\r\ntest\\test_cpp_models.py:52: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): ReLU...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg16 of PyCapsule object at 0x000000323C5E9990>\r\nname = 'VGG16'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n____________________________ Tester.test_vgg16_bn _____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg16_bn>\r\n\r\n    def test_vgg16_bn(self):\r\n>       process_model(models.vgg16_bn(self.pretrained), self.image, _C_tests.forward_vgg16bn, 'VGG16BN')\r\n\r\ntest\\test_cpp_models.py:64: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): Batc...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg16bn of PyCapsule object at 0x000000323C5B5EA0>\r\nname = 'VGG16BN'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n______________________________ Tester.test_vgg19 ______________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg19>\r\n\r\n    def test_vgg19(self):\r\n>       process_model(models.vgg19(self.pretrained), self.image, _C_tests.forward_vgg19, 'VGG19')\r\n\r\ntest\\test_cpp_models.py:55: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): ReLU...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg19 of PyCapsule object at 0x000000323C5B5ED0>\r\nname = 'VGG19'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n____________________________ Tester.test_vgg19_bn _____________________________\r\n\r\nself = <test_cpp_models.Tester testMethod=test_vgg19_bn>\r\n\r\n    def test_vgg19_bn(self):\r\n>       process_model(models.vgg19_bn(self.pretrained), self.image, _C_tests.forward_vgg19bn, 'VGG19BN')\r\n\r\ntest\\test_cpp_models.py:67: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nmodel = VGG(\r\n  (features): Sequential(\r\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (1): Batc...lace=True)\r\n    (5): Dropout(p=0.5, inplace=False)\r\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\r\n  )\r\n)\r\ntensor = tensor([[[[0.0902, 0.1098, 0.1216,  ..., 0.2824, 0.2314, 0.2392],\r\n          [0.0980, 0.0863, 0.1020,  ..., 0.3333, 0.3...20, 0.1059, 0.0980,  ..., 0.0667, 0.0784, 0.0706],\r\n          [0.1059, 0.0941, 0.0980,  ..., 0.0588, 0.0667, 0.0667]]]])\r\nfunc = <built-in method forward_vgg19bn of PyCapsule object at 0x000000323C5B5C90>\r\nname = 'VGG19BN'\r\n\r\n    def process_model(model, tensor, func, name):\r\n        model.eval()\r\n        traced_script_module = torch.jit.trace(model, tensor)\r\n        traced_script_module.save(\"model.pt\")\r\n    \r\n        py_output = model.forward(tensor)\r\n>       cpp_output = func(\"model.pt\", tensor)\r\nE       RuntimeError: undefined Tensor (infer_is_variable at C:\\w\\1\\s\\windows\\pytorch\\build\\aten\\src\\ATen/Functions.h:1149)\r\nE       (no backtrace available)\r\n\r\ntest\\test_cpp_models.py:16: RuntimeError\r\n___________________________ Tester.test_cityscapes ____________________________\r\n\r\nself = <test_datasets.Tester testMethod=test_cityscapes>\r\n\r\n    def test_cityscapes(self):\r\n        with cityscapes_root() as root:\r\n    \r\n            for mode in ['coarse', 'fine']:\r\n    \r\n                if mode == 'coarse':\r\n                    splits = ['train', 'train_extra', 'val']\r\n                else:\r\n                    splits = ['train', 'val', 'test']\r\n    \r\n                for split in splits:\r\n                    for target_type in ['semantic', 'instance']:\r\n                        dataset = torchvision.datasets.Cityscapes(root, split=split,\r\n                                                                  target_type=target_type, mode=mode)\r\n                        self.generic_segmentation_dataset_test(dataset, num_images=2)\r\n    \r\n                    color_dataset = torchvision.datasets.Cityscapes(root, split=split,\r\n                                                                    target_type='color', mode=mode)\r\n                    color_img, color_target = color_dataset[0]\r\n                    self.assertTrue(isinstance(color_img, PIL.Image.Image))\r\n                    self.assertTrue(np.array(color_target).shape[2] == 4)\r\n    \r\n                    polygon_dataset = torchvision.datasets.Cityscapes(root, split=split,\r\n                                                                      target_type='polygon', mode=mode)\r\n                    polygon_img, polygon_target = polygon_dataset[0]\r\n                    self.assertTrue(isinstance(polygon_img, PIL.Image.Image))\r\n                    self.assertTrue(isinstance(polygon_target, dict))\r\n                    self.assertTrue(isinstance(polygon_target['imgHeight'], int))\r\n                    self.assertTrue(isinstance(polygon_target['objects'], list))\r\n    \r\n                    # Test multiple target types\r\n                    targets_combo = ['semantic', 'polygon', 'color']\r\n                    multiple_types_dataset = torchvision.datasets.Cityscapes(root, split=split,\r\n                                                                             target_type=targets_combo,\r\n                                                                             mode=mode)\r\n                    output = multiple_types_dataset[0]\r\n                    self.assertTrue(isinstance(output, tuple))\r\n                    self.assertTrue(len(output) == 2)\r\n                    self.assertTrue(isinstance(output[0], PIL.Image.Image))\r\n                    self.assertTrue(isinstance(output[1], tuple))\r\n                    self.assertTrue(len(output[1]) == 3)\r\n                    self.assertTrue(isinstance(output[1][0], PIL.Image.Image))  # semantic\r\n                    self.assertTrue(isinstance(output[1][1], dict))  # polygon\r\n>                   self.assertTrue(isinstance(output[1][2], PIL.Image.Image))  # color\r\n\r\ntest\\test_datasets.py:195: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:119: in __exit__\r\n    next(self.gen)\r\ntest\\fakedata_generation.py:243: in cityscapes_root\r\n    yield tmp_dir\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:119: in __exit__\r\n    next(self.gen)\r\ntest\\common_utils.py:16: in get_tmp_dir\r\n    shutil.rmtree(tmp_dir)\r\n..\\conda\\envs\\py37\\lib\\shutil.py:516: in rmtree\r\n    return _rmtree_unsafe(path, onerror)\r\n..\\conda\\envs\\py37\\lib\\shutil.py:395: in _rmtree_unsafe\r\n    _rmtree_unsafe(fullname, onerror)\r\n..\\conda\\envs\\py37\\lib\\shutil.py:395: in _rmtree_unsafe\r\n    _rmtree_unsafe(fullname, onerror)\r\n..\\conda\\envs\\py37\\lib\\shutil.py:395: in _rmtree_unsafe\r\n    _rmtree_unsafe(fullname, onerror)\r\n..\\conda\\envs\\py37\\lib\\shutil.py:400: in _rmtree_unsafe\r\n    onerror(os.unlink, fullname, sys.exc_info())\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\npath = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmp5etnebcf\\\\gtFine\\\\test\\\\bochum'\r\nonerror = <function rmtree.<locals>.onerror at 0x000000323F3BFDC8>\r\n\r\n    def _rmtree_unsafe(path, onerror):\r\n        try:\r\n            with os.scandir(path) as scandir_it:\r\n                entries = list(scandir_it)\r\n        except OSError:\r\n            onerror(os.scandir, path, sys.exc_info())\r\n            entries = []\r\n        for entry in entries:\r\n            fullname = entry.path\r\n            try:\r\n                is_dir = entry.is_dir(follow_symlinks=False)\r\n            except OSError:\r\n                is_dir = False\r\n            if is_dir:\r\n                try:\r\n                    if entry.is_symlink():\r\n                        # This can only happen if someone replaces\r\n                        # a directory with a symlink after the call to\r\n                        # os.scandir or entry.is_dir above.\r\n                        raise OSError(\"Cannot call rmtree on a symbolic link\")\r\n                except OSError:\r\n                    onerror(os.path.islink, fullname, sys.exc_info())\r\n                    continue\r\n                _rmtree_unsafe(fullname, onerror)\r\n            else:\r\n                try:\r\n>                   os.unlink(fullname)\r\nE                   PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmp5etnebcf\\\\gtFine\\\\test\\\\bochum\\\\bochum_000000_000000_gtFine_color.png'\r\n\r\n..\\conda\\envs\\py37\\lib\\shutil.py:398: PermissionError\r\n__________________________ Tester.test_extract_gzip ___________________________\r\n\r\nself = <test_datasets_utils.Tester testMethod=test_extract_gzip>\r\n\r\n    def test_extract_gzip(self):\r\n        with get_tmp_dir() as temp_dir:\r\n            with tempfile.NamedTemporaryFile(suffix='.gz') as f:\r\n>               with gzip.GzipFile(f.name, 'wb') as zf:\r\n\r\ntest\\test_datasets_utils.py:101: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <[AttributeError(\"'GzipFile' object has no attribute 'fileobj'\") raised in repr()] GzipFile object at 0x32007d28c8>\r\nfilename = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpc1wq6shu.gz'\r\nmode = 'wb', compresslevel = 9, fileobj = None, mtime = None\r\n\r\n    def __init__(self, filename=None, mode=None,\r\n                 compresslevel=9, fileobj=None, mtime=None):\r\n        \"\"\"Constructor for the GzipFile class.\r\n    \r\n        At least one of fileobj and filename must be given a\r\n        non-trivial value.\r\n    \r\n        The new class instance is based on fileobj, which can be a regular\r\n        file, an io.BytesIO object, or any other object which simulates a file.\r\n        It defaults to None, in which case filename is opened to provide\r\n        a file object.\r\n    \r\n        When fileobj is not None, the filename argument is only used to be\r\n        included in the gzip file header, which may include the original\r\n        filename of the uncompressed file.  It defaults to the filename of\r\n        fileobj, if discernible; otherwise, it defaults to the empty string,\r\n        and in this case the original filename is not included in the header.\r\n    \r\n        The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or\r\n        'xb' depending on whether the file will be read or written.  The default\r\n        is the mode of fileobj if discernible; otherwise, the default is 'rb'.\r\n        A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and\r\n        'wb', 'a' and 'ab', and 'x' and 'xb'.\r\n    \r\n        The compresslevel argument is an integer from 0 to 9 controlling the\r\n        level of compression; 1 is fastest and produces the least compression,\r\n        and 9 is slowest and produces the most compression. 0 is no compression\r\n        at all. The default is 9.\r\n    \r\n        The mtime argument is an optional numeric timestamp to be written\r\n        to the last modification time field in the stream when compressing.\r\n        If omitted or None, the current time is used.\r\n    \r\n        \"\"\"\r\n    \r\n        if mode and ('t' in mode or 'U' in mode):\r\n            raise ValueError(\"Invalid mode: {!r}\".format(mode))\r\n        if mode and 'b' not in mode:\r\n            mode += 'b'\r\n        if fileobj is None:\r\n>           fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\r\nE           PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpc1wq6shu.gz'\r\n\r\n..\\conda\\envs\\py37\\lib\\gzip.py:163: PermissionError\r\n___________________________ Tester.test_extract_tar ___________________________\r\n\r\nself = <test_datasets_utils.Tester testMethod=test_extract_tar>\r\n\r\n    def test_extract_tar(self):\r\n        for ext, mode in zip(['.tar', '.tar.gz'], ['w', 'w:gz']):\r\n            with get_tmp_dir() as temp_dir:\r\n                with tempfile.NamedTemporaryFile() as bf:\r\n                    bf.write(\"this is the content\".encode())\r\n                    bf.seek(0)\r\n                    with tempfile.NamedTemporaryFile(suffix=ext) as f:\r\n>                       with tarfile.open(f.name, mode=mode) as zf:\r\n\r\ntest\\test_datasets_utils.py:90: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\tarfile.py:1611: in open\r\n    return cls.taropen(name, mode, fileobj, **kwargs)\r\n..\\conda\\envs\\py37\\lib\\tarfile.py:1621: in taropen\r\n    return cls(name, mode, fileobj, **kwargs)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <tarfile.TarFile object at 0x0000003200A91AC8>\r\nname = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmplby3znrd.tar', mode = 'w'\r\nfileobj = None, format = None, tarinfo = None, dereference = None\r\nignore_zeros = None, encoding = None, errors = 'surrogateescape'\r\npax_headers = None, debug = None, errorlevel = None, copybufsize = None\r\n\r\n    def __init__(self, name=None, mode=\"r\", fileobj=None, format=None,\r\n            tarinfo=None, dereference=None, ignore_zeros=None, encoding=None,\r\n            errors=\"surrogateescape\", pax_headers=None, debug=None,\r\n            errorlevel=None, copybufsize=None):\r\n        \"\"\"Open an (uncompressed) tar archive `name'. `mode' is either 'r' to\r\n           read from an existing archive, 'a' to append data to an existing\r\n           file or 'w' to create a new file overwriting an existing one. `mode'\r\n           defaults to 'r'.\r\n           If `fileobj' is given, it is used for reading or writing data. If it\r\n           can be determined, `mode' is overridden by `fileobj's mode.\r\n           `fileobj' is not closed, when TarFile is closed.\r\n        \"\"\"\r\n        modes = {\"r\": \"rb\", \"a\": \"r+b\", \"w\": \"wb\", \"x\": \"xb\"}\r\n        if mode not in modes:\r\n            raise ValueError(\"mode must be 'r', 'a', 'w' or 'x'\")\r\n        self.mode = mode\r\n        self._mode = modes[mode]\r\n    \r\n        if not fileobj:\r\n            if self.mode == \"a\" and not os.path.exists(name):\r\n                # Create nonexistent files in append mode.\r\n                self.mode = \"w\"\r\n                self._mode = \"wb\"\r\n>           fileobj = bltn_open(name, self._mode)\r\nE           PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmplby3znrd.tar'\r\n\r\n..\\conda\\envs\\py37\\lib\\tarfile.py:1436: PermissionError\r\n___________________________ Tester.test_extract_zip ___________________________\r\n\r\nself = <test_datasets_utils.Tester testMethod=test_extract_zip>\r\n\r\n    def test_extract_zip(self):\r\n        with get_tmp_dir() as temp_dir:\r\n            with tempfile.NamedTemporaryFile(suffix='.zip') as f:\r\n                with zipfile.ZipFile(f, 'w') as zf:\r\n                    zf.writestr('file.tst', 'this is the content')\r\n>               utils.extract_archive(f.name, temp_dir)\r\n\r\ntest\\test_datasets_utils.py:77: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\utils.py:231: in extract_archive\r\n    with zipfile.ZipFile(from_path, 'r') as z:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <zipfile.ZipFile [closed]>\r\nfile = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpiwmc4x4z.zip', mode = 'r'\r\ncompression = 0, allowZip64 = True, compresslevel = None\r\n\r\n    def __init__(self, file, mode=\"r\", compression=ZIP_STORED, allowZip64=True,\r\n                 compresslevel=None):\r\n        \"\"\"Open the ZIP file with mode read 'r', write 'w', exclusive create 'x',\r\n        or append 'a'.\"\"\"\r\n        if mode not in ('r', 'w', 'x', 'a'):\r\n            raise ValueError(\"ZipFile requires mode 'r', 'w', 'x', or 'a'\")\r\n    \r\n        _check_compression(compression)\r\n    \r\n        self._allowZip64 = allowZip64\r\n        self._didModify = False\r\n        self.debug = 0  # Level of printing: 0 through 3\r\n        self.NameToInfo = {}    # Find file info given name\r\n        self.filelist = []      # List of ZipInfo instances for archive\r\n        self.compression = compression  # Method of compression\r\n        self.compresslevel = compresslevel\r\n        self.mode = mode\r\n        self.pwd = None\r\n        self._comment = b''\r\n    \r\n        # Check if we were passed a file-like object\r\n        if isinstance(file, os.PathLike):\r\n            file = os.fspath(file)\r\n        if isinstance(file, str):\r\n            # No, it's a filename\r\n            self._filePassed = 0\r\n            self.filename = file\r\n            modeDict = {'r' : 'rb', 'w': 'w+b', 'x': 'x+b', 'a' : 'r+b',\r\n                        'r+b': 'w+b', 'w+b': 'wb', 'x+b': 'xb'}\r\n            filemode = modeDict[mode]\r\n            while True:\r\n                try:\r\n>                   self.fp = io.open(file, filemode)\r\nE                   PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpiwmc4x4z.zip'\r\n\r\n..\\conda\\envs\\py37\\lib\\zipfile.py:1207: PermissionError\r\n___________________________ Tester.test_video_clips ___________________________\r\n\r\nself = <test_datasets_video_utils.Tester testMethod=test_video_clips>\r\n\r\n    def test_video_clips(self):\r\n        with get_list_of_videos(num_videos=3) as video_list:\r\n>           video_clips = VideoClips(video_list, 5, 5)\r\n\r\ntest\\test_datasets_video_utils.py:62: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\video_utils.py:55: in __init__\r\n    self._compute_frame_pts()\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\video_utils.py:84: in _compute_frame_pts\r\n    for batch in dl:\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:278: in __iter__\r\n    return _MultiProcessingDataLoaderIter(self)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:682: in __init__\r\n    w.start()\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\process.py:112: in start\r\n    self._popen = self._Popen(self)\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\context.py:223: in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\context.py:322: in _Popen\r\n    return Popen(process_obj)\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\popen_spawn_win32.py:89: in __init__\r\n    reduction.dump(process_obj, to_child)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nobj = <Process(Process-1, initial daemon)>, file = <_io.BufferedWriter name=10>\r\nprotocol = None\r\n\r\n    def dump(obj, file, protocol=None):\r\n        '''Replacement for pickle.dump() using ForkingPickler.'''\r\n>       ForkingPickler(file, protocol).dump(obj)\r\nE       AttributeError: Can't pickle local object 'VideoClips._compute_frame_pts.<locals>.DS'\r\n\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\reduction.py:60: AttributeError\r\n---------------------------- Captured stderr call -----------------------------\r\n\r\n_____________________ Tester.test_video_clips_custom_fps ______________________\r\n\r\nself = <test_datasets_video_utils.Tester testMethod=test_video_clips_custom_fps>\r\n\r\n    def test_video_clips_custom_fps(self):\r\n        with get_list_of_videos(num_videos=3, sizes=[12, 12, 12], fps=[3, 4, 6]) as video_list:\r\n            num_frames = 4\r\n            for fps in [1, 3, 4, 10]:\r\n>               video_clips = VideoClips(video_list, num_frames, num_frames, fps)\r\n\r\ntest\\test_datasets_video_utils.py:117: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\video_utils.py:55: in __init__\r\n    self._compute_frame_pts()\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\video_utils.py:84: in _compute_frame_pts\r\n    for batch in dl:\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:278: in __iter__\r\n    return _MultiProcessingDataLoaderIter(self)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:682: in __init__\r\n    w.start()\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\process.py:112: in start\r\n    self._popen = self._Popen(self)\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\context.py:223: in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\context.py:322: in _Popen\r\n    return Popen(process_obj)\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\popen_spawn_win32.py:89: in __init__\r\n    reduction.dump(process_obj, to_child)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nobj = <Process(Process-2, initial daemon)>, file = <_io.BufferedWriter name=10>\r\nprotocol = None\r\n\r\n    def dump(obj, file, protocol=None):\r\n        '''Replacement for pickle.dump() using ForkingPickler.'''\r\n>       ForkingPickler(file, protocol).dump(obj)\r\nE       AttributeError: Can't pickle local object 'VideoClips._compute_frame_pts.<locals>.DS'\r\n\r\n..\\conda\\envs\\py37\\lib\\multiprocessing\\reduction.py:60: AttributeError\r\n---------------------------- Captured stderr call -----------------------------\r\nTraceback (most recent call last):\r\n\r\n  File \"<string>\", line 1, in <module>\r\n\r\n  File \"c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n\r\n    exitcode = _main(fd)\r\n\r\n  File \"c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\multiprocessing\\spawn.py\", line 115, in _main\r\n\r\n    self = reduction.pickle.load(from_parent)\r\n\r\nEOFError: Ran out of input\r\n\r\n\r\n-------------------------- Captured stderr teardown ---------------------------\r\nTraceback (most recent call last):\r\n\r\n  File \"<string>\", line 1, in <module>\r\n\r\n  File \"c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n\r\n    exitcode = _main(fd)\r\n\r\n  File \"c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\multiprocessing\\spawn.py\", line 115, in _main\r\n\r\n    self = reduction.pickle.load(from_parent)\r\n\r\nEOFError: Ran out of input\r\n\r\n_______________________ Tester.test_read_partial_video ________________________\r\n\r\nself = <test_io.Tester testMethod=test_read_partial_video>\r\n\r\n    def test_read_partial_video(self):\r\n>       with temp_video(10, 300, 300, 5, lossless=True) as (f_name, data):\r\n\r\ntest\\test_io.py:84: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:112: in __enter__\r\n    return next(self.gen)\r\ntest\\test_io.py:51: in temp_video\r\n    io.write_video(f.name, data, fps=fps, video_codec=video_codec, options=options)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\io\\video.py:55: in write_video\r\n    container.mux(packet)\r\nav/container/output.pyx:198: in av.container.output.OutputContainer.mux\r\n    ???\r\nav/container/output.pyx:204: in av.container.output.OutputContainer.mux_one\r\n    ???\r\nav/container/output.pyx:166: in av.container.output.OutputContainer.start_encoding\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   av.AVError: [Errno 13] Permission denied\r\n\r\nav/utils.pyx:109: AVError\r\n___________________ Tester.test_read_partial_video_bframes ____________________\r\n\r\nself = <test_io.Tester testMethod=test_read_partial_video_bframes>\r\n\r\n    def test_read_partial_video_bframes(self):\r\n        # do not use lossless encoding, to test the presence of B-frames\r\n        options = {'bframes': '16', 'keyint': '10', 'min-keyint': '4'}\r\n>       with temp_video(100, 300, 300, 5, options=options) as (f_name, data):\r\n\r\ntest\\test_io.py:100: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:112: in __enter__\r\n    return next(self.gen)\r\ntest\\test_io.py:51: in temp_video\r\n    io.write_video(f.name, data, fps=fps, video_codec=video_codec, options=options)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\io\\video.py:55: in write_video\r\n    container.mux(packet)\r\nav/container/output.pyx:198: in av.container.output.OutputContainer.mux\r\n    ???\r\nav/container/output.pyx:204: in av.container.output.OutputContainer.mux_one\r\n    ???\r\nav/container/output.pyx:166: in av.container.output.OutputContainer.start_encoding\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   av.AVError: [Errno 13] Permission denied\r\n\r\nav/utils.pyx:109: AVError\r\n_________________________ Tester.test_read_timestamps _________________________\r\n\r\nself = <test_io.Tester testMethod=test_read_timestamps>\r\n\r\n    def test_read_timestamps(self):\r\n>       with temp_video(10, 300, 300, 5) as (f_name, data):\r\n\r\ntest\\test_io.py:69: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:112: in __enter__\r\n    return next(self.gen)\r\ntest\\test_io.py:51: in temp_video\r\n    io.write_video(f.name, data, fps=fps, video_codec=video_codec, options=options)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\io\\video.py:59: in write_video\r\n    container.mux(packet)\r\nav/container/output.pyx:198: in av.container.output.OutputContainer.mux\r\n    ???\r\nav/container/output.pyx:204: in av.container.output.OutputContainer.mux_one\r\n    ???\r\nav/container/output.pyx:166: in av.container.output.OutputContainer.start_encoding\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   av.AVError: [Errno 13] Permission denied\r\n\r\nav/utils.pyx:109: AVError\r\n___________________ Tester.test_read_timestamps_from_packet ___________________\r\n\r\nself = <test_io.Tester testMethod=test_read_timestamps_from_packet>\r\n\r\n    def test_read_timestamps_from_packet(self):\r\n>       with temp_video(10, 300, 300, 5, video_codec='mpeg4') as (f_name, data):\r\n\r\ntest\\test_io.py:129: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:112: in __enter__\r\n    return next(self.gen)\r\ntest\\test_io.py:51: in temp_video\r\n    io.write_video(f.name, data, fps=fps, video_codec=video_codec, options=options)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\io\\video.py:55: in write_video\r\n    container.mux(packet)\r\nav/container/output.pyx:198: in av.container.output.OutputContainer.mux\r\n    ???\r\nav/container/output.pyx:204: in av.container.output.OutputContainer.mux_one\r\n    ???\r\nav/container/output.pyx:166: in av.container.output.OutputContainer.start_encoding\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   av.AVError: [Errno 13] Permission denied\r\n\r\nav/utils.pyx:109: AVError\r\n________________________ Tester.test_write_read_video _________________________\r\n\r\nself = <test_io.Tester testMethod=test_write_read_video>\r\n\r\n    def test_write_read_video(self):\r\n>       with temp_video(10, 300, 300, 5, lossless=True) as (f_name, data):\r\n\r\ntest\\test_io.py:62: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\contextlib.py:112: in __enter__\r\n    return next(self.gen)\r\ntest\\test_io.py:51: in temp_video\r\n    io.write_video(f.name, data, fps=fps, video_codec=video_codec, options=options)\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\io\\video.py:55: in write_video\r\n    container.mux(packet)\r\nav/container/output.pyx:198: in av.container.output.OutputContainer.mux\r\n    ???\r\nav/container/output.pyx:204: in av.container.output.OutputContainer.mux_one\r\n    ???\r\nav/container/output.pyx:166: in av.container.output.OutputContainer.start_encoding\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   av.AVError: [Errno 13] Permission denied\r\n\r\nav/utils.pyx:109: AVError\r\n___________________________ Tester.test_save_image ____________________________\r\n\r\nself = <test_utils.Tester testMethod=test_save_image>\r\n\r\n    def test_save_image(self):\r\n        with tempfile.NamedTemporaryFile(suffix='.png') as f:\r\n            t = torch.rand(2, 3, 64, 64)\r\n>           utils.save_image(t, f.name)\r\n\r\ntest\\test_utils.py:43: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\utils.py:105: in save_image\r\n    im.save(filename)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <PIL.Image.Image image mode=RGB size=134x68 at 0x323F3755C8>\r\nfp = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpm0s9rq8o.png'\r\nformat = 'PNG', params = {}\r\nfilename = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpm0s9rq8o.png'\r\nopen_fp = True, save_all = False, ext = '.png'\r\nsave_handler = <function _save at 0x000000323CA1FA68>\r\n\r\n    def save(self, fp, format=None, **params):\r\n        \"\"\"\r\n        Saves this image under the given filename.  If no format is\r\n        specified, the format to use is determined from the filename\r\n        extension, if possible.\r\n    \r\n        Keyword options can be used to provide additional instructions\r\n        to the writer. If a writer doesn't recognise an option, it is\r\n        silently ignored. The available options are described in the\r\n        :doc:`image format documentation\r\n        <../handbook/image-file-formats>` for each writer.\r\n    \r\n        You can use a file object instead of a filename. In this case,\r\n        you must always specify the format. The file object must\r\n        implement the ``seek``, ``tell``, and ``write``\r\n        methods, and be opened in binary mode.\r\n    \r\n        :param fp: A filename (string), pathlib.Path object or file object.\r\n        :param format: Optional format override.  If omitted, the\r\n           format to use is determined from the filename extension.\r\n           If a file object was used instead of a filename, this\r\n           parameter should always be used.\r\n        :param params: Extra parameters to the image writer.\r\n        :returns: None\r\n        :exception ValueError: If the output format could not be determined\r\n           from the file name.  Use the format option to solve this.\r\n        :exception IOError: If the file could not be written.  The file\r\n           may have been created, and may contain partial data.\r\n        \"\"\"\r\n    \r\n        filename = \"\"\r\n        open_fp = False\r\n        if isPath(fp):\r\n            filename = fp\r\n            open_fp = True\r\n        elif HAS_PATHLIB and isinstance(fp, Path):\r\n            filename = str(fp)\r\n            open_fp = True\r\n        if not filename and hasattr(fp, \"name\") and isPath(fp.name):\r\n            # only set the name for metadata purposes\r\n            filename = fp.name\r\n    \r\n        # may mutate self!\r\n        self._ensure_mutable()\r\n    \r\n        save_all = params.pop(\"save_all\", False)\r\n        self.encoderinfo = params\r\n        self.encoderconfig = ()\r\n    \r\n        preinit()\r\n    \r\n        ext = os.path.splitext(filename)[1].lower()\r\n    \r\n        if not format:\r\n            if ext not in EXTENSION:\r\n                init()\r\n            try:\r\n                format = EXTENSION[ext]\r\n            except KeyError:\r\n                raise ValueError(\"unknown file extension: {}\".format(ext))\r\n    \r\n        if format.upper() not in SAVE:\r\n            init()\r\n        if save_all:\r\n            save_handler = SAVE_ALL[format.upper()]\r\n        else:\r\n            save_handler = SAVE[format.upper()]\r\n    \r\n        if open_fp:\r\n            if params.get(\"append\", False):\r\n                fp = builtins.open(filename, \"r+b\")\r\n            else:\r\n                # Open also for reading (\"+\"), because TIFF save_all\r\n                # writer needs to go back and edit the written data.\r\n>               fp = builtins.open(filename, \"w+b\")\r\nE               PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpm0s9rq8o.png'\r\n\r\n..\\conda\\envs\\py37\\lib\\site-packages\\PIL\\Image.py:2085: PermissionError\r\n_____________________ Tester.test_save_image_single_pixel _____________________\r\n\r\nself = <test_utils.Tester testMethod=test_save_image_single_pixel>\r\n\r\n    def test_save_image_single_pixel(self):\r\n        with tempfile.NamedTemporaryFile(suffix='.png') as f:\r\n            t = torch.rand(1, 3, 1, 1)\r\n>           utils.save_image(t, f.name)\r\n\r\ntest\\test_utils.py:49: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n..\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\utils.py:105: in save_image\r\n    im.save(filename)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <PIL.Image.Image image mode=RGB size=1x1 at 0x323F678748>\r\nfp = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpn5hd8b_0.png'\r\nformat = 'PNG', params = {}\r\nfilename = 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpn5hd8b_0.png'\r\nopen_fp = True, save_all = False, ext = '.png'\r\nsave_handler = <function _save at 0x000000323CA1FA68>\r\n\r\n    def save(self, fp, format=None, **params):\r\n        \"\"\"\r\n        Saves this image under the given filename.  If no format is\r\n        specified, the format to use is determined from the filename\r\n        extension, if possible.\r\n    \r\n        Keyword options can be used to provide additional instructions\r\n        to the writer. If a writer doesn't recognise an option, it is\r\n        silently ignored. The available options are described in the\r\n        :doc:`image format documentation\r\n        <../handbook/image-file-formats>` for each writer.\r\n    \r\n        You can use a file object instead of a filename. In this case,\r\n        you must always specify the format. The file object must\r\n        implement the ``seek``, ``tell``, and ``write``\r\n        methods, and be opened in binary mode.\r\n    \r\n        :param fp: A filename (string), pathlib.Path object or file object.\r\n        :param format: Optional format override.  If omitted, the\r\n           format to use is determined from the filename extension.\r\n           If a file object was used instead of a filename, this\r\n           parameter should always be used.\r\n        :param params: Extra parameters to the image writer.\r\n        :returns: None\r\n        :exception ValueError: If the output format could not be determined\r\n           from the file name.  Use the format option to solve this.\r\n        :exception IOError: If the file could not be written.  The file\r\n           may have been created, and may contain partial data.\r\n        \"\"\"\r\n    \r\n        filename = \"\"\r\n        open_fp = False\r\n        if isPath(fp):\r\n            filename = fp\r\n            open_fp = True\r\n        elif HAS_PATHLIB and isinstance(fp, Path):\r\n            filename = str(fp)\r\n            open_fp = True\r\n        if not filename and hasattr(fp, \"name\") and isPath(fp.name):\r\n            # only set the name for metadata purposes\r\n            filename = fp.name\r\n    \r\n        # may mutate self!\r\n        self._ensure_mutable()\r\n    \r\n        save_all = params.pop(\"save_all\", False)\r\n        self.encoderinfo = params\r\n        self.encoderconfig = ()\r\n    \r\n        preinit()\r\n    \r\n        ext = os.path.splitext(filename)[1].lower()\r\n    \r\n        if not format:\r\n            if ext not in EXTENSION:\r\n                init()\r\n            try:\r\n                format = EXTENSION[ext]\r\n            except KeyError:\r\n                raise ValueError(\"unknown file extension: {}\".format(ext))\r\n    \r\n        if format.upper() not in SAVE:\r\n            init()\r\n        if save_all:\r\n            save_handler = SAVE_ALL[format.upper()]\r\n        else:\r\n            save_handler = SAVE[format.upper()]\r\n    \r\n        if open_fp:\r\n            if params.get(\"append\", False):\r\n                fp = builtins.open(filename, \"r+b\")\r\n            else:\r\n                # Open also for reading (\"+\"), because TIFF save_all\r\n                # writer needs to go back and edit the written data.\r\n>               fp = builtins.open(filename, \"w+b\")\r\nE               PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpn5hd8b_0.png'\r\n\r\n..\\conda\\envs\\py37\\lib\\site-packages\\PIL\\Image.py:2085: PermissionError\r\n============================== warnings summary ===============================\r\nc:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\lsun.py:8\r\n  c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\datasets\\lsun.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n    from collections import Iterable\r\n\r\nc:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\av\\container\\__init__.py:1\r\n  c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\av\\container\\__init__.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n    from .core import Container, open\r\n\r\ntest/test_datasets.py::Tester::test_imagenet\r\n  c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\r\n    return f(*args, **kwds)\r\n\r\ntest/test_transforms.py::Tester::test_randomperspective\r\n  c:\\w\\2\\s\\packaging\\windows\\conda\\envs\\py37\\lib\\site-packages\\torchvision\\transforms\\functional.py:440: UserWarning: torch.gels is deprecated in favour of torch.lstsq and will be removed in the next release. Please use torch.lstsq instead.\r\n    res = torch.gels(B, A)[0]\r\n\r\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n======= 32 failed, 141 passed, 14 skipped, 4 warnings in 407.68 seconds =======\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"User Info Endpoint Handling Expects Key \"user\" in Response","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Document how to actually run the example in the `usage` section","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Color Theme Bug\n\n* I am reporting a bug. I used the bug reporting system by using `SPC h I` in spacemacs. However, at the end after using `C-c C-c` to submit, it pops out a webpage with error. I am not sure if it has been successfully submitted so decide to paste it here anyway.\r\n\r\n---\r\n\r\n#### Description :octocat:\r\nI love the color theme \"gruvbox\", and have tried very hard to implement that.\r\nI followed the documentation and found a bug.\r\n\r\n#### Reproduction guide :beetle:\r\n- Edit ~/.spacemacs by adding 'gruvbox' in to the list of themes:\r\n  ```\r\n  ...\r\n  dotspacemacs-themes '(gruvbox spacemacs spacemacs-light)'\r\n  ...\r\n  ```\r\n- Open emacs\r\n- Emacs seems to be downloading the theme\r\n- It works! (for only this time)\r\n- Close emacs\r\n- Open emacs again\r\n- An error pop out! (more in the observed behaviour section)\r\n- Close emacs, sadly\r\n- Remove \"gruvbox\" from the config file\r\n- Open emacs again. Emacs will remove the theme package it just installed.\r\n- Close emacs\r\n- Add \"gruvbox\" again in the config, the same way.\r\n- Open emacs, and it will download and load the theme correctly.\r\n- Close emacs, and openning it again gives the same error.\r\n- Repeat the above. The error came out 5 times, and I am convinced that this is a bug.\r\n\r\n*Observed behaviour:* :eyes: :broken_heart:\r\n- After opening emacs the second time, the theme \"gruvbox\" fails to be loaded.\r\n- The system falls back to the default theme, and outputs an error/warning message on the welcoming page, as follows:\r\n                      Warnings:\r\n                          - An error occurred while applying the theme \"gruvbox\", fallback on theme\r\n                            \"spacemacs-dark\". Error was: (file-missing Cannot open load file No such file or\r\n                            directory autothemer)      \r\n                          - Please check the value of \"dotspacemacs-themes\" in your dotfile or open an issue\r\n                            so we can add support for the theme \"gruvbox\".      \r\n\r\n\r\n*Expected behaviour:* :heart: :smile:\r\n- The system should (but not) work as the theme was freshly loaded.\r\n\r\n#### System Info :computer:\r\n- OS: gnu/linux\r\n- Emacs: 26.2\r\n- Spacemacs: 0.200.13\r\n- Spacemacs branch: master (rev. 8c0b8c344)\r\n- Graphic display: t\r\n- Distribution: spacemacs\r\n- Editing style: vim\r\n- Completion: helm\r\n- Layers:\r\n```elisp\r\n(helm emacs-lisp git markdown org)\r\n```\r\n- System configuration features: XPM JPEG TIFF GIF PNG RSVG IMAGEMAGICK SOUND GPM DBUS GSETTINGS GLIB NOTIFY ACL GNUTLS LIBXML2 FREETYPE M17N_FLT LIBOTF XFT ZLIB TOOLKIT_SCROLL_BARS GTK3 X11 XDBE XIM MODULES THREADS LIBSYSTEMD LCMS2\r\n\r\n\r\n#### Backtrace :paw_prints:\r\n```\r\n<<BACKTRACE IF RELEVANT>>\r\n```\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"`npm run pack` to build binaries is not working ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Must have proxy servers as neutral for WDAG\n\nHostnames and aliases for proxy servers must be included in the \"Domains categorized as both work and personal\" policy (aka \"neutral\"). That's an important note left out of the documentation for that policy.\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: 41a8c802-79ca-1593-c045-2ed150e9ce40\r\n* Version Independent ID: 3dabd613-2eee-7c65-6f30-6746c8fb5bdf\r\n* Content: [Configure the Group Policy settings for Windows Defender Application Guard (Windows 10)](https://docs.microsoft.com/en-us/windows/security/threat-protection/windows-defender-application-guard/configure-wd-app-guard)\r\n* Content Source: [windows/security/threat-protection/windows-defender-application-guard/configure-wd-app-guard.md](https://github.com/MicrosoftDocs/windows-itpro-docs/blob/master/windows/security/threat-protection/windows-defender-application-guard/configure-wd-app-guard.md)\r\n* Product: **w10**\r\n* Technology: **windows**\r\n* GitHub Login: @Dansimp\r\n* Microsoft Alias: **dansimp**","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Create examples and instructions on how to use this module","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Do you have room for one more?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Use \"universal\" categories for part-of-speech tags (1.10.0)","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Mouse locking does not work\n\nHello,\r\n\r\nFollowing up on my \"Civilization\" project here: https://zmozgu.net/civ.html\r\n\r\nI wanted to enable mouse locking feature. I have followed the documentation and modified my static HTML file to create the \"dosbox.conf\" and pass the \"autolock=true\" into it. \r\n\r\nWeird thing happens - the OS cursor does not disappear after clicking and there is a position difference between the OS cursor and DOS cursor, that is visible in the game area - the further you move the OS cursor to the sides, the bigger the distance between it and the DOS cursor becomes. \r\n\r\nYou can check it by yourself - you have to wait until the game intro ends and the DOS cursor can be visible.\r\n\r\nWhat am I doing wrong?\r\n\r\nMy code is below:\r\n\r\n```\r\n<body>\r\n  <canvas id=\"jsdos\"></canvas>\r\n  <script>\r\n    Dos(document.getElementById(\"jsdos\"), {\r\n        wdosboxUrl: \"https://js-dos.com/6.22/current/wdosbox.js\"\r\n    }).ready((fs, main) => {\r\n\r\n\tfs.createFile(\"dosbox.conf\", `\r\n            [sdl]\r\n            autolock=true\r\n        `);\r\n\r\n      fs.extract(\"civ.zip\").then(() => {\r\n        main([\"-conf\", \"dosbox.conf\", \"-c\", \"cd civ1\", \"-c\", \"CIV.EXE\"])\r\n      });\r\n    });\r\n  </script>\r\n</body>\r\n\r\n</html>\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Issue when installing: ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add a TMX parser","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"QFlightInstruments README misleading / incomplete","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Invalid reference links provided in documentation","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Create Topics index.\n\nNeed to add `// Topics:` tags to docs and generate topics index","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"performance of 2013-Haswell and 2017-SkylakePurley on Skylake-SP","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# README update  \n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# getDay doesn't let you set weekStartsOn\n\nHi there, thanks for maintaining this super useful library,\r\nI have a remark / request / issue regarding `getDay`:\r\n\r\n`getWeekOfMonth` accept options such as `locale, weekStartsOn`.\r\nhttps://date-fns.org/v2.0.0-beta.4/docs/getWeekOfMonth\r\n\r\nThis means that:\r\n```ts\r\nconst aug11_2019 = new Date(2019, 7, 11)\r\ngetWeekOfMonth(aug11_2019) === 3 // Sunday, third week of august\r\ngetWeekOfMonth(aug11_2019, {weeksStartsOn: 1) === 2 // Week starts on Monday, we're still on week 2\r\n```\r\n\r\n(supposedly, there's a known bug with Sundays: https://github.com/date-fns/date-fns/issues/1040)\r\n\r\nI expect the `getDay` function to let me set `locale, weeksStartsOn` too, so that:\r\n\r\n```ts\r\ngetDay(aug11_2019) === 0 // Sunday, first day of the week\r\ngetDay(aug11_2019, {weeksStartsOn: 1) === 6 // last day of the previous week\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"0.1.32 seems to run fine also without host application","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Consider publishing the API online","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Kinetic, compiling error","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add missing temp module for sme","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"REPL in the website ?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Segfault in tac_plus","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Mailchimp v3 use FNAME and LNAME for firstName and lastName ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# repsonse file option missing?\n\n### Which version of the AzCopy was used? \r\n10.2.1\r\n##### Note: The version is visible when running AzCopy without any argument\r\n\r\n### Which platform are you using? (ex: Windows, Mac, Linux)\r\nWindows\r\n\r\n### What command did you run?\r\nazcopy /@c:\\...\\x.responsefile\r\n\r\n##### Note: Please remove the SAS to avoid exposing your credentials. If you cannot remember the exact command, please retrieve it from the beginning of the log file.\r\n\r\n### What problem was encountered?\r\nThe standard help string showed up\r\n\r\n### How can we reproduce the problem in the simplest way?\r\nCall azcopy with the usual responsefile option\r\n\r\n### Have you found a mitigation/solution?\r\nNo. I can use the command line, but with all those special characters in the SAS, I found it impossible to put it into a batch file\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Add contact details to Google Doc","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Broken link\n\nA schematic of the original hardware can be found here:\r\nhttp://swhs.home.xs4all.nl/bbc/mmbeeb/\r\nThis link is broken non existent in the documentation readme.txt.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"CF v269","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Fix download command for README.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# CherryPy - Pytest hangs with default \"interactive\" mode \n\n**I'm submitting a ...**\r\n- [ ] bug report\r\n- [X] feature request\r\n- [ ] question about the decisions made in the repository\r\n\r\n**Do you want to request a *feature* or report a *bug*?**\r\nA \"feature\" request, mostly for the documentation rather than for the actual code of Cherrypy.\r\n\r\n**What is the current behavior?**\r\nRunning Cherrypy helper.CPWebCase tests hangs on failed assertions due to interactive mode, that can be disabled with helper.CPWebCase.interactive = False or through an enviroment variable (WEBTEST_INTERACTIVE).\r\nBut I had to look at the source code of CPWebCase to understand what was going on, with trial and error. I was not able to find documentation about this behaviour until I found this page: https://schneide.blog/2017/02/06/integration-tests-with-cherrypy-and-requests/ that reported my exact problem (read the first lines of the article).\r\n\r\n**If the current behavior is a bug, please provide the steps to reproduce and if possible a screenshots and logs of the problem. If you can, show us your code.**\r\n\r\nA minimal example to reproduce the problem (tries to get a not existing url):\r\n\r\n```\r\nfrom cherrypy.test import helper\r\n\r\nclass TestSample(helper.CPWebCase):\r\n\r\n    def test_sample(self):\r\n        self.getPage('/')\r\n        self.assertStatus(\"200 OK\")\r\n```\r\n\r\nThe test will hang forever if \"interactive\" is True.\r\n\r\n**What is the expected behavior?**\r\nPlease tell why \"interactive\" is true by default and why there is no documentation about the possibility to disable it/how to disable it.\r\n\r\n**Please tell us about your environment:**\r\n\r\n- Cheroot version: 6.5.5\r\n- CherryPy version: 18.1.2\r\n- Python version: 3.7.3\r\n- OS: Windows\r\n- Browser: not relevant.\r\n- pytest: 5.0.1","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Custom Commands that return void are still chainable.\n\nWhen I have a custom command defined as:\r\n```\r\nmyCommand = () => { \r\nreturn void;\r\n}\r\n```\r\nAnd I use it like so:\r\n```\r\nCy.myCommand().pause(). \r\n```\r\n\r\nI would expect to hit a run time error since my custom command `myCommand` doesn't return a `Cypress.Chainable<T>`,\r\n\r\nBut instead the `pause()` command executes after I chain if off of my void method, and I am able to continue chaining even further.\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Bind Control Click to Command Click?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Old README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Instructions for using the markdown editor","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Update to v4.2","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"How to compile on arm?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Inconsistent strategy for .gitignore and deploy-exclude.txt files","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Markdown link open a new tab/window","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"README.md img","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Development of the library with own solutions","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"asjp dist files","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Noble was installed on RPi0 but I can't run it ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Config\n\nI found a few things that could improve the API reviewing the project:\r\n\r\n1. Documentational comments explaining your javascript functions and less readable components in them\r\n\r\n2. Quite nuanced, but having your database first in the compose file will cause it to start first, meaning that you can have the database running without the app, which might cause `port already in use errors` on restart and using resources to maintain the Mongo server without it being used.\r\n\r\n3. If you don't have the Docker containers hard coded to each other directly or through env variables, this poses a security risk in production, especially with the database.  Docker can recognize env vars and files at runtime.  \r\n\r\n4. I'm not sure how Docker does with cookies out of the box, but if you have issues with authentication try setting up a reverse proxy to pass along headers and cookies, and prevent CORS errors.  \r\n\r\n5. Architectural- bin is for built executables (binaries), such as bin/www (a conventional name for web server startup scripts).  Did you mean `src` when naming this folder?  The architecture could be improved by delegating different folders to more broad functionality.  \r\n\r\nOtherwise, very well written code, consistently great use of syntactic sugar and the decisions you made in tooling + functionality show sophisticated design and research.   Refactor the architecture and the project will shine.  ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"sles12 sp2 installation loops after first stage. Never gets to stage 2.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# File handler: trailing newline position is not defined \n\nI've done an error here: https://github.com/B2W-BIT/aiologger/blob/master/aiologger/handlers/files.py#L79\r\n\r\nAs you told in the docs, write order is not guaranteed. That's why sometimes 2 log lines concats, and then there are doing 2 empty lines. I'll return str concatenation back","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Notebooks not executing","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Exclude Debug","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Loading problem","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"documentation: `vars` option is missing for e.g. follow","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"loops-test.js and instructions don't match for whileLoop(n)","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Documentation\n\nAdd documentation for available events and functions","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"set_opacity not working for Circle edge","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"dp.kinect not registered after writing registration name and opening .dpreg ","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Private registry key usage\n\n### Description\r\nNot sure if this warrants a new issue given its closely related to the already closed [#511 ](https://github.com/polyaxon/polyaxon/issues/511), but I think I've got the other side of the issue here.\r\n Also, total kubernetes newcomer, so apologies if this is terribly dumb. I'm trying to use a private registry (ECR) instead of the in-cluster docker registry for both pushing and pulling images. \r\n\r\n### To Reproduce\r\nI added the secret with kubectl:\r\n`kubectl create secret generic dconf --from-file=sec_config.json=./sec_config.json -n polyaxon`\r\n\r\nwhere the file was like `{\"credsStore\":\"reallyLongPasssword\"}`, with the password coming from `aws ecr get-login`. \r\n\r\n### Expected behavior\r\nIf I understood the docs correctly, it looks like the key should just be listed in the UI, but I don't see anything there, nor was there anything after I ran an upgrade using the polyaxon CLI tool. \r\n\r\nAny help would be much appreciated!\r\n\r\n### Environment\r\npolyaxon 0.5.5\r\nkubernetes+helm","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Training on VOC2011","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"RHOAR Integration","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# url-prefix option is needed\n\nIf you want to deploy your documentation to gh-pages, for instance, you will have the following base url: `https://something.github.io/yourreponame`. The problem is that all urls generated by `Perl6::Documentable` are relative to the root source, which in this case, is `https://something.github.io/`.\r\n\r\nSo an easy solution is to provide a new option to add an arbitrary prefix to all urls, through `&rewrite-url`.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Discord link broken?\n\nNot really an issue, but both the discord invite on the README.md page and on the website are broken.","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Add actual exercises","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# ejercicio 2 workshop endpoint\n\ndejo la rama que cree para las pruebas del endpoint de mercado libre https://github.com/devjaime/clone-mercadolibre\r\n\r\nEstoy modificando el tama\u00f1o de la letra el tema, y otras cosas para que quede m\u00e1s presentable.\r\nEn el readme estoy anotando todo lo aprendido, \r\nPara este ejemplo agregue context solo porque me resultaba m\u00e1s f\u00e1cil leer el c\u00f3digo. Consulta si no ocupara axios, podria ocupar fetch directamente?\r\nhttps://es.reactjs.org/docs/context.html\r\n\r\n![image](https://user-images.githubusercontent.com/26843824/62831201-6521d180-bbe9-11e9-90f4-11bb628c9acb.png)\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Update documentation with get_datacenter_by_name method","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Add \"Airports Web\" API","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Add CloudWatch agent for disk space and memory monitoring\n\nFor users that don't have New Relic or similar tools, we want to provide the ability to monitor disk space and memory usage by enabling those metrics.\r\n\r\nCloudWatch agent https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html provides disk and memory metrics https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html, and there are some Puppet modules that seem to support the provisioning of CloudWatch monitoring.\r\nOne thing to note is that we would like to support the provisioning of CloudWatch monitoring on RHEL7 and Amazon Linux 2 on Packer AEM.\r\n\r\nConsistent to other feature flags, please add a configuration property `aws.install_cloudwatchagent` to enable/disable CloudWatch agent installation.\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"auto refresh page feature?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Edit README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Add Call of Duty 4 : Modern Warfare auto splitter\n\nhttps://raw.githubusercontent.com/KunoDemetries/cod4/master/mw.asl\r\n\r\nI wasn't sure how to add it so I made it into a repositories file. \r\n\r\nit has start, split, reset, and remove loads.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Update DOCS for security_groups in aws_instance","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Template Docs: 'packagename' replacer broken?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Improve documentation for service and token urls","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# try chunk store\n\ntry indexeddb for chunk store\r\n\r\nhttps://github.com/webtorrent/webtorrent/blob/master/docs/api.md#clientaddtorrentid-opts-function-ontorrent-torrent-\r\n\r\nhttps://www.npmjs.com/package/idb-chunk-store","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Implement pubsub\n\nIn https://github.com/openzipkin/zipkin-gcp/issues/45, there was a proposal to add pubsub transport (collector and sender), but that never happened.\r\n\r\n@javierviera is currently adding https://github.com/openzipkin/zipkin-go/pull/142 on the golang side, but that's asymmetric and confusing if no server side exists.\r\n\r\nIn any case, the message format should be standard (ListOfSpans in proto or json)\r\n\r\nImplementation wise, sender (java client) should likely use grpc as that's typical. collector should likely use armeria as that's less dependencies and fits into our normal observability tools better (logs metrics tracing) (see stackdriver-storage as an example).\r\n\r\nLooking at the api, it seems there's no grpc endpoint for pubsub, but there's a rest api which likely shares similar auth etc. There seems to be a pull api which could be run in a loop similar to our kafka collectors https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions/pull\r\n\r\n@anuraaga have you done any work in pubsub in curiostack?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Create on onClick event","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# No longer works with upgraded Vue and Vuex\n\nI am using vuex-persist@2.0.1\r\n\r\nI recently upgraded vue and vuex.\r\nvue@2.6.10\r\nvuex@3.1.0\r\n\r\nBefore the upgrade I had vuex-persist working perfectly, in my typescript project, with the provided documentation.\r\nAfter the upgrade, I now get an error in my Store. Here is my code:\r\n```\r\nconst vuexAllModules = new VuexPersistence({\r\n\tstorage: window.localStorage\r\n});\r\n\r\nexport default new Vuex.Store<RootState>({\r\n\tstrict: !config.isProd,\r\n\tmodules: {\r\n\t\tmodule1,\r\n\t\tmodule2\r\n\t},\r\n\tstate: {},\r\n\tgetters: {},\r\n\tmutations: {},\r\n\tactions: {},\r\n\tplugins: [vuexAllModules.plugin] // <<<<-----SOURCE OF ERROR\r\n});\r\n```\r\n\r\n**ERROR**\r\n```\r\nType 'Plugin<unknown>[]' is not assignable to type 'Plugin<RootState>[]'.\r\n  Type 'Plugin<unknown>' is not assignable to type 'Plugin<RootState>'.\r\n    Types of parameters 'store' and 'store' are incompatible.\r\n      Type 'Store<RootState>' is not assignable to type 'Store<unknown>'.\r\n        Types of property 'registerModule' are incompatible.\r\n          Type '{ <T>(path: string, module: Module<T, RootState>, options?: ModuleOptions | undefined): void; <T>(path: string[], module: Module<T, RootState>, options?: ModuleOptions | undefined): void; }' is not assignable to type '{ <T>(path: string, module: Module<T, unknown>, options?: ModuleOptions | undefined): void; <T>(path: string[], module: Module<T, unknown>, options?: ModuleOptions | undefined): void; }'.\r\n            Types of parameters 'module' and 'module' are incompatible.\r\n              Type 'Module<any, unknown>' is not assignable to type 'Module<any, RootState>'.\r\n                Types of property 'actions' are incompatible.\r\n                  Type 'ActionTree<any, unknown> | undefined' is not assignable to type 'ActionTree<any, RootState> | undefined'.\r\n                    Type 'ActionTree<any, unknown>' is not assignable to type 'ActionTree<any, RootState>'.\r\n                      Index signatures are incompatible.\r\n                        Type 'Action<any, unknown>' is not assignable to type 'Action<any, RootState>'.\r\n                          Type 'ActionHandler<any, unknown>' is not assignable to type 'Action<any, RootState>'.\r\n                            Type 'ActionHandler<any, unknown>' is not assignable to type 'ActionHandler<any, RootState>'.\r\n                              Type 'unknown' is not assignable to type 'RootState'.ts(2322)\r\nindex.d.ts(96, 3): The expected type comes from property 'plugins' which is declared here on type 'StoreOptions<RootState>'\r\n```","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"give some advice on installing Oxcal","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Strange landscapes when m/n > 0.5","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Migrate away from wordpress","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Section/headers level hierarchy mixup (?) in docs (main index in particular)\n\nI noted some oddities in appearance of `index.rst` - the `Developer Documentation` \"section\" looks somewhat stitched to the end of the `User Documentation` chapter and has no TOC entry. Although it _appears_ to be marked as section according to the Python [devguide](https://devguide.python.org/documenting/#sections) recommendations\r\n> Normally, there are no heading levels assigned to certain characters as the structure is determined from the succession of headings. However, for the Python documentation, here is a suggested convention:\r\n```\r\n# with overline, for parts\r\n* with overline, for chapters\r\n=, for sections\r\n-, for subsections\r\n```\r\nit looks like here the markers are indeed assigned in the order they appear: `# * - =`\r\ni.e. the `====` heading is demoted to level 4 and thus below `:tocdepth: 3`.\r\nI haven't found a way to force the levels to some other order if the first intended `subsection` entry just happens to occur before the first `section`...\r\nMight make more sense here to mark `Developer Documentation` as a chapter, on the same level as `Project details`.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# DATABENDERS - MIND PALACE \n\n**Before you start, please follow this format for your issue title**:  \r\nTEAM NAME - PROJECT NAME\r\n\r\n## \u2139\ufe0f Project information\r\n_Please complete all applicable._\r\n\r\n- **Project Name**: MIND PALACE\r\n- **Short Project Description**: ALL IN ONE TOOLKIT FOR PEOPLE SUFFERING FROM MENTAL HEALTH ISSUES\r\n- **Team Name**: DATABENDERS\r\n- **Team Members**: PARTH SHARMA  (https://github.com/Mr-Parth) , TUSHAR_ANCHLIYA (https://github.com/anchliyatushar), NANDINI RATHORE (https://github.com/nandini035)\r\n- **Demo Link**: https://drive.google.com/open?id=19wq-i6dq1EiTqT_M2Dd3zPYDcX3MA7RK\r\n- **Repository Link**: https://github.com/Mr-Parth/CFT-Hack_api\r\n- **Labels**:  Blockchain\r\n\r\n## \ud83d\udd25 Your Pitch\r\nWe are developing an ALL-IN-ONE platform for people suffering from mental health issues. The prototype is technically divided in three parts :- Android App (UI), Backend (NodeJS), Truffle App (Ethereum | VueJs | Web3).\r\nWe bridge the gap between Therapists and Normal Users, enabling to access virtual support groups and have a sacred experience to deal with all negativity.\r\nOur Revenue Model is based on :- Advertisements, Freemium, Commission\r\nKEY POINTS IN OUR PRODUCT :- Therapists, Support Groups, Blockchain, ALL-IN-ONE kind of intents, Blogs website/community \r\n\r\n## \ud83d\udd26 Any other specific thing you want to highlight?\r\nKindly go through README :)\r\n\r\n## \u2705 Checklist\r\n\r\n**Before you post the issue**:\r\n- [\u2705 ] You have followed the issue title format.\r\n- [\u2705 ] You have mentioned the correct labels.\r\n- [\u2705 ] You have provided all the information correctly.\r\n- [\u2705 ] You have uploaded the pitch deck to the given Google Drive\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# The system cannot find the path specified. error Command failed with exit code 1.\n\n$ yarn bootstrap                                                                                                                                                                                 yarn run v1.13.0                                                                                                                                                                                 $ yarn && ocular-bootstrap                                                                                                                                                                       warning package-lock.json found. Your project contains lock files generated by tools other than Yarn. It is advised not to mix package managers in order to avoid resolution inconsistencies cau sed by unsynchronized lock files. To clear this warning, remove package-lock.json.                                                                                                               [1/5] Validating package.json...                                                                                                                                                                 [2/5] Resolving packages...                                                                                                                                                                      [3/5] Fetching packages...                                                                                                                                                                       info fsevents@1.2.9: The platform \"win32\" is incompatible with this module.                                                                                                                      info \"fsevents@1.2.9\" is an optional dependency and failed compatibility check. Excluding it from installation.                                                                                  [4/5] Linking dependencies...                                                                                                                                                                    warning \" > @babel/plugin-proposal-class-properties@7.4.4\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                                                     warning \"@babel/plugin-proposal-class-properties > @babel/helper-create-class-features-plugin@7.4.4\" has unmet peer dependency \"@babel/core@^7.0.0\".                                             warning \" > @babel/preset-react@7.0.0\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                                                                         warning \"@babel/preset-react > @babel/plugin-transform-react-display-name@7.2.0\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                               warning \"@babel/preset-react > @babel/plugin-transform-react-jsx@7.3.0\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                                        warning \"@babel/preset-react > @babel/plugin-transform-react-jsx-self@7.2.0\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                                   warning \"@babel/preset-react > @babel/plugin-transform-react-jsx-source@7.2.0\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                                 warning \"@babel/preset-react > @babel/plugin-transform-react-jsx > @babel/plugin-syntax-jsx@7.2.0\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                             warning \" > @babel/register@7.4.4\" has unmet peer dependency \"@babel/core@^7.0.0-0\".                                                                                                             warning \" > @deck.gl/test-utils@7.1.10\" has unmet peer dependency \"@deck.gl/core@^7.0.0\".                                                                                                        warning \" > babel-loader@8.0.5\" has unmet peer dependency \"@babel/core@^7.0.0\".                                                                                                                  warning \" > babel-loader@8.0.5\" has unmet peer dependency \"webpack@>=2\".                                                                                                                         warning \" > eslint-config-uber-jsx@3.3.3\" has unmet peer dependency \"eslint@>= 3.0.0 < 5\".                                                                                                       warning \"eslint-config-uber-jsx > eslint-config-uber-es5@2.0.3\" has unmet peer dependency \"eslint@>= 3.0.0 < 5\".                                                                                 warning \"eslint-config-uber-jsx > eslint-plugin-react@6.10.3\" has unmet peer dependency \"eslint@^2.0.0 \\|\\| ^3.0.0\".                                                                               warning \" > eslint-plugin-react@7.12.4\" has unmet peer dependency \"eslint@^3.0.0 \\|\\| ^4.0.0 \\|\\| ^5.0.0\".                                                                                           warning \" > ocular-dev-tools@0.0.27\" has incorrect peer dependency \"@probe.gl/test-utils@^3.0.2\".                                                                                                warning \" > @streetscape.gl/layers@1.0.0-beta.16\" has unmet peer dependency \"@deck.gl/core@^7.1.2\".                                                                                              warning \" > @streetscape.gl/layers@1.0.0-beta.16\" has unmet peer dependency \"@deck.gl/layers@^7.1.2\".                                                                                            [5/5] Building fresh packages...                                                                                                                                                                 The system cannot find the path specified.                                                                                                                                                       error Command failed with exit code 1.                                                                                                                                                           info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.\r\n--\r\n\r\n\r\nWould you help me to figure it out the issue.","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Setup CI","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Release iOS SDK with README","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Improve docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Documentation does not show \"ref\" in method signatures\n\n<!--\r\n# Please make sure that the issue is present in the\r\n# develop branch of MonoGame before reporting\r\n#\r\n# You can download the development build installer from:\r\n# http://www.monogame.net/downloads/\r\n-->\r\n\r\n<!-- Write your issue below -->\r\n\r\nThe documentation on the website doesn't show the `ref` keyword in method signatures. For example, compare the documentation pages for [this](http://www.monogame.net/documentation/?page=M_Microsoft_Xna_Framework_Input_Joystick_GetState_1) and [this](http://www.monogame.net/documentation/?page=M_Microsoft_Xna_Framework_Rectangle_Intersect) with the actual signatures [here](https://github.com/MonoGame/MonoGame/blob/develop/MonoGame.Framework/Input/Joystick.cs#L57) and [here](https://github.com/MonoGame/MonoGame/blob/develop/MonoGame.Framework/Rectangle.cs#L425).\r\n\r\n\r\n\r\n<!-- System stats -->\r\n\r\n#### What version of MonoGame does the bug occur on:\r\n- Develop\r\n\r\n#### What operating system are you using:\r\n- N/A\r\n\r\n#### What MonoGame platform are you using:\r\n<!-- e.g. DesktopGL, WindowsDX, WindowsUWP, Android -->\r\n- N/A\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# out of date function signatures\n\nthe \"WebGLRenderingContext\" parameter is missing from the following docs:\r\n\r\nhttps://github.com/greggman/twgl.js/blob/a90ce8ef2083fd6185fa30cc8972aafc28cc68d7/dist/4.x/twgl.d.ts#L251\r\nhttps://github.com/greggman/twgl.js/blob/a90ce8ef2083fd6185fa30cc8972aafc28cc68d7/dist/4.x/twgl.d.ts#L267\r\nhttps://github.com/greggman/twgl.js/blob/a90ce8ef2083fd6185fa30cc8972aafc28cc68d7/src/programs.js#L828-L838\r\nhttps://github.com/greggman/twgl.js/blob/a90ce8ef2083fd6185fa30cc8972aafc28cc68d7/src/programs.js#L1393-L1402\r\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"No VHDL nor Verilog standard version specified in readme","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Enhance the `options` section in the DOCs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"cryptography 2.0.1 segfaults on Ubuntu 12.04","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Document math.Log template func","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"ResourceList does not render item as per doc","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Custom Operations with Docker\n\nI try to add [custom operations](https://docs.nvidia.com/deeplearning/sdk/tensorrt-inference-server-master-branch-guide/docs/custom_operation.html#custom-operations) to a model\r\n\r\nCurrently I run the Server with [docker](https://docs.nvidia.com/deeplearning/sdk/tensorrt-inference-server-master-branch-guide/docs/run.html#running-the-inference-server):\r\n\r\n```\r\n$ nvidia-docker run --rm --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p8000:8000 -p8001:8001 -p8002:8002 -v/path/to/model/repository:/models <tensorrtserver image name> trtserver --model-store=/models\r\n```\r\nFrom the documentation about custom operations I infer that the combined command looks like:\r\n\r\n```\r\n`$ nvidia-docker run --rm --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p8000:8000 -p8001:8001 -p8002:8002 -v/path/to/model/repository:/models <tensorrtserver image name> LD_PRELOAD=libtrtcustom.so trtserver --model-store=/models\r\n```\r\ndifference: LD_PRELOAD=libtrtcustom.so added before trtserver\r\n\r\nThe problem is that the server does not start - it does not find the library.\r\nWhere do I have to place the library (in container or outside)? \r\nDoes the approach work with docker or only with manual builds?\r\nHow does the correct command to run the server look like?\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Docs: Add documentation for style overriding for each Field component\n\n","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"[PRE REVIEW]: Django Remote Submission","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Question","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Default title\n\ndefault description\n\n|Property | Value|\n|------------ | -------------|\n| Session ID | 6a50b5012de09d92a86454b06eb92fda3439729d |\n| Status | done |\n| Reason | CLIENT_STOPPED_SESSION |\n| Input Capabilities | <ul><li> **build:** Automate_win_chrome545380</li><li> **name:** win_chrome_112100</li><li> **browserstack.queue.retries:** 2</li><li> **acceptSslCert:** false</li><li> **detected_language:** selenium/3.141.0 (ruby linux)</li><li> **browserstack.seleniumLogs:** true</li><li> **browserstack.appiumLogs:** false</li><li> **browser_version:** 76.0</li></ul> |\n| Session URL | https://automate-ci.bsstag.com/builds/2f6273d21fc8803236b36339a52ad5d189b05938/sessions/6a50b5012de09d92a86454b06eb92fda3439729d |\n| Public Session URL | https://automate-ci.bsstag.com/builds/2f6273d21fc8803236b36339a52ad5d189b05938/sessions/6a50b5012de09d92a86454b06eb92fda3439729d?auth_token=5c417f82f12253b97d869886be9282bba500d98c4fc6cd7dd1887312f38e16d4 |\n| Exception Timestamp | 00:04 |\n\n\n**Exception Stacktrace: **no such element: Unable to locate element: {\"method\":\"id\",\"selector\":\"okgoogle\"}\n  (Session info: chrome=76.0.3809.87)\n  (Driver info: chromedriver=76.0.3809.68 (420c9498db8ce8fcd190a954d51297672c1515d5-refs/branch-heads/3809@{#864}),platform=Mac OS X 10.11.6 x86_64) (WARNING: The server did not provide any stacktrace information)\nCommand duration or timeout: 20 milliseconds\nFor documentation on this error, please visit: http://seleniumhq.org/exceptions/no_such_element.html\nBuild info: version: '2.53.0', revision: '35ae25b', time: '2016-03-15 17:00:58'\nSystem info: host: 'mac-208-52-157-48.browserstack.com', ip: '208.52.157.48', os.name: 'Mac OS X', os.arch: 'x86_64', os.version: '10.11.6', java.version: '1.8.0_51'\nDriver info: org.openqa.selenium.chrome.ChromeDriver\nCapabilities [{mobileEmulationEnabled=false, timeouts={implicit=0, pageLoad=300000, script=30000}, hasTouchScreen=false, platform=MAC, acceptSslCerts=false, goog:chromeOptions={debuggerAddress=localhost:55078}, acceptInsecureCerts=false, webStorageEnabled=true, browserName=chrome, takesScreenshot=true, javascriptEnabled=true, setWindowRect=true, unexpectedAlertBehaviour=ignore, applicationCacheEnabled=false, rotatable=false, networkConnectionEnabled=false, chrome={chromedriverVersion=76.0.3809.68 (420c9498db8ce8fcd190a954d51297672c1515d5-refs/branch-heads/3809@{#864}), userDataDir=/var/folders/3y/zz_w6_s56sl__vcrf3r5bhzr0000hr/T/.com.google.Chrome.0Fpv4v}, takesHeapSnapshot=true, pageLoadStrategy=normal, strictFileInteractability=false, databaseEnabled=false, handlesAlerts=true, version=76.0.3809.87, browserConnectionEnabled=false, proxy={}, nativeEvents=true, locationContextEnabled=true, cssSelectorsEnabled=true}]\nSession ID: d829b31bca8e01fa091db8d5d749aaab\n*** Element info: {Using=id, value=okgoogle}","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"date_added and shelves properties on getSingleShelf results?","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Can you please provide more information about users file?","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Missing node-gyp in manual install instructions","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Setting timeout option in Start-AzureRmVm","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# Documentation is lacking\n\n# Bug Report\r\n\r\n## System Information\r\n- Ubuntu 19.04\r\n- v1.8.3.4 built 09/08/2019 13:01\r\n- Mainline\r\n## I confirm:\r\n- [x ] that I have searched for an existing bug report for this issue.\r\n- [ x] that I am using the latest available version of AMP.\r\n- [ x] that my operating system is up-to-date.\r\n<!--\r\n  If all 3 boxes above are not confirmed, the issue with be closed as invalid.\r\n  Please only fill the boxes above with an 'x' character, and not anything else or it won't be marked correctly.\r\n-->\r\n\r\n## Symptoms \r\n\r\nI am trying to attach an existing ADS minecraft instance to a ADS on another server. Based on what I read in the forums (!) this should be possible. I found there appears to be an attach command for ampinstmgr. This command does not help to attach an instance on another server. This is documented nowhere other than in the forums.\r\n\r\nThere is many more examples of this. \r\n\r\nThe only existing documentation is on the git wiki. Especially the ampinstmgr command line page seems usefull but even that lacks basic explanation of options and parameters.\r\n\r\nThere needs to be better documentation!\r\n\r\n## Reproduction\r\n\r\n- Try to find information on running a game on another server: nothing in the documents\r\n- Try to find what is meant with e.g. [Module] [Provision Settings] -> Nowhere to be found \r\n- ampinstmgr help attach did  provide some information (basically that  I can't use it)","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"# Swagger documentation of Attribute API is out of sync\n\nIn the documentation for endpoint [/attributes/get_attributes__attribute_id_](https://backendapi.turing.com/docs/#/attributes/get_attributes__attribute_id_) the return is an array of attributes, but when the \"Try out\" is executed only one attribute is returned (no array).","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"npm start gives error","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Remove = from command line options in docs","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"provision Portland K8s cluster","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"# What is the ultimate end effect of setting bare-metal in the configuration\n\n<!--\r\n\r\n   ************************************** WARNING **************************************\r\n\r\n   The ciarcom bot parses this header automatically. Any deviation from the \r\n   template may cause the bot to automatically correct this header or may result in a \r\n   warning message, requesting updates.\r\n\r\n   Please ensure that nothing follows the Issue request type section, all \r\n   issue details are within the Description section and no changes are made to the \r\n   template format (as detailed below).\r\n\r\n   *************************************************************************************\r\n\r\n-->\r\n\r\n### Description\r\n\r\n<!--\r\n    Required\r\n    Add detailed description of what you are reporting.\r\n    Good example: https://os.mbed.com/docs/mbed-os/latest/contributing/workflow.html\r\n    Things to consider sharing:\r\n    - What target does this relate to?\r\n    - What toolchain (name + version) are you using?\r\n    - What tools (name + version - is it mbed-cli, online compiler or IDE) are you using?\r\n    - What is the SHA of Mbed OS (git log -n1 --oneline)?\r\n    - Steps to reproduce. (Did you publish code or a test case that exhibits the problem?)\r\n-->\r\nMbed-OS v5.12\r\n\r\nI'm using a custom CMake build process because I have requirements that mbed-cli is unable to accommodate.  \r\n\r\nI want to set up a rtos-less build.  I've seen issues #7800 and #7794.  I have no problems with eliminating the files those two issues cover, but I've also seen a reference to bare-metal in https://os.mbed.com/docs/mbed-os/v5.12/tutorials/migrating-to-mbed-os-5.html\r\n\r\nI would like to know what effect that configuration has - what defines are added or whatnot?  I tried grepping for bare-metal in the mbed-cli and tools directory but came up empty.  Is there a central source for the mapping of the directives in the json files to defines/files/etc that are added to the build process?\r\n\r\n### Issue request type\r\n\r\n<!--\r\n    Required\r\n    Please add only one X to one of the following types. Do not fill multiple types (split the issue otherwise.)\r\n    Please note this is not a GitHub task list, indenting the boxes or changing the format to add a '.' or '*' in front\r\n    of them would change the meaning incorrectly. The only changes to be made are to add a description text under the\r\n    description heading and to add a 'x' to the correct box.\r\n-->\r\n    [X] Question\r\n    [ ] Enhancement\r\n    [ ] Bug\r\n\r\n","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Something is missing","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Docs wrong for ionSwipe event on expandable ItemSliding","cats":{"DOCUMENTATION":1.0,"OTHER":0.0}}
{"text":"Can't start minishift due to rate limit","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Consider better view for endpoint selection","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"runAll does not work on a default Fedora installation","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Some click events are not dispatched in WebWorker mode","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
{"text":"Sequencing Sagas via yield*","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}}
